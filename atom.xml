<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>杨文昊的个人博客</title>
  
  <subtitle>愿你出走半生，归来仍是少年。</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2020-11-17T12:58:02.736Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>Alpha Yang</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>线段树</title>
    <link href="http://yoursite.com/2020/11/18/%E7%BA%BF%E6%AE%B5%E6%A0%91/"/>
    <id>http://yoursite.com/2020/11/18/%E7%BA%BF%E6%AE%B5%E6%A0%91/</id>
    <published>2020-11-17T20:54:38.000Z</published>
    <updated>2020-11-17T12:58:02.736Z</updated>
    
    <content type="html"><![CDATA[<object data="线段树.pdf" type="application/pdf" width="100%" height="100%">]]></content>
    
    <summary type="html">
    
      
      
        &lt;object data=&quot;线段树.pdf&quot; type=&quot;application/pdf&quot; width=&quot;100%&quot; height=&quot;100%&quot;&gt;


      
    
    </summary>
    
    
      <category term="ACM算法" scheme="http://yoursite.com/categories/ACM%E7%AE%97%E6%B3%95/"/>
    
      <category term="算法竞赛" scheme="http://yoursite.com/categories/ACM%E7%AE%97%E6%B3%95/%E7%AE%97%E6%B3%95%E7%AB%9E%E8%B5%9B/"/>
    
    
      <category term="线段树" scheme="http://yoursite.com/tags/%E7%BA%BF%E6%AE%B5%E6%A0%91/"/>
    
  </entry>
  
  <entry>
    <title>异常检测|视频监控方向8篇论文模型浅析</title>
    <link href="http://yoursite.com/2020/10/26/%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B-%E8%A7%86%E9%A2%91%E7%9B%91%E6%8E%A7%E6%96%B9%E5%90%918%E7%AF%87%E8%AE%BA%E6%96%87%E6%A8%A1%E5%9E%8B%E6%B5%85%E6%9E%90/"/>
    <id>http://yoursite.com/2020/10/26/%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B-%E8%A7%86%E9%A2%91%E7%9B%91%E6%8E%A7%E6%96%B9%E5%90%918%E7%AF%87%E8%AE%BA%E6%96%87%E6%A8%A1%E5%9E%8B%E6%B5%85%E6%9E%90/</id>
    <published>2020-10-25T20:55:25.000Z</published>
    <updated>2020-11-01T14:41:01.972Z</updated>
    
    <content type="html"><![CDATA[<p>在上星期的异常检测的<a href="https://zhuanlan.zhihu.com/p/266513299" target="_blank" rel="noopener">综述论文</a>中，我们谈及了异常检测的方向的很多应用层面，由于之后我的实验室可能会展开视屏监控(video surveillance)方面的任务，所以我也最近在研究该方向的论文，需要说明的是，异常检测并不是异常预测，无法提前知晓异常行为的发生，常见的异常情况如所有人都在走，有人突然跑起来或者骑了车的人路过，或者有人在视频下突然打起架来，检测难度是相当大的。另外要说的是，这些异常检测方法可以分为不同的任务，例如重构(reconstruction)任务与预测(prediction)任务，按照不同的任务训练数据集，将其中的异常行为给检测出来。上周内我阅读了8篇idea非常好并且可能会对我之后工作有启发式意义的论文，暂且对他们进行了粗略的阅读(阅读了模型idea与结果)，并以此文按照一定顺序介绍这些论文的模型方法，下周我可能会挑选1~2篇进行精读，西电电信大三的专业课是真的多（逃</p><a id="more"></a><h3 id="Future-frame-prediction-for-anomaly-detection–a-new-baseline"><a href="#Future-frame-prediction-for-anomaly-detection–a-new-baseline" class="headerlink" title="Future frame prediction for anomaly detection–a new baseline"></a>Future frame prediction for anomaly detection–a new baseline</h3><p>GB/T论文引用：Liu W, Luo W, Lian D, et al. Future frame prediction for anomaly detection–a new baseline[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2018: 6536-6545.</p><p>原文下载地址：<a href="https://openaccess.thecvf.com/content_cvpr_2018/papers/Liu_Future_Frame_Prediction_CVPR_2018_paper.pdf" target="_blank" rel="noopener">Future frame prediction for anomaly detection–a new baseline</a></p><p>这是来自上海科学技术大学高盛华课题组的一篇论文，于2018年被计算机视觉顶会CVPR接收，截止当前被引用170次。</p><p>上科大深耕异常检测视频监控方向的研究多年，有自己的上科大数据集，且被视觉界承认与使用。这篇文章从标题就可以得知，在视屏监控的预测残差分析方向形成了新的baseline，具体的准确率之后提到。我认为该篇论文的主要工作研究贡献可分为以下两点：</p><ul><li>首次(他说的)提出一种新的异常检测研究方法，利用一段时间的视屏图像进行下一个时刻的预测，并与真实情况进行分析比较，去检测异常情况。</li><li>为了能更准确的拟合正常的事件情况，除了采用传统的空间(spatial)上的密度与梯度约束，还首次利用Flownet对时序(temporal)上预测图像与真实图像进行约束。</li></ul><p>然后，我们直接放上该论文的主要模型，来分析整个实验的思路。</p><p><img src="/../image/advs1.png" alt=""></p><p>Fig2就是该实验的流程图了，首先在视频的时序逻辑上，进行到t时刻时t个frame，$I_1,I_2,…,I_t$，通过U-Net网络提取特征向量，并预测下一个时刻的图像$\hat{I}_{t+1}$，与真实的图像(gound truth)进行密度与梯度的误差分析，与此同时，也是这篇文章的亮点，还进行了时序上的比较，用Flownet将预测的t+1图像与实际的t图像进行光流提取，得到$Flow_{I_t\sim\hat{I}_{t+1}}$，并将实际的t+1图像与实际的t图像进行光流提取，得到$Flow_{I_t\sim I_{t+1}}$，将上述两者进行误差分析。虽然这里判决器输出的二分类标签，但实际的预测过程中，输出的是异常程度的score，如果出现了异常情况，就容易出现较低的分数。</p><p>这个Idea应该是在当前的视屏监测中非常常见的，通过训练正常情况的模型，去train相应的Flownet与Discriminator，从而更好地拟合正常情况，当异常情况发生时，肯定出现Loss较大的结果，从判定较低的正常score，从而达到检测的目的。下面我们来看看该实验的结果。</p><p><img src="/../image/advs2.png" alt=""></p><p>在各个数据集上表现还是很好的，当然使用的GAN的那个方法竟然感觉更Amazing，让我之后有空去阅读一下。这篇论文有开源代码，不过是用TF写的，所以我可能之后不会细读。</p><h3 id="Memorizing-normality-to-detect-anomaly-Memory-augmented-deep-autoencoder-for-unsupervised-anomaly-detection"><a href="#Memorizing-normality-to-detect-anomaly-Memory-augmented-deep-autoencoder-for-unsupervised-anomaly-detection" class="headerlink" title="Memorizing normality to detect anomaly: Memory-augmented deep autoencoder for unsupervised anomaly detection"></a>Memorizing normality to detect anomaly: Memory-augmented deep autoencoder for unsupervised anomaly detection</h3><p>GB/T论文引用：Gong D, Liu L, Le V, et al. Memorizing normality to detect anomaly: Memory-augmented deep autoencoder for unsupervised anomaly detection[C]//Proceedings of the IEEE International Conference on Computer Vision. 2019: 1705-1714.</p><p>原文下载地址：<a href="https://openaccess.thecvf.com/content_ICCV_2019/papers/Gong_Memorizing_Normality_to_Detect_Anomaly_Memory-Augmented_Deep_Autoencoder_for_Unsupervised_ICCV_2019_paper.pdf" target="_blank" rel="noopener">Memorizing normality to detect anomaly: Memory-augmented deep autoencoder for unsupervised anomaly detection</a></p><p>这是来自澳大利亚阿德莱德大学的一篇论文，于2019年被计算机视觉顶会ICCV接收，截止当前被引用63次。</p><p>这是篇加入Memory模块的AutoEncoder无监督学习异常检测方法，当然我需要首先说明的是这里的无监督学习并不是指样本是不加样本的normal和abnormal，而是指训练时利用无监督学习只训练正常样本，而从中学习到一些性质，从而与异常情况的极差拉开差距，值得注意的是传统方法OCNN和高斯分布异常检测的思路都是如此。</p><p>在AE中加入Memory模块的思路其实这并不是第一次，但是该篇文章是把该思路应用于视频监控的，从我的第一感觉来看觉得不如第一篇文章非常靠谱，但实验结果确实表现不错，下面我来总结下该论文的主要工作贡献：</p><ul><li>在异常检测领域AE被研究者广泛使用，通常的方法是使用AE来拟合normal的情况，然后来判断异常情况，然而由于AE的泛化能力过强，所以有可能还能泛化(normalize)异常情况，所以该文章提出加入Mem模块，使得recon. error(重构误差)增强，从而区分异常情况。</li></ul><p>下面我们来看下改论文给出的研究流程图：</p><p><img src="/../image/advs3.png" alt=""></p><p>注意该流程图只有一个Mem模块，而实际上实验中有多个。在训练阶段，我们只训练normal样本，并不断更新Mem，在测试阶段，我们不再更新Mem模块，当输入样本后，我们将未标记样本编码，找到Mem中最相近的Mem slots，然后将其解码，并与原始输入进行重构误差分析，即recon. error，如果是异常情况，会使error更大，这样的方法理论上有一定可能规避了AE泛化能力过强的问题。</p><p>这篇论文了解这个思路还是远远不够的，下面我们来详细解释下Mem模块的运作内理。</p><p><img src="/../image/advs4.png" alt=""></p><p>该图再次展示了论文的MemAE模型的更细节的内容，也就是Mem模块是如何address的，具体的理论公式感兴趣可以去深扒一下论文，我这里不做过多的数学公式推导，等下周精读论文我再细细道来。</p><p>我们来解释下具体的实验思路(以下将未训练的模块统称为pretrained)，首先输入样本x，进行pretrained编码，$z=f_e(x;\theta_e)$，将编码后的z向量扔进pretrained Memory Addressing模块，得到vector权重w，经过Hard Shrinkage得到$\hat{w}$，其实这个Shrinkage就是变种的ReLu激活函数，$\hat{w}_i=h(w_i;\lambda)$，然后与update之后的Memory M得到$\hat{z}=\hat{w}M$，最后进行pretrained解码输出$\hat{x}$，计算recon. error，这就是训练过程，测试过程也类似，那就是使用trained network来进行测试了。</p><p>好了，整篇文章的模型思路到这里应该已经差不多了，下面我们来看看实验结果，这篇文章很有趣，他不光跑了视频的数据集，还跑了图像的数据集，MNIST和CIFAR-10。</p><p><img src="/../image/advs5.png" alt=""></p><p>实验结果在图像识别的领域表现得竟然也很好，非常amazing啊！这样以后就能更准确的识别你小学二年级写的数字了（狗头。当然，这个方法也跑了异常检测的常用的3个数据集，如下图，就结果而言与上科大的方法准确率差距不算法，但是我很好奇他为啥没跑Pred1的数据集QAQ。</p><p><img src="/../image/advs6.png" alt=""></p><h3 id="Learning-Memory-guided-Normality-for-Anomaly-Detection"><a href="#Learning-Memory-guided-Normality-for-Anomaly-Detection" class="headerlink" title="Learning Memory-guided Normality for Anomaly Detection"></a>Learning Memory-guided Normality for Anomaly Detection</h3><p>GB/T论文引用：Park H, Noh J, Ham B. Learning Memory-guided Normality for Anomaly Detection[C]//Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. 2020: 14372-14381.</p><p>原文下载地址：<a href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Park_Learning_Memory-Guided_Normality_for_Anomaly_Detection_CVPR_2020_paper.pdf" target="_blank" rel="noopener">Learning Memory-guided Normality for Anomaly Detection</a></p><p>这是篇来自韩国延世大学的文章，2020年被CVPR接收，非常新鲜，截止当前被引用3次。</p><p>这篇文章看完之后，和上一篇2019ICCV的大体思路一致，也同样是为了防止AutoAE的泛化效果过强，导致异常情况检测不出来，所以加入了Mem模块，这篇文章也同样阐述了由于正常情况的distribution很多，异常情况的特征不一定在CNN的特征提取后那么明显地能得到我们想优化的Loss，那么这篇文章相较于上一篇的主要工作贡献，或者说创新之处，我们可以概括为以下两点：</p><ul><li>首先ICCV的文章主要做的是reconstruction的任务并得出异常画面的Loss和标签，而这篇文章既做了预测也做了重构任务，该文章model的输入可以是frame，即$I_t$从而预测下一个时间的$\hat{I}_t$。</li><li>ICCV文章的work采用的是激活函数+误差拟合的方法来训练并更新Memory模块的，而这篇文章的work的更新机制则是借鉴了CNN卷积的方法，用来更新以及输出，这个我们下面详细讲。</li></ul><p>好的，下面就是该模型的基本流程图了，和上一篇文章的大题思路一致，创新的部分主要是它的Mem更新机制。</p><p><img src="/../image/advs7.png" alt=""></p><p>这就是这篇文章的framework，其中Encoder是变种的U-net网络，用来提取输入frame的特征向量，提取出$H\times W \times C$的特征，然后作为$K(K=H\times W)$个queries，然后就是更新机制(感兴趣的可以扒一扒文章理论，这里不做详细说明了)，同样最后解码获得预测的frame。</p><p>以上为预训练的步骤，输出的frame与原frame对比，并计算误差Loss，本文使用了三个比较常见的Loss(Reconstruction Loss, Feature compactness Loss, Feature separateness Loss)，大家有兴趣可以去看看，然后训练了模型，最后再进行测试，下面我们来简单看看测试结果。</p><p><img src="/../image/advs8.png" alt=""></p><p>可以看到，这篇work做了不少实验，在预测的任务上表现突出，Reconstruction的异常检测上是不如上一篇ICCV的work的，同样也测试了有无Mem模块的实验，数据放在这里。这篇文章提供了很好的Mem更新与读取的思路，建议大家去看看，但是我对这个work的总体兴趣不算特别高，就简单说说以上内容了。</p><h3 id="Spatio-temporal-autoencoder-for-video-anomaly-detection"><a href="#Spatio-temporal-autoencoder-for-video-anomaly-detection" class="headerlink" title="Spatio-temporal autoencoder for video anomaly detection"></a>Spatio-temporal autoencoder for video anomaly detection</h3><p>GB/T论文引用：Zhao Y, Deng B, Shen C, et al. Spatio-temporal autoencoder for video anomaly detection[C]//Proceedings of the 25th ACM international conference on Multimedia. 2017: 1933-1941.</p><p>原文下载地址：<a href="https://alpha-yang.lanzous.com/iTMEXhrgbub" target="_blank" rel="noopener">Spatio-temporal autoencoder for video anomaly detection</a> (Notes：本文为付费文章，禁止以任何形式出售)</p><p>这是来自上海交通大学卢宏涛教授与阿里巴巴达摩院合作的work，于2017年被ACM MM会议接收，截止当前引用量为86次。</p><p>这篇文章看完之后，深刻地让我认识到了卷积有多么**的属性，总结一下，这篇文章没有Mem，没有什么花里胡哨的技巧，就是从头卷积到尾。采用了三维卷积，从时空(Spatial-Temporal)两个维度将frame的特征提取出来，以下我将这个work的模型简称为STAE(Spatial-Temporal AutoEncoder)，我将这篇文章的创新贡献与研究主要概括为以下三点：</p><ul><li>利用3D卷积构建了深度AE网络，对frame进行特征提取。</li><li>构造了新的预测型损失值函数，weight-decreasing prediction loss，$L_{pred}=\frac{1}{N}\Sigma_{i=1}^{N}\frac{1}{T^2}\Sigma_{t=1}^T(T-t)||X_{i+T}^t-f_{pred}(X_i)^t||_2^2$</li><li>构建了包含很多异常情况的数据集。</li></ul><p>下面就是整个网络流程图，其实非常容易理解，就是编码器和解码器，不过这个三维卷积具有很强的特征提取的作用。</p><p><img src="/../image/advs9.png" alt=""></p><p>大概整个work的思路就是如此，就是这样不停地套神经网络，得出了Reconstruction和Prediction的结果，这篇文章我认为对之后的很多研究可能会有启发意义，由于是17年的文章，所以最后的对比实验结果，并没有和近两年也就是前面介绍的论文相比。</p><p><img src="/../image/advs10.png" alt=""></p><h3 id="Object-centric-auto-encoders-and-dummy-anomalies-for-abnormal-event-detection-in-video"><a href="#Object-centric-auto-encoders-and-dummy-anomalies-for-abnormal-event-detection-in-video" class="headerlink" title="Object-centric auto-encoders and dummy anomalies for abnormal event detection in video"></a>Object-centric auto-encoders and dummy anomalies for abnormal event detection in video</h3><p>GB/T论文引用：Ionescu R T, Khan F S, Georgescu M I, et al. Object-centric auto-encoders and dummy anomalies for abnormal event detection in video[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2019: 7842-7851.</p><p>原文下载地址：<a href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Ionescu_Object-Centric_Auto-Encoders_and_Dummy_Anomalies_for_Abnormal_Event_Detection_in_CVPR_2019_paper.pdf" target="_blank" rel="noopener">Object-centric auto-encoders and dummy anomalies for abnormal event detection in video</a></p><p>这篇文章于2019年被计算机视觉顶会CVPR接收，截止当前被引用44次。</p><p>该work非常的有趣，当大家都在想如何把network做深的时候，这篇文章则是想着如何处理得到的特征向量，我们前面介绍了引入Mem模块的方法，而这篇文章也给我提供了一个全新的思路，我把文章的创意贡献简单概括为两个方面：</p><ul><li>训练无监督的object-centric卷积自动编码器，用来提取特征向量，并利用k-means把训练样本分为了不同的clusters</li><li>对于不同聚类使用监督学习方法SVM划分边界，然后训练one-versus-rest，对分类进行打分。</li></ul><p>该文章的framework流程图，如图所示，然后我们再一步一步的分析该work的总体思想。</p><p><img src="/../image/advs11.png" alt=""></p><p>如这篇文章的model所示，object-centric是用FPN框架把frame中的人物给提取出来，并选择一段时间的3张图片，如图所示。然后根据梯度的变化量以及t时刻frame本身，分别作为motion和appearance的输入值，再进行卷积AE，注意接下来我们是把隐含层作为特征向量拿出来并合并在一起。为了讲解清楚，下面我分开阐述该model的训练与测试过程，测试也就是inference推断。</p><p><strong>训练过程：</strong>将提取出的特征向量通过看K-means划分为不同的聚类，然后对每一个聚类都进行分析，比如输入了normal的样本，发现它属于聚类i中，那我们可以觉得聚类i是正常样本的可能性更高，然后利用SVM划分boundary，假设一共有k个聚类，可以把他们当成k个二分类SVM问题，同样最后的分数score也是由k各分类器得到的。</p><p><strong>测试/推断(test/inference)：</strong>推断过程，我们提取完特征向量后，直接使用k个SVM的分类打出对应的score，其中的最高分就作为我们的abnormality score s了。</p><script type="math/tex; mode=display">s(x)=-max_i\{g_i(x)\},\forall i \in \{1,2,...,k\}\\g_i(x)=\Sigma_{j=1}^mw_j\cdot x_j +b</script><p>最后来简单看一下实验结果，就结果而言，这个model表现地非常好，正好我有一位同学在做行人行为定位与识别方面的研究，其实如果能把两者结合会是一个很好的落地idea。</p><p><img src="/../image/advs12.png" alt=""></p><h3 id="Margin-Learning-Embedded-Prediction-for-Video-Anomaly-Detection-with-A-Few-Anomalies"><a href="#Margin-Learning-Embedded-Prediction-for-Video-Anomaly-Detection-with-A-Few-Anomalies" class="headerlink" title="Margin Learning Embedded Prediction for Video Anomaly Detection with A Few Anomalies"></a>Margin Learning Embedded Prediction for Video Anomaly Detection with A Few Anomalies</h3><p>GB/T论文引用：Liu W, Luo W, Li Z, et al. Margin Learning Embedded Prediction for Video Anomaly Detection with A Few Anomalies[C]//IJCAI. 2019: 3023-3030.</p><p>原文下载地址：<a href="https://www.ijcai.org/Proceedings/2019/0419.pdf" target="_blank" rel="noopener">Margin Learning Embedded Prediction for Video Anomaly Detection with A Few Anomalies</a></p><p>又是一篇来自上海科大高盛华老师组的文章，于2019年被机器学习A类会议IJCAI接收，截止当前被引用4次。</p><p>这是我看的论文中为数不多利用半监督学习思想的异常检测方法，这是8篇论文中我最感兴趣的一篇，可惜没有开源代码，现在我复现也没啥时间，之后倒是想试试看。该work阐述了如果我们只有少量的abnormal的样本，事实上在视屏监控的问题中，异常样本的数量是远远少于正常样本的，那在这样的情况下我们能不能将normal和abnormal的区分度拉到最大，下面我来介绍下这篇文章的主要创意贡献，也就是他的核心模型：</p><ul><li>该work提出了Margin Learning Embedded Prediction(MLEP) framework的模型，可以大间隔地拉大正常样本和异常样本之间的决策边界，既可以处理frame亦可以处理video。</li></ul><p>我们下面通过framework的流程图来好好理解其中的算法思路，特别是半监督学习的思路。</p><p><img src="/../image/advs13.png" alt=""></p><p>选取三段时间的video frame即$I_t \sim I_{t+T-1}$，包含异常情况的正样本，正常情况的负样本，与正常情况的未标签样本，经过Predictor提取出特征向量和预测future frame $\hat{I}_t$，其中Predictor由Encoder和ConvLSTM组成，然后我们对特征向量进行Margin Learning，让正常情况尽量靠近，以及异常情况远离的思想，对参数进行训练，从而达到整个实验目的，总体来说，我认为这样的思想甚是有趣，确实可以处理一些少样本异常情况的办法。</p><p><img src="/../image/advs14.png" alt=""></p><p>最后来看下实验结果，我对这篇文章倒是很想试验试验他在其他测试集上的效果，因为我觉得他是目前而言对于少样本异常的Open-set目前最有效的实验方法。</p><h3 id="Real-world-anomaly-detection-in-surveillance-videos"><a href="#Real-world-anomaly-detection-in-surveillance-videos" class="headerlink" title="Real-world anomaly detection in surveillance videos"></a>Real-world anomaly detection in surveillance videos</h3><p>GB/T论文引用：Sultani W, Chen C, Shah M. Real-world anomaly detection in surveillance videos[C]//Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2018: 6479-6488.</p><p>原文下载地址：<a href="https://openaccess.thecvf.com/content_cvpr_2018/papers/Sultani_Real-World_Anomaly_Detection_CVPR_2018_paper.pdf" target="_blank" rel="noopener">Real-world anomaly detection in surveillance videos</a></p><p>这是一篇来自巴基斯坦大学的文章工作，于2018年被计算机视觉顶会CVPR接收，截止当前被引用276次。</p><p>这篇文章也提供了异常检测非常好的方法，被引用了很多次，相较于其他方法，该model的可解释性更强，阅读完论文后，我将该篇文章的主要贡献概括为两个方面：</p><ul><li>idea较为新颖，将正常样本和异常样本统一打包在bag里，作为样本进行multiple instance learning(MIL)，最后对其进行ranking score。</li><li>另外本文构建了新的数据集，1900个视屏，长达128小时。</li></ul><p>还是老样子，我们先来看该文章的framework，从而去理解这个model是如何work的。</p><p><img src="/../image/advs15.png" alt=""></p><p>本文framework的流程图如上图所示，将异常情况与正常情况一起训练，按道理而言是监督学习的方法，进行FC network的参数拟合。首先时序上选取32张正常情况与异常情况的segments，并分别把他们放入Positive bags和Negative bags里，然后用pretrained的C3D网络来提取特征向量，然后通过pretrained的FC layers全连接层，进行4096到1的压缩，得到分值scores，将两个情况的分值放在对应的两个bag里，然后将正bag的最大值与负包的最小值进行比较，最后的Loss function得到了这样的式子，属于SVM中loss的变种体：</p><script type="math/tex; mode=display">l(\mathcal{B_a},\mathcal{B_n})=max(0,1-max_{i\in \mathcal{B_a}}f(\mathcal{V_a^i})+max_{i\in \mathcal{B_n}}f(\mathcal{V_n^i}))+\lambda_1\Sigma_i^{(n-1)}(f(\mathcal{V_a^i})-f(\mathcal{V_a^{i+1}}))^2+\lambda_2\Sigma_i^nf(\mathcal{V_a^i})</script><p>然后最后实验结果并没有与很多方法进行比较，但是就他自己的可视化测试的结果而言，表现地还是挺准确的，另外他们自己建立的open-set数据集挑战难度较大，可以预见未来该领域有更多的work可以去探究。</p><p><img src="/../image/advs16.png" alt=""></p><h3 id="A-revisit-of-sparse-coding-based-anomaly-detection-in-stacked-rnn-framework"><a href="#A-revisit-of-sparse-coding-based-anomaly-detection-in-stacked-rnn-framework" class="headerlink" title="A revisit of sparse coding based anomaly detection in stacked rnn framework"></a>A revisit of sparse coding based anomaly detection in stacked rnn framework</h3><p>GB/T论文引用：Luo W, Liu W, Gao S. A revisit of sparse coding based anomaly detection in stacked rnn framework[C]//Proceedings of the IEEE International Conference on Computer Vision. 2017: 341-349.</p><p>原文下载地址：<a href="https://openaccess.thecvf.com/content_ICCV_2017/papers/Luo_A_Revisit_of_ICCV_2017_paper.pdf" target="_blank" rel="noopener">A revisit of sparse coding based anomaly detection in stacked rnn framework</a></p><p>上周我阅读的最后一篇文章也是来自上科大高盛华老师组的文章，于2017被计算机视觉顶会ICCV接收，截止当前被引用121次。</p><p>本文的model其实是RNN网络的变种与改进，将其应用于了异常检测领域，其实最近几年RNN和LSTM这些越来越适用于检测一段时间内的特征处理，这篇文章其实能说的内容比较少，因为我也没细看，主要的创意点就是模型吧，另外还构建了属于自己的数据集。</p><p>下面我们直接来看本文的framework，模型就是标题所示的Temporally-coherent Sparse Coding(TSC)与sRNN相结合的改进模型。</p><p><img src="/../image/advs17.png" alt=""></p><p>Fig1中图(a)表示的就sRNN网络结果，和RNN就是堆积方式的区别，这里不了解的可以去自行查阅资料，然后本文的work提出的模型就是图(b)了，这篇文章主要是这样一个改进模型，用来进行时序模型上的分析，这是一个非常有趣且新颖的模型，之后可能阅读到不少基于这个模型改进的方法吧。</p><p><img src="/../image/advs18.png" alt=""></p><p>最后就是测试集的效果啦，当然还有文章里介绍的上科大提出的新的异常检测数据集<strong>ShanghaiTech Campus Dataset</strong>，从上面7篇文章我们也可以看出，在之后的几年里上科大的数据集受到了大家的广泛认可。</p><p>最后的最后，终于写完了这8篇论文模型简单的分析了，反正我头已经晕了，研究一个新的领域总是非常interesting的，不知道未来自己能不能也为机器学习的科研做出一点点成果，各位晚安~</p><p>Notes：这周一定更新数学模型，马尔可夫决策过程，本周日晚12点前没更新，我直播女装（逃</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在上星期的异常检测的&lt;a href=&quot;https://zhuanlan.zhihu.com/p/266513299&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;综述论文&lt;/a&gt;中，我们谈及了异常检测的方向的很多应用层面，由于之后我的实验室可能会展开视屏监控(video surveillance)方面的任务，所以我也最近在研究该方向的论文，需要说明的是，异常检测并不是异常预测，无法提前知晓异常行为的发生，常见的异常情况如所有人都在走，有人突然跑起来或者骑了车的人路过，或者有人在视频下突然打起架来，检测难度是相当大的。另外要说的是，这些异常检测方法可以分为不同的任务，例如重构(reconstruction)任务与预测(prediction)任务，按照不同的任务训练数据集，将其中的异常行为给检测出来。上周内我阅读了8篇idea非常好并且可能会对我之后工作有启发式意义的论文，暂且对他们进行了粗略的阅读(阅读了模型idea与结果)，并以此文按照一定顺序介绍这些论文的模型方法，下周我可能会挑选1~2篇进行精读，西电电信大三的专业课是真的多（逃&lt;/p&gt;
    
    </summary>
    
    
      <category term="科研路漫漫" scheme="http://yoursite.com/categories/%E7%A7%91%E7%A0%94%E8%B7%AF%E6%BC%AB%E6%BC%AB/"/>
    
      <category term="异常检测" scheme="http://yoursite.com/categories/%E7%A7%91%E7%A0%94%E8%B7%AF%E6%BC%AB%E6%BC%AB/%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B/"/>
    
    
      <category term="视屏监控" scheme="http://yoursite.com/tags/%E8%A7%86%E5%B1%8F%E7%9B%91%E6%8E%A7/"/>
    
  </entry>
  
  <entry>
    <title>【决策模型】马尔可夫决策过程</title>
    <link href="http://yoursite.com/2020/10/20/%E3%80%90%E5%86%B3%E7%AD%96%E6%A8%A1%E5%9E%8B%E3%80%91%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E5%86%B3%E7%AD%96%E8%BF%87%E7%A8%8B/"/>
    <id>http://yoursite.com/2020/10/20/%E3%80%90%E5%86%B3%E7%AD%96%E6%A8%A1%E5%9E%8B%E3%80%91%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB%E5%86%B3%E7%AD%96%E8%BF%87%E7%A8%8B/</id>
    <published>2020-10-19T16:45:09.000Z</published>
    <updated>2020-11-06T16:56:01.654Z</updated>
    
    <content type="html"><![CDATA[<p>咕了2个月的时光，我终于开始更新这个专栏系列了，真的惭愧，这两天在忙着整理校长奖学金的材料，所以写完这篇文章我可能需要再咕一段时间QAQ。</p><p>这次来讲一个数学模型中常见但是非常难以理解的话题，马尔可夫决策过程。可能很多同学都听过这个，那么这篇文章将带你搞懂马尔可夫性、马尔可夫链、马尔可夫过程、马尔可夫决策过程这些概念。由于本章内容有些难以理解，所以我前前后后也研究了一个多月。由于我目前的研究兴趣在于强化学习，而马尔可夫决策过程是强化学习建模的最基本模型，所以本文是根据David Silver的强化学习公开课整理的资料，马尔可夫决策过程是非常重要的模型。</p><a id="more"></a><h2 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1 Introduction"></a>1 Introduction</h2><ul><li>马尔可夫决策过程描述了我们想去决策事件本身的环境，即environment，我们的决策会因为环境得改变而改变，如果智能体agent选择的决策使得环境变差了，那它就会为此背锅，整个环境是持续可观察的。</li><li>目前的马尔可夫决策过程，可用于相当多的行为以及模式的决策分析，也在扩展人工智能的边界，在数学建模的问题中，也可改进很多的模型。</li><li>本文只讲解马尔可夫决策过程的模型分析以及概念解读与公式推导，关于模型的求解方法可利用动态规划、随机采样等，在数学建模中没必要运用深度学习法。</li></ul><h2 id="2-Markov-Processes马尔可夫过程"><a href="#2-Markov-Processes马尔可夫过程" class="headerlink" title="2 Markov Processes马尔可夫过程"></a>2 Markov Processes马尔可夫过程</h2><h3 id="2-1-Markov-Property马尔可夫性"><a href="#2-1-Markov-Property马尔可夫性" class="headerlink" title="2.1 Markov Property马尔可夫性"></a>2.1 Markov Property马尔可夫性</h3><p>在了解马尔可夫过程之前，我们首先得了解什么是马尔可夫性，马尔可夫性其实是一种假设，“未来的一切仅与现在有关，独立于过去的状态”。</p><p>关于马尔可夫性，我们给出了如下的Definition：</p><script type="math/tex; mode=display">A\; state\; S_t\; is\; Markov\; if\; and\; only\; if\\\mathbb{P}[S_{t+1}\;|\; S_t]=\mathbb{P}[S_{t+1}\; |\; S_1,...,S_t]</script><p>从上述的式子可以看出，t+1时刻的状态包含了1,..,t时刻状态的全部历史信息，并且当我们知道t时刻的状态后，我们只关注于环境的信息，而不用管之前所有状态的信息，这就是马尔可夫性，当论文中说某一状态或其他信息符合马尔可夫性时，我们也应当联想到这个性质。</p><h3 id="2-2-State-Transition-Matrix状态传输矩阵"><a href="#2-2-State-Transition-Matrix状态传输矩阵" class="headerlink" title="2.2 State Transition Matrix状态传输矩阵"></a>2.2 State Transition Matrix状态传输矩阵</h3><p>对于当前的马尔可夫状态s和其他的状态s’，状态传输矩阵的Definition：</p><script type="math/tex; mode=display">\mathcal{P}_{ss'}=\mathbb{P}[S_{t+1}=s'\; |\; S_t=s]\\\mathcal{P}=\begin{bmatrix}\mathcal{P}_{11} & \ldots & \mathcal{P}_{1n}\\\vdots & & \vdots \\\mathcal{P}_{n1} & \ldots & \mathcal{P}_{nn}\\\end{bmatrix}</script><p>以上就是状态传输矩阵的定义，大部分的模型建立都是利用矩阵的运算的，所以这部分很重要，当然$\Sigma\mathcal{P_{ss’}}=1$，这相信比较好理解。</p><h3 id="2-3-Markov-Chain马尔可夫链"><a href="#2-3-Markov-Chain马尔可夫链" class="headerlink" title="2.3 Markov Chain马尔可夫链"></a>2.3 Markov Chain马尔可夫链</h3><p>马尔可夫链(Markov Chain)又称马尔可夫过程(Markov Process)，是一种无记忆的随机过程(memoryless random process)，我们给出如下Definition，马尔可夫链是状态与转移概率的组合，$A\; Markov\; Chain\; is\; a\; tuple\; \langle \mathcal{S},\mathcal{P} \rangle$</p><p>其中，状态$\mathcal{S}$是状态的集合，概率$\mathcal{P}$是概率的矩阵。</p><p>下面我们用David老师上课举的一个例子来进一步理解马尔可夫过程，注意这个例子贯穿了整堂课程的内容。</p><p><img src="/../image/markov1.png" alt=""></p><p>这是一个学生上课情况的马尔可夫链结构，我们将Class 1作为学生的起始状态，把Sleep作为学生的终止状态。那我们可以想到一个学生从开始到结束可能会经历各种不同可能的状态。可能刷Facebook上瘾了出不来了，可能去Pub蹦迪了又返回复习了第一节课，等等。</p><p>那我们接下来首先写出这条马尔可夫链的状态传输矩阵：</p><script type="math/tex; mode=display">\mathcal{P}=\begin{bmatrix}& 0.5 & & & & 0.5 & \\& & 0.8 & & & & 0.2\\& &  & 0.6 & 0.4 & & \\& &  & & & & 1.0\\0.2 & 0.4 & 0.4 & & & & \\0.1 & & & & & 0.9 & \\& & & & & & 1\\\end{bmatrix}</script><p>其中行列分别代表状态C1,C2,C3,Pass,Pub,Facebook,Sleep。</p><h2 id="3-Markov-Reward-Process马尔可夫奖励过程"><a href="#3-Markov-Reward-Process马尔可夫奖励过程" class="headerlink" title="3 Markov Reward Process马尔可夫奖励过程"></a>3 Markov Reward Process马尔可夫奖励过程</h2><h3 id="3-1-MRP"><a href="#3-1-MRP" class="headerlink" title="3.1 MRP"></a>3.1 MRP</h3><p>简单来说，马尔可夫奖励过程就是含有奖励的马尔可夫链，要想理解MRP方程的含义，我们就得弄清楚奖励函数的由来，我们可以把奖励表述为进入某一状态后收获的奖励。奖励函数如下所示：</p><script type="math/tex; mode=display">\mathcal{R}_s=\mathbb{E}[R_{t+1}\; | \; S_t=s]</script><p>其实看到这个公式，我相信很多读者应该和我一样纠结，为什么奖励是t+1下一时刻的呢？然而这只是一个约定而已，实际上你把$R_{t+1}$改成$R_t$也没什么关系。本质上还是我们上面说的“把奖励表述为进入某一状态后收获的奖励”，这样理解即可。</p><p>下面就能给出MRP的Definition了，$A\; Markov\; reward\; process\;is\; a\; tuple\; \langle \mathcal{S},\mathcal{P},\mathcal{R},\mathcal{\gamma} \rangle$</p><p>其中，S还是状态合集，P是概率传输矩阵，R是奖励函数如上所示，$\gamma$是衰减因子。</p><p>衰减因子是金融学上的概念，代表了对于远期利益的不确定性，其中$\gamma \in[0,1]$，下面讲到回报时还会提到。</p><h3 id="3-2-Return回报"><a href="#3-2-Return回报" class="headerlink" title="3.2 Return回报"></a>3.2 Return回报</h3><p>回报的定义是从当前时刻开始的回报与衰减因子的乘积之和，公式如下：</p><script type="math/tex; mode=display">G_t = R_{t+1}+\gamma R_{t+2}+...=\sum_{k=0}^\infty \gamma^k R_{t+k+1}</script><p>注意回报的定义并不是当前状态之前的奖励总和，我们一定要理解马尔科夫模型构建的意义，是为了探寻未来的最优策略，以及马尔可夫性与历史总是不相关的，仅与当前状态有关。所以一切模型构建均是围绕未来进行展开的，包括这里的回报。衰减因子代表人们对于未来奖励的期望，如果$\gamma$趋近0，则更重视眼前的利益，如果$\gamma$趋近1，则更重视未来的利益。</p><h3 id="3-3-Value-Function价值函数"><a href="#3-3-Value-Function价值函数" class="headerlink" title="3.3 Value Function价值函数"></a>3.3 Value Function价值函数</h3><p>价值函数的定义是当处于现在状态s时，MRP未来回报的期望值，价值函数给出了当前状态的长期价值。</p><script type="math/tex; mode=display">v(s)=\mathbb{E}[G_t\; |\; S_t=s]</script><p>下面说了这么多概念让我们回到刚刚学生上课的例子。</p><p><img src="/../image/markov2.png" alt=""></p><p>在上图中，圆圈代表状态，R代表进入圆圈状态的即时奖励，而圆圈内的红色数字代表的就是价值函数，如何求出价值函数也就是当前马尔可夫最重要也是最需要讨论的问题。</p><h3 id="3-4-Bellman-Equation贝尔曼方程"><a href="#3-4-Bellman-Equation贝尔曼方程" class="headerlink" title="3.4 Bellman Equation贝尔曼方程"></a>3.4 Bellman Equation贝尔曼方程</h3><p>要想求解马尔可夫奖励过程的价值函数，我们在这里引入了贝尔曼方程，首先让我们看看贝尔曼方程：</p><script type="math/tex; mode=display">\begin{align}v(s) &= \mathbb{E}[G_t\; |\;S_t=s]\\& = \mathbb{E}[R_{t+1} + \gamma R_{t+2} +\gamma^2 R_{t+3}+\cdots \; | \; S_t=s]\\& = \mathbb{E}[R_{t+1} + \gamma (R_{t+2} +\gamma R_{t+3}+\cdots \;) | \; S_t=s]\\& = \mathbb{E}[R_{t+1} + \gamma G_{t+1}\; |\; S_t=s]\\& = \mathbb{E}[R_{t+1} + \gamma v(S_{t+1})\; |\; S_t=s]\end{align}</script><p>这就是贝尔曼方程简单的推导过程，这样我们就可以把价值函数分为两部分，一部分是即时奖励R，一部分是计算损失的下一状态的价值函数。</p><p>下面，我们抛开时间的关系，仅由状态来列写上述方程：</p><script type="math/tex; mode=display">v(s) = \mathbb{E}[R_{t+1}+\gamma v(S_{t+1})\; |\; S_t=s]\\v(s) = R_s + \gamma \sum_{s'\in \mathcal{S}}\mathcal{P}_{ss'}v(s')</script><p>以上两式就是贝尔曼方程的两种形式了，下面我们来进行求解，将贝尔曼方程简化为矩阵形式：</p><script type="math/tex; mode=display">v = \mathcal{R}+\gamma \mathcal{P}v\\\begin{bmatrix}v(1)\\\vdots\\v(n)\end{bmatrix}=\begin{bmatrix}\mathcal{R}_1\\\vdots\\\mathcal{R}_n\end{bmatrix}+\gamma\begin{bmatrix}\mathcal{P}_{11}&\ldots&\mathcal{P}_{1n}\\\vdots\\\mathcal{R}_n&\ldots&\mathcal{P}_{nn}\end{bmatrix}\begin{bmatrix}v(1)\\\vdots\\v(n)\end{bmatrix}</script><p>下面进行线性方程的矩阵直接求解：</p><script type="math/tex; mode=display">\begin{align}v &= \mathcal{R}+\gamma \mathcal{P}v\\(1-\gamma \mathcal{P})&= \mathcal{R}\\v &= (1-\gamma \mathcal{P})\mathcal{R}\end{align}</script><p>当然这种直接解法只能适用于小型的MRP模型，大型的MRP模型通常采用迭代的方法，比如动态规划，蒙特卡洛评估，时序差分学习等等。</p><h2 id="4-Markov-Decision-Process马尔可夫决策过程"><a href="#4-Markov-Decision-Process马尔可夫决策过程" class="headerlink" title="4 Markov Decision Process马尔可夫决策过程"></a>4 Markov Decision Process马尔可夫决策过程</h2><h3 id="4-1-MDP"><a href="#4-1-MDP" class="headerlink" title="4.1 MDP"></a>4.1 MDP</h3><p>下面终于讲到了今天的重头戏，MDP模型，如模型标题的意思所言，MDP就是具有决策状态的马尔可夫奖励过程。这里我们直接给出了马尔可夫决策过程的定义：$A\; Markov\; Decision\; Process\; is \; a\; tuple\; \langle \mathcal{S},\mathcal{A},\mathcal{P},\mathcal{R},\mathcal{\gamma} \rangle$</p><p>显然比起马尔可夫奖励过程，我们多了一个$\mathcal{A}$集合代表决策过程中所有action的集合。</p><p>而相应的，我们也需要改动传输概率矩阵和奖励函数的定义式了，因为他们都需要与action有关了。</p><script type="math/tex; mode=display">\mathcal{P}_{ss'}^a = \mathbb{P}[S_{t+1}=s'\; |\; S_t=s,A_t=a]\\\mathcal{R}_{s}^a = \mathbb{E}[R_{t+1}\; |\; S_t=s,A_t=a]</script><p>下面让我们回到那个学生上课的例子：</p><p><img src="/../image/markov3.png" alt=""></p><p>在MDP模型中，我们的智能体agent是能选择自己行动的action的，如果环境因为他的action变差了，那它就会因此背锅，最终的选择一定是让环境越来越好。</p><h3 id="4-2-Policies策略"><a href="#4-2-Policies策略" class="headerlink" title="4.2 Policies策略"></a>4.2 Policies策略</h3><p>策略是agent对于环境所表达的行为，这里我们给出它的定义和解释：</p><script type="math/tex; mode=display">\pi(a|s)=\mathbb{P}[A_t=a\;|\; S_t=s]</script><p>在上述定义中，MDP模型依旧是所有状态保持马尔可夫性，则我们可以得出MDP的策略也只与当前状态有关，与历史无关。另外策略也是与时间无关的，仅与当前状态有关，即$A_t\sim \pi(\cdot|S_t),\forall t&gt;0$</p><p>下面我们来理解策略在MDP的作用，以及MDP模型的分解：</p><ul><li>给出一个MDP $\mathcal{M}=\langle \mathcal{S},\mathcal{A},\mathcal{P},\mathcal{R},\mathcal{\gamma} \rangle$ 和一个策略 $\pi$</li><li>此时状态序列就构成了马尔可夫链 $\langle \mathcal{S},\mathcal{P}^\pi \rangle$</li><li>此时状态与奖励构成了MRP $\langle \mathcal{S},\mathcal{P}^\pi,\mathcal{R}^\pi,\mathcal{\gamma} \rangle$</li></ul><p>而这里我们给出基于策略 $\pi$ 的传输概率矩阵与奖励，即新的定义：</p><script type="math/tex; mode=display">\mathcal{P}_{ss'}^{\pi}=\sum_{a\in \mathcal{A}}\pi(a|s)\mathcal{P}_{ss'}^a\\\mathcal{R}_s^{\pi} = \sum_{a\in \mathcal{A} }\pi(a|s)R_s^a</script><h3 id="4-3-Policy-based-Value-Function基于策略的价值函数"><a href="#4-3-Policy-based-Value-Function基于策略的价值函数" class="headerlink" title="4.3 Policy based Value Function基于策略的价值函数"></a>4.3 Policy based Value Function基于策略的价值函数</h3><p>MDP模型中有两种基于策略的价值函数：(1) 在状态s时收益的期望，代表的是状态带来的价值 (2) 在状态s时，采取动作a后收益的期望，代表的是动作带来的价值。两者共同构成了MDP的价值函数。</p><p>下面我们分别给出定义式：</p><ul><li>state-value function</li></ul><script type="math/tex; mode=display">v_{\pi}(s)=\mathbb{E}_\pi[G_t\; |\; S_t=s]</script><ul><li>action-value function</li></ul><script type="math/tex; mode=display">q_\pi(s,a)=\mathbb{E}_\pi[G_t\; |\; S_t=s,A_t=a]</script><h3 id="4-4-Bellman-Expectation-Equation贝尔曼期望方程"><a href="#4-4-Bellman-Expectation-Equation贝尔曼期望方程" class="headerlink" title="4.4 Bellman Expectation Equation贝尔曼期望方程"></a>4.4 Bellman Expectation Equation贝尔曼期望方程</h3><p>同样，我们依旧可以利用贝尔曼方程来转换两个基于策略的价值函数：</p><script type="math/tex; mode=display">v_{\pi}(s)=\mathbb{E}_\pi[R_{t+1} + \gamma v_\pi (S_{t+1})\; |\; S_t=s]\\q_\pi(s,a)=\mathbb{E}_\pi[R_{t+1} + \gamma q_\pi(S_{t+1},A_{t+1})\; |\; S_t=s,A_t=a]</script><p>下面我们需要将我们的MDP模型进行解释，在马尔可夫链和MRP模型中，我们仅有状态的价值函数，那很显然在MDP模型中这是不够的，因为我们引入了Action，如果环境因为我们agent的Action而变差了，那Action则一定要背锅，于是我们也要考虑Action的价值函数，下面我们根据各种情况分别阐述如何求出价值函数。</p><ul><li>从状态到动作的价值函数</li></ul><p><img src="/../image/markov4.png" alt=""></p><p>当我们处于状态s时，agent有两个状态可以去执行，那我们此处的价值函数可以定义为：</p><script type="math/tex; mode=display">v_\pi(s)=\sum_{a\in \mathcal{A}}\pi(a|s)q_\pi(s,a)</script><p>这其实也很好理解，状态的价值函数就是所有下一步执行动作的价值函数的数学期望。</p><ul><li>从动作到状态的价值函数</li></ul><p><img src="/../image/markov5.png" alt=""></p><p>当从状态s执行动作action后我们可以进入下一个状态s‘，那我们此处的价值函数可以定义为：</p><script type="math/tex; mode=display">q_\pi(s,a)=\mathcal{R}_s^a+\gamma \sum_{s'\in \mathcal{S}}\mathcal{P}_{ss'}^av_\pi(s')</script><p>动作的价值函数就是离开状态s的即时奖励，加上所有可以进入下一个状态概率与价值的和。</p><ul><li>从状态到状态的价值函数</li></ul><p><img src="/../image/markov6.png" alt=""></p><p>状态到状态的价值函数只需要把上面两个价值函数合在一块即可：</p><script type="math/tex; mode=display">v_\pi(s)=\sum_{a\in \mathcal{A}}\pi(a|s)\left(\mathcal{R}_s^a+\gamma \sum_{s'\in \mathcal{S}}\mathcal{P}_{ss'}^av_\pi(s')\right)</script><ul><li>从动作到动作的价值函数</li></ul><p><img src="/../image/markov7.png" alt=""></p><script type="math/tex; mode=display">q_\pi(s,a)=\mathcal{R}_s^a+\gamma \sum_{s'\in \mathcal{S}}\mathcal{P}_{ss'}^a\sum_{a'\in \mathcal{A}}\pi(a'|s')q_\pi(s',a')</script><p>下面举一个简单的计算例子，还是使用学生上课的MDP模型。</p><p><img src="/../image/markov8.png" alt=""></p><p>假设我们通过某些算法求得红色的状态的价值为7.4，那我们该如何进行验证？这里可能会有读者很奇怪，这个价值函数不是求出来的嘛，为啥是验证。这些价值函数都只能得到一个近似解，那么所有近似解都涉及到了损失值的问题，那我们就需要去拟合最小的Loss，当然现在流行深度强化学习方法。</p><p>好，话说回来，根据我们上面状态到状态的价值函数，就可以很明确的得出这个值了，计算公式如图红色部分所示。下面我们列出MDP模型的贝尔曼方程矩阵形式，并给出直接解。</p><script type="math/tex; mode=display">v_\pi=\mathcal{R}^\pi+\gamma \mathcal{P}^\pi v_\pi \\v_\pi =(1-\gamma \mathcal{P}^\pi)^{-1}\mathcal{R}^\pi</script><h3 id="4-5-Optimal-Value-Function最优价值函数"><a href="#4-5-Optimal-Value-Function最优价值函数" class="headerlink" title="4.5 Optimal Value Function最优价值函数"></a>4.5 Optimal Value Function最优价值函数</h3><p>下面我们分别给出状态和动作最优价值函数的定义，其实就是在策略 $\pi$ 下，可以取得最大的价值函数，因为由于agent选择的不同策略，所有状态的价值函数都会相应的改变。</p><script type="math/tex; mode=display">v_*(s)=\max_\pi v_\pi(s)\\q_*(s,a)=\max_\pi q_\pi(s,a)</script><p>所有的MDP模型的最终任务就是为了确定最优价值函数相应的策略。</p><h3 id="4-6-Theorem-of-MDP定理"><a href="#4-6-Theorem-of-MDP定理" class="headerlink" title="4.6 Theorem of MDP定理"></a>4.6 Theorem of MDP定理</h3><p>以上给出的绝大部分是定义，下面我们给出几条MDP模型的定理，注意这是定理。</p><ul><li>对于MDP模型，我们承认存在一个最优策略$\pi_<em>$，比其他任何策略都好，即$\pi_</em> \geq \pi, \forall \pi$，这里我们还需要再定义策略比较的规则，即$\pi \geq \pi’ \; if\; v_\pi(s)\geq v_{\pi’}(s),\forall s$ </li><li>所有的最优策略都有相同的最优价值函数，即$v_{\pi_<em>}(s)=v_</em>(s)$</li><li>所有的最优策略都有相同的最优动作价值函数，即$q_{\pi_<em>}(s,a)=q_{</em>}(s,a)$</li></ul><h3 id="4-7-Finding-an-Optimal-Policy寻找最优策略"><a href="#4-7-Finding-an-Optimal-Policy寻找最优策略" class="headerlink" title="4.7 Finding an Optimal Policy寻找最优策略"></a>4.7 Finding an Optimal Policy寻找最优策略</h3><p>我们可以通过最大化动作价值函数$q_{*}(s,a)$的方法来寻找最优策略：</p><script type="math/tex; mode=display">\pi_*(a|s)=\left\{\begin{array}{rl}1 & \text{if } \displaystyle a=\arg\max_{a\in \mathcal{A}} q_*(s,a)\\0 & \text{otherwise } \end{array} \right.</script><h3 id="4-8-Bellman-Optimality-Equation贝尔曼最优方程"><a href="#4-8-Bellman-Optimality-Equation贝尔曼最优方程" class="headerlink" title="4.8 Bellman Optimality Equation贝尔曼最优方程"></a>4.8 Bellman Optimality Equation贝尔曼最优方程</h3><p><img src="/../image/markov9.png" alt=""></p><p>当我们的agent在状态s时，对于该状态的最优价值函数一定是选择价值最优的动作函数，即：</p><script type="math/tex; mode=display">v_*(s)=\max_a q_*(s,a)</script><p>而对于action的最优动作价值而言，相当于离开状态s的即时奖励，加上可以转移的下一个状态的最优价值与传输概率的成绩之和，即：</p><p><img src="/../image/markov10.png" alt=""></p><script type="math/tex; mode=display">q_*(s,a)=\mathcal{R}_s^a+\gamma\sum_{s'\in \mathcal{S}}\mathcal{P}_{ss'}^av_*(s')</script><p>那么状态到状态的价值函数与动作到动作的价值函数与上面同理，只需要把两个方程式叠加即可。</p><p><img src="/../image/markov11.png" alt=""></p><p><img src="/../image/markov12.png" alt=""></p><p>最后再举一个计算最优方程的例子，让我们再回到学生上课的MDP模型中。</p><p><img src="/../image/markov13.png" alt=""></p><p>相信如果你认真看完了以上内容，能很好地明白红色的式子，当然这里我们假设了执行a动作时，必然会进入下一个状态s‘，即传输概率为1。</p><h3 id="4-9-Solving-the-Bellman-Optimality-Equation求解贝尔曼最优方程"><a href="#4-9-Solving-the-Bellman-Optimality-Equation求解贝尔曼最优方程" class="headerlink" title="4.9 Solving the Bellman Optimality Equation求解贝尔曼最优方程"></a>4.9 Solving the Bellman Optimality Equation求解贝尔曼最优方程</h3><p>贝尔曼最优方程是非线性的，通常而言没有固定的解法，有很多著名的迭代解法：</p><ul><li>Value Iteration 价值迭代</li><li>Policy Iteration 策略迭代</li><li>Q-learning </li><li>Sarsa</li></ul><p>这个可以大家之后去多了解了解。</p><h2 id="5-Conclusion"><a href="#5-Conclusion" class="headerlink" title="5 Conclusion"></a>5 Conclusion</h2><p>最后做个总结的话，这个应该是我研究最久的模型了，里面可能有很不到位的讲解之处，请大家谅解。</p><p>另外有任何问题，欢迎评论区留言来一起交流 ~ </p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;咕了2个月的时光，我终于开始更新这个专栏系列了，真的惭愧，这两天在忙着整理校长奖学金的材料，所以写完这篇文章我可能需要再咕一段时间QAQ。&lt;/p&gt;
&lt;p&gt;这次来讲一个数学模型中常见但是非常难以理解的话题，马尔可夫决策过程。可能很多同学都听过这个，那么这篇文章将带你搞懂马尔可夫性、马尔可夫链、马尔可夫过程、马尔可夫决策过程这些概念。由于本章内容有些难以理解，所以我前前后后也研究了一个多月。由于我目前的研究兴趣在于强化学习，而马尔可夫决策过程是强化学习建模的最基本模型，所以本文是根据David Silver的强化学习公开课整理的资料，马尔可夫决策过程是非常重要的模型。&lt;/p&gt;
    
    </summary>
    
    
      <category term="数学建模" scheme="http://yoursite.com/categories/%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1/"/>
    
      <category term="模型篇" scheme="http://yoursite.com/categories/%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1/%E6%A8%A1%E5%9E%8B%E7%AF%87/"/>
    
    
      <category term="马尔可夫" scheme="http://yoursite.com/tags/%E9%A9%AC%E5%B0%94%E5%8F%AF%E5%A4%AB/"/>
    
  </entry>
  
  <entry>
    <title>异常检测|Anomaly Detection综述</title>
    <link href="http://yoursite.com/2020/10/18/%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B-Anomaly-Detection%E7%BB%BC%E8%BF%B0/"/>
    <id>http://yoursite.com/2020/10/18/%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B-Anomaly-Detection%E7%BB%BC%E8%BF%B0/</id>
    <published>2020-10-17T20:39:56.000Z</published>
    <updated>2020-11-01T14:40:53.145Z</updated>
    
    <content type="html"><![CDATA[<p>[TOC]</p><h2 id="一、简介"><a href="#一、简介" class="headerlink" title="一、简介"></a>一、简介</h2><p>异常检测一直是机器学习中一个非常重要的子分支，在各种人工智能落地应用例如计算机视觉、数据挖掘、NLP中，异常检测算法都是很热门的研究方向，特别是大数据时代，人工处理数据的速度已经远远赶不上机器了，所以更快地检测数据中的异常情况成为了我们当下非常重要的任务。在深度学习广泛的推广之前，传统的异常检测算法有很多，例如高斯拟合，半监督学习等等，而在深度学习大火之后，人们也开始研究将深度学习应用于各种异常任务中(也就是Deep Anomaly Detection，以下统称DAD)，并取得了很大的成功，本文将把当下该方向热门的研究方向分类并列举了对应的文章，希望能帮助大家更好地理解此方向的研究。</p><a id="more"></a><h2 id="二、异常检测的概念"><a href="#二、异常检测的概念" class="headerlink" title="二、异常检测的概念"></a>二、异常检测的概念</h2><p><img src="/../image/anomaly_detection_example1.PNG" alt=""></p><p>异常检测，从定义而言就是一种识别不正常情况与挖掘非逻辑数据的技术，也叫outliers。例如在计算机视觉的应用中，有人在抖音发表一个视屏，在边骑车边打电话，那这就是个不符合规范的视屏，我们能否采用一些方式来将其检测出来，再例如在数据挖掘领域中，那异常检测的应用就更广泛了，比如信用卡盗刷，超大金额支出等等。通常情况下，在我们阅读论文的过程中，异常检测(Anomaly Detection)也被叫做，Novelty Detection，Outlier Detection，Forgery Detection，Out-of-distribution Detection。在阅读论文的情况，这些名词也有轻微的区别，以计算机视觉为例，如下图所示。</p><p><img src="/../image/anomaly_detection_types.png" alt=""></p><p>在计算机视觉的基本任务——图像分类中，单分类与多分类问题，将几种概念的细微区别基本阐述清楚了。Anomaly Detection指在不属于该分类的数据集中，而Novelty是检测可能属于该分类但却没见过(Unseen)也就是Novel的数据集，而OOD(out-of-distribution)则是多分类中不同目标的分布，这些任务在接下来的论文中，也经常有人进行相应的研究。</p><h2 id="三、异常检测相关工作与方向"><a href="#三、异常检测相关工作与方向" class="headerlink" title="三、异常检测相关工作与方向"></a>三、异常检测相关工作与方向</h2><p>首先根据查阅异常检测方向综述的文章，我将基于深度学习的异常检测应用方向论文，按照主要的逻辑结构列举在了下面，我相信这可以更加方便地向你展示异常检测方向你应该怎样去研究你的论文。</p><h3 id="1-DAD研究的主要元素"><a href="#1-DAD研究的主要元素" class="headerlink" title="1. DAD研究的主要元素"></a>1. DAD研究的主要元素</h3><h4 id="1-异常数据集"><a href="#1-异常数据集" class="headerlink" title="(1) 异常数据集"></a>(1) 异常数据集</h4><ul><li>点集</li><li>连续集</li><li>团队集</li></ul><h4 id="2-异常检测模型"><a href="#2-异常检测模型" class="headerlink" title="(2) 异常检测模型"></a>(2) 异常检测模型</h4><ul><li>无监督学习、AutoEncoder、GAN、矩阵因子分解</li><li>半监督学习、强化学习</li><li>Hybrid(混种)、特征提取+传统算法</li><li>单分类神经网络</li></ul><h4 id="3-异常检测应用"><a href="#3-异常检测应用" class="headerlink" title="(3) 异常检测应用"></a>(3) 异常检测应用</h4><ul><li>诈骗检测</li><li>网络侵入检测</li><li>医学异常检测</li><li>传感器网络异常检测</li><li>视屏监督</li><li>物联网大数据异常检测</li><li>日志异常检测</li><li>工业危害检测</li></ul><h3 id="2-异常检测论文分类"><a href="#2-异常检测论文分类" class="headerlink" title="2. 异常检测论文分类"></a>2. 异常检测论文分类</h3><p>下面也是我根据参考文献，把异常检测论文分成几个当前研究方向，相当于列出了一个目录在这里，可供之后方便查看，关于论文分类的一些概念，我会在下面的介绍中详细提及。</p><h4 id="1-数据的连续性"><a href="#1-数据的连续性" class="headerlink" title="(1) 数据的连续性"></a>(1) 数据的连续性</h4><h4 id="2-数据标签的可用性"><a href="#2-数据标签的可用性" class="headerlink" title="(2) 数据标签的可用性"></a>(2) 数据标签的可用性</h4><ul><li>监督学习Supervised Learning</li><li>半监督学习Semi-supervised Learning</li><li>无监督学习Unsupervised Learning</li></ul><h4 id="3-基于训练对象的模型"><a href="#3-基于训练对象的模型" class="headerlink" title="(3) 基于训练对象的模型"></a>(3) 基于训练对象的模型</h4><ul><li>深度混种模型Deep Hybrid Model(DHM)</li><li>单分类神经网络One-Class Neural Networks(OC-NN)</li></ul><h4 id="4-数据异常类型"><a href="#4-数据异常类型" class="headerlink" title="(4) 数据异常类型"></a>(4) 数据异常类型</h4><ul><li>点集Point</li><li>连续集Contextual</li><li>团队集Collective or Group</li></ul><h4 id="5-异常检测输出类型"><a href="#5-异常检测输出类型" class="headerlink" title="(5) 异常检测输出类型"></a>(5) 异常检测输出类型</h4><ul><li>异常分数Anomaly Score</li><li>标签Lable</li></ul><h4 id="6-异常检测应用"><a href="#6-异常检测应用" class="headerlink" title="(6) 异常检测应用"></a>(6) 异常检测应用</h4><p>有将近十种异常检测相关的应用，由于目前对该部分研究较浅，所以之后会考虑单独写篇文章来总结异常检测方面的应用型论文。</p><h2 id="四、原始数据的连续性Nature-of-Input-Data"><a href="#四、原始数据的连续性Nature-of-Input-Data" class="headerlink" title="四、原始数据的连续性Nature of Input Data"></a>四、原始数据的连续性Nature of Input Data</h2><p>在DAD问题中选择怎样的网络结构很大部分取自于原始数据(raw/input data)的类型，原始数据在广义上我们可以分为连续型(Sequential)与非连续型(Non-sequential)，如何选择相应的模型，我列举在下表中。</p><div class="table-container"><table><thead><tr><th style="text-align:center">原始数据类型</th><th style="text-align:center">举例</th><th style="text-align:center">DAD模型选择</th></tr></thead><tbody><tr><td style="text-align:center">连续型Sequential</td><td style="text-align:center">视屏，DNA序列，自然语言文本</td><td style="text-align:center">CNN，RNN，LSTM</td></tr><tr><td style="text-align:center">非连续型Non-sequential</td><td style="text-align:center">图片，传感器</td><td style="text-align:center">CNN，AE及其变种</td></tr></tbody></table></div><p>DAD在未降维的高维原始数据中表现优异，成功提取大规模数据的关系，通常情况下，网络越深，提取效果越好，这个部分感兴趣的话可以参考下面这篇文章。</p><ul><li>Yann LeCun, Yoshua Bengio, and Geoffrey Hinton. Deep learning. nature, 521(7553):436, 2015.</li></ul><h2 id="五、数据标签的可用性Availability-of-Labels"><a href="#五、数据标签的可用性Availability-of-Labels" class="headerlink" title="五、数据标签的可用性Availability of Labels"></a>五、数据标签的可用性Availability of Labels</h2><p>数据标签是非常重要的事情，标签代表着正常(normal)数据或是未见过(unseen/novel)的数据，对于标签内容的使用同样是现在异常检测方向论文重点考虑的事情。异常检测的模型也可以根据数据标签的内容广义的分为三类，监督，半监督和无监督。</p><h3 id="1-监督Supervised-DAD"><a href="#1-监督Supervised-DAD" class="headerlink" title="1. 监督Supervised DAD"></a>1. 监督Supervised DAD</h3><p>基于监督学习的DAD文章，整理了两篇医学方向的，由于监督学习对于标签内容的依赖度过重，所以他对于异常检测的问题并不是那么合适，所以它并不如半监督和无监督应用地那么广泛。</p><ul><li>Raghavendra Chalapathy, Ehsan Zare Borzeshi, and Massimo Piccardi. An investigation of recurrent neural architectures for drug name recognition. arXiv preprint arXiv:1609.07585, 2016a.</li><li>Raghavendra Chalapathy, Ehsan Zare Borzeshi, and Massimo Piccardi. Bidirectional lstm-crf for clinical concept extraction. arXiv preprint arXiv:1611.08373, 2016b.</li></ul><h3 id="2-半监督Semi-supervised-DAD"><a href="#2-半监督Semi-supervised-DAD" class="headerlink" title="2. 半监督Semi-supervised DAD"></a>2. 半监督Semi-supervised DAD</h3><p>由于正常数据集比异常数据集更好获得，所以半监督学习DAD方法被非常广泛的使用，拥有了足够的数据集，我们能更好地标出正常数据，异常数据，新数据的界限，半监督学习模型列举三篇论文。</p><ul><li>Drausin Wulsin, Justin Blanco, Ram Mani, and Brian Litt. Semi-supervised anomaly detection for eeg waveforms using deep belief nets. In Machine Learning and Applications (ICMLA), 2010 Ninth International Conference on, pages 436–441. IEEE, 2010.</li><li>Mutahir Nadeem, Ochaun Marshall, Sarbjit Singh, Xing Fang, and Xiaohong Yuan. Semi-supervised deep neural network for network intrusion detection. 2016.</li><li>Hongchao Song, Zhuqing Jiang, Aidong Men, and Bo Yang. A hybrid semi-supervised anomaly detection model for high-dimensional data. Computational intelligence and neuroscience, 2017.</li></ul><h3 id="3-无监督Unsupervised-DAD"><a href="#3-无监督Unsupervised-DAD" class="headerlink" title="3. 无监督Unsupervised DAD"></a>3. 无监督Unsupervised DAD</h3><p>传统机器学习算法其实我感觉更倾向于直接从数据集中让机器去学习一些东西，然后直接用参数的方式表示出来，异常检测问题同样我们也用自动标签的方式去检测是否异常，因为有时候可能数据难以获取。自动解码器是无监督DAD的核心，所以这里深度学习的一些神经网络大有可为，例如RNN，LSTM等等。我们这里只列举了一种采用变种半监督学习方法的论文，应用于异常数据降维，表现效果超越很多传统降维算法，如PCA，Isolation等等。</p><ul><li>Aaron Tuor, Samuel Kaplan, Brian Hutchinson, Nicole Nichols, and Sean Robinson. Deep learning for unsupervised insider threat detection in structured cybersecurity data streams. arXiv preprint arXiv:1710.00811, 2017.</li></ul><h2 id="六、基于训练对象的模型"><a href="#六、基于训练对象的模型" class="headerlink" title="六、基于训练对象的模型"></a>六、基于训练对象的模型</h2><p>按照训练对象的区别，我们把训练模型单独划分为两类，变种模型与单分类神经网络。</p><h3 id="1-深度变种模型Deep-Hybrid-Models-DHM"><a href="#1-深度变种模型Deep-Hybrid-Models-DHM" class="headerlink" title="1. 深度变种模型Deep Hybrid Models(DHM)"></a>1. 深度变种模型Deep Hybrid Models(DHM)</h3><ul><li>Jerone TA Andrews, Edward J Morton, and Lewis D Griffin. Detecting anomalous data using auto-encoders. International Journal of Machine Learning and Computing, 6(1):21, 2016a.</li><li>Tolga Ergen, Ali Hassan Mirza, and Suleyman Serdar Kozat. Unsupervised and semi-supervised anomaly detection with lstm neural networks. arXiv preprint arXiv:1710.09207, 2017.</li></ul><h3 id="2-单分类神经网络One-Class-Neural-Networks-OC-NN"><a href="#2-单分类神经网络One-Class-Neural-Networks-OC-NN" class="headerlink" title="2. 单分类神经网络One-Class Neural Networks(OC-NN)"></a>2. 单分类神经网络One-Class Neural Networks(OC-NN)</h3><ul><li>Raghavendra Chalapathy, Aditya Krishna Menon, and Sanjay Chawla. Anomaly detection using one-class neural networks. arXiv preprint arXiv:1802.06360, 2018a.</li></ul><h2 id="七、数据异常类型"><a href="#七、数据异常类型" class="headerlink" title="七、数据异常类型"></a>七、数据异常类型</h2><h3 id="1-点集Point"><a href="#1-点集Point" class="headerlink" title="1. 点集Point"></a>1. 点集Point</h3><p>好像没人专门研究过</p><h3 id="2-连续集Contextual"><a href="#2-连续集Contextual" class="headerlink" title="2. 连续集Contextual"></a>2. 连续集Contextual</h3><ul><li>Xiuyao Song, Mingxi Wu, Christopher Jermaine, and Sanjay Ranka. Conditional anomaly detection. IEEE Transactions on Knowledge and Data Engineering, 19(5):631–645, 2007.</li></ul><h3 id="3-团队集Collective-or-Group"><a href="#3-团队集Collective-or-Group" class="headerlink" title="3. 团队集Collective or Group"></a>3. 团队集Collective or Group</h3><ul><li>Raghavendra Chalapathy, Edward Toth, and Sanjay Chawla. Group anomaly detection using deep generative models. arXiv preprint arXiv:1804.04876, 2018b.</li><li>Lo¨ıc Bontemps, James McDermott, Nhien-An Le-Khac, et al. Collective anomaly detection based on long short-term memory recurrent neural networks. In International Conference on Future Data and Security Engineering, pages 141–152. Springer, 2016.</li><li>Daniel B Araya, Katarina Grolinger, Hany F ElYamany, Miriam AM Capretz, and G Bitsuamlak. Collective contextual anomaly detection framework for smart buildings. In Neural Networks (IJCNN), 2016 International Joint Conference on, pages 511–518. IEEE, 2016.</li><li>Naifan Zhuang, Tuoerhongjiang Yusufu, Jun Ye, and Kien A Hua. Group activity recognition with differential recurrent convolutional neural networks. In Automatic Face &amp; Gesture Recognition (FG 2017), 2017 12th IEEE International Conference on, pages 526–531. IEEE, 2017.</li></ul><h2 id="八、最后总结"><a href="#八、最后总结" class="headerlink" title="八、最后总结"></a>八、最后总结</h2><p>总之就是，今晚没写完qaq。。。</p><p>给大家推荐一个超级nice的github仓库，里面的文章都比较新，并且也进行了一些分类。</p><p><a href="https://github.com/hoya012/awesome-anomaly-detection" target="_blank" rel="noopener">awesome-anomaly-detection</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;[TOC]&lt;/p&gt;
&lt;h2 id=&quot;一、简介&quot;&gt;&lt;a href=&quot;#一、简介&quot; class=&quot;headerlink&quot; title=&quot;一、简介&quot;&gt;&lt;/a&gt;一、简介&lt;/h2&gt;&lt;p&gt;异常检测一直是机器学习中一个非常重要的子分支，在各种人工智能落地应用例如计算机视觉、数据挖掘、NLP中，异常检测算法都是很热门的研究方向，特别是大数据时代，人工处理数据的速度已经远远赶不上机器了，所以更快地检测数据中的异常情况成为了我们当下非常重要的任务。在深度学习广泛的推广之前，传统的异常检测算法有很多，例如高斯拟合，半监督学习等等，而在深度学习大火之后，人们也开始研究将深度学习应用于各种异常任务中(也就是Deep Anomaly Detection，以下统称DAD)，并取得了很大的成功，本文将把当下该方向热门的研究方向分类并列举了对应的文章，希望能帮助大家更好地理解此方向的研究。&lt;/p&gt;
    
    </summary>
    
    
      <category term="科研路漫漫" scheme="http://yoursite.com/categories/%E7%A7%91%E7%A0%94%E8%B7%AF%E6%BC%AB%E6%BC%AB/"/>
    
      <category term="论文阅读" scheme="http://yoursite.com/categories/%E7%A7%91%E7%A0%94%E8%B7%AF%E6%BC%AB%E6%BC%AB/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"/>
    
    
      <category term="异常检测" scheme="http://yoursite.com/tags/%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B/"/>
    
  </entry>
  
  <entry>
    <title>Pycharm通过ssh远程连接GPU服务器训练深度学习代码</title>
    <link href="http://yoursite.com/2020/09/26/Pycharm%E9%80%9A%E8%BF%87ssh%E8%BF%9C%E7%A8%8B%E8%BF%9E%E6%8E%A5GPU%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%AE%AD%E7%BB%83%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%BB%A3%E7%A0%81/"/>
    <id>http://yoursite.com/2020/09/26/Pycharm%E9%80%9A%E8%BF%87ssh%E8%BF%9C%E7%A8%8B%E8%BF%9E%E6%8E%A5GPU%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%AE%AD%E7%BB%83%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%BB%A3%E7%A0%81/</id>
    <published>2020-09-25T21:54:29.000Z</published>
    <updated>2020-09-26T16:33:39.227Z</updated>
    
    <content type="html"><![CDATA[<p>我相信大家在进行深度学习的科研时，都会遇到这个问题：(1) 使用的是租借的或者是实验室的云端服务器 (2) 自己在本地写代码，但是需要gpu来验证，而不是瞎眼写代码。 我平时使用python编译器基本是Pycharm，如果是轻量级的项目，我一般使用vscode (只要你用vsc我们就是异父异母的亲兄弟)。而一般写大平台项目我用的都是<strong>专业版</strong>的Pycharm，注意我以下教程的功能只能professional版本能用，community版本不能使用哦~</p><p>我这里想要把远端gpu云服务器和本地Pycharm代码项目给连接起来，这对于我们的代码调试与修改，是相当方便的。下面我就来记录一下我具体的操作过程。</p><a id="more"></a><h2 id="一、deployment远程配置"><a href="#一、deployment远程配置" class="headerlink" title="一、deployment远程配置"></a>一、deployment远程配置</h2><p><img src="/../image/d1.png" alt=""></p><p>首先我们需要配置我们的远程配置链接，打开Tools-&gt;Deployment-&gt;Configuration</p><p>然后我们点击<code>+</code>，输入服务器的IP与密码，选择<code>SFTP</code>类型，新建服务器的配置。</p><p><img src="/../image/d2.png" alt=""></p><p>最后选择<code>Mappings</code>，将本地路径与远端路径进行选择，远端路径就市部署到Linux上的路径，即本地文件上传的位置，进行保存，远端配置文件就配置完成了。</p><p><img src="/../image/d3.png" alt=""></p><h2 id="二、本地项目选择远端python解释器"><a href="#二、本地项目选择远端python解释器" class="headerlink" title="二、本地项目选择远端python解释器"></a>二、本地项目选择远端python解释器</h2><p>通过Files-&gt;settings路径进入配置界面，然后我们选择项目解释器<strong>Project Interpreter</strong>，选择ssh解释器已经存在的配置，并创造一个新copy，注意一下这里的逻辑关系，刚开始我并没有理解<code>Create</code>与<code>Move</code>的关系。</p><p><img src="/../image/d4.png" alt=""></p><p>这里如果点击<code>Move</code>则是表示把这个服务器上的默认解释器直接转移到当前项目中，并且不方便修改解释器路径(一台服务器上一般是多个python环境组成)。而<code>Create</code>选项则是创建了一个复制的环境，这样的好处显而易见，方便管理不用项目代码的连接位置，与编译器，如下图所示。</p><p><img src="/../image/d5.png" alt=""></p><p>在这里我选择的是python解释器是anaconda，由于电脑上有多个环境，而且有时候我需要使用特定的虚拟环境，那么如何知晓解释器的路径呢？打开远端服务器的命令行</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">~$ python        # 进入想要作为解释器的python环境</span><br><span class="line">&gt;&gt;&gt; import sys   </span><br><span class="line">&gt;&gt;&gt; print(sys.executable)  # 这里就是输出了python的解释器路径</span><br></pre></td></tr></table></figure><h2 id="三、将项目代码上传到远端服务器"><a href="#三、将项目代码上传到远端服务器" class="headerlink" title="三、将项目代码上传到远端服务器"></a>三、将项目代码上传到远端服务器</h2><p>最后我们还得选择上传到远端服务器的位置，这里我放在了我的文件夹中，勾选<code>Automatically upload</code>选项就是在<code>Finish</code>之后将所有项目代码自动上传。</p><p><img src="/../image/d6.png" alt=""></p><p>上传速度很快，耐心等待后，整个项目就完全部署到远端服务器上了，这时候你在本地运行，实际上代码是跑在远端服务器上的，如下图所示。</p><p><img src="/../image/d7.png" alt=""></p><p>这里可以看到，我们代码已经是跑在远端服务器上了，Pycharm这样的功能是极其方便的。</p><p>那么，如果我们需要修改某个文件的代码，还需要把所有项目重新上传吗？</p><p>这很显然，没必要，我们只需要把修改过的文件更新到远端即可。比如，我们修改了<code>test_image.py</code>文件，我们只需要右击，单独把它上传到远端，然后运行即可。</p><p><img src="/../image/d8.png" alt=""></p><p>OK，关于Pycharm如何通过ssh连接远端GPU服务器训练深度学习的代码教程就讲到这里了 ~</p><p>祝大家深度学习愉快 ~ 之后我要开始更新数模教程了</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;我相信大家在进行深度学习的科研时，都会遇到这个问题：(1) 使用的是租借的或者是实验室的云端服务器 (2) 自己在本地写代码，但是需要gpu来验证，而不是瞎眼写代码。 我平时使用python编译器基本是Pycharm，如果是轻量级的项目，我一般使用vscode (只要你用vsc我们就是异父异母的亲兄弟)。而一般写大平台项目我用的都是&lt;strong&gt;专业版&lt;/strong&gt;的Pycharm，注意我以下教程的功能只能professional版本能用，community版本不能使用哦~&lt;/p&gt;
&lt;p&gt;我这里想要把远端gpu云服务器和本地Pycharm代码项目给连接起来，这对于我们的代码调试与修改，是相当方便的。下面我就来记录一下我具体的操作过程。&lt;/p&gt;
    
    </summary>
    
    
      <category term="科研路漫漫" scheme="http://yoursite.com/categories/%E7%A7%91%E7%A0%94%E8%B7%AF%E6%BC%AB%E6%BC%AB/"/>
    
      <category term="ssh" scheme="http://yoursite.com/categories/%E7%A7%91%E7%A0%94%E8%B7%AF%E6%BC%AB%E6%BC%AB/ssh/"/>
    
    
      <category term="ssh" scheme="http://yoursite.com/tags/ssh/"/>
    
  </entry>
  
  <entry>
    <title>Django项目框架部署到远端服务器</title>
    <link href="http://yoursite.com/2020/09/22/Django%E9%A1%B9%E7%9B%AE%E6%A1%86%E6%9E%B6%E9%83%A8%E7%BD%B2%E5%88%B0%E8%BF%9C%E7%AB%AF%E6%9C%8D%E5%8A%A1%E5%99%A8/"/>
    <id>http://yoursite.com/2020/09/22/Django%E9%A1%B9%E7%9B%AE%E6%A1%86%E6%9E%B6%E9%83%A8%E7%BD%B2%E5%88%B0%E8%BF%9C%E7%AB%AF%E6%9C%8D%E5%8A%A1%E5%99%A8/</id>
    <published>2020-09-21T16:11:54.000Z</published>
    <updated>2020-09-25T13:55:27.060Z</updated>
    
    <content type="html"><![CDATA[<p>对这次web开发与项目部署进行简单的记录小结~</p><p>由于最近从事了深度学习方面的科研，实验室想将其算法落地，做成一个在线系统，于是这几天和几位朋友自学的Django框架，做了一个初步的最简单的网页，实现图像到画像的深度学习算法转换，这篇博客主要记录将做好的Django框架部署到远端的过程。</p><a id="more"></a><p>我们的系统虽然还有很多不完善的地方，但是没关系，越早把它部署到互联网上，才能越早发现线上特有的问题。现在也提倡渐进式开发，让产品在迭代中快速成长。</p><p>那么我们如何才能把Django框架推到远端呢，这里我们首先介绍下原理，其实很好理解，我们项目部署到远端，客户端发来http请求，Nginx作为直接对外的服务器接口，对http请求进行静态分析，而uwsgi则像是两个框架之间的静态“桥梁”，负责处理资源分析的问题。</p><p><img src="..\image\dj1.png" alt=""></p><p>好，下面我们来看具体的操作。</p><h2 id="一、合适的服务器与版本库需求"><a href="#一、合适的服务器与版本库需求" class="headerlink" title="一、合适的服务器与版本库需求"></a>一、合适的服务器与版本库需求</h2><p>我们把项目部署到远端服务器上，并要求能够通过公网访问。首先我们得选择一块合适的服务器，可以是阿里云，也可以是腾讯云等，区别不大，这里我直接使用的是实验室的服务器。</p><p>下面我们来讲解所有需要安装的库，这里需要注意一个问题，在我们推网站的过程中，<strong>请使用Python3.7版本来完成此事</strong>，由于实验室的服务器上当时只有conda，所以我们尝试用conda部署项目的时候，怎么也无法安装uwsgi库，最后是新建了虚拟环境才解决的，反正强烈不建议。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">~$ sudo apt-get nginx</span><br></pre></td></tr></table></figure><p>首先安装nginx版本库，使用最新的即可，下面我们通过pip3来安装剩下的支持库，在远端服务器上运行指令。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">~$ pip install uwsgi</span><br><span class="line">~$ pip install django</span><br></pre></td></tr></table></figure><p>安装两个需要依赖的库，下面一定记得检查一下，是否安装在了python3.7的库中，教大家一些简单的命令来验证。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">~$ python  # 进入python，这里会显示</span><br><span class="line">&gt;&gt;&gt; import sys   # 自带的system库</span><br><span class="line">&gt;&gt;&gt; print(sys.executable)   # 在这里可以查看python的路径与版本</span><br><span class="line">&gt;&gt;&gt; exit(0)   # 退出python</span><br><span class="line">~$ whereis python  # 查看当前主机上所有的python版本</span><br><span class="line">~$ which python  # 查看默认指向的python路径</span><br></pre></td></tr></table></figure><p>下面我再教大家如何查看自己刚刚装的第三方库的路径，这个很重要，因为之后的配置文件会让你填写进去。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">~$ python</span><br><span class="line">&gt;&gt;&gt; import django  # 检查django</span><br><span class="line">&gt;&gt;&gt; print(django.__file__)  # 这里便会输出django的安装path</span><br><span class="line">&gt;&gt;&gt; exit(0)</span><br></pre></td></tr></table></figure><p>基本上掌握了这些，然后安装完我们所需要的版本库，就能愉快地开始部署啦~</p><h2 id="二、Nginx配置与代码部署"><a href="#二、Nginx配置与代码部署" class="headerlink" title="二、Nginx配置与代码部署"></a>二、Nginx配置与代码部署</h2><p>下面我们检查下Nginx作为接受http请求的工具，是否能成功提起，我们首先在服务器(记得将你的Django项目上传到服务器上)上打开<code>/mysite/mysite/settings.py</code>，修改如下部分：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">DEBUG = <span class="literal">True</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># comment by yihao for anywhere to visit</span></span><br><span class="line"><span class="comment"># ALLOWED_HOSTS = ['10.170.60.58']</span></span><br><span class="line">ALLOWED_HOSTS = [<span class="string">'*'</span>]</span><br></pre></td></tr></table></figure><p>首先关于Debug模式，建议改成False，为了避免安全性问题。这里由于我们的网站还需要改进，为了防止报错看不到，所以暂时选择的True，但实际上线还是需要改成False。</p><p>关于<code>ALLOWED_HOSTS</code>部分，’*’表示允许所有请求，这是师兄改的，其实还可以改成域名或ip的形式，例如<code>ALLOWED_HOSTS = [&#39;ywh.com&#39;,&#39;10.170.60.58&#39;]</code></p><p>好，完成这些后，我们检查下Nginx是否能正常运行。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">~$ sudo service nginx start  # 这里必须要sudo，否则请求会被拒绝</span><br></pre></td></tr></table></figure><p>这是你就能看到Nginx的欢迎界面了，但显然这里的配置还是不可以的，现在只是提起了整个网站，现在我们还要让Nginx指向我们对应的服务器地址，这里我们进入Nginx的配置文件中。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">~$ cd &#x2F;etc&#x2F;nginx&#x2F;sites-available    # 进入配置文件</span><br></pre></td></tr></table></figure><p>这里是Nginx可以配置的地方，我们新建一个文件，命名为IP地址或已经选定的域名，或者直接本主机地址。</p><p>假设IP地址为<code>10.170.60.58</code>，新建该文件，无后缀名，并在文件中添加如下配置</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">server&#123;</span><br><span class="line">    charset utf<span class="number">-8</span>;</span><br><span class="line">    listen <span class="number">80</span>;</span><br><span class="line">    server_name <span class="number">10.170</span><span class="number">.60</span><span class="number">.58</span>;    <span class="comment"># 指定你的IP地址或域名   </span></span><br><span class="line"></span><br><span class="line">    location / &#123;</span><br><span class="line">        proxy_set_header Host $host;</span><br><span class="line">        uwsgi_pass unix:///home/amax/mysite/site.sock;     <span class="comment"># 设置监听的sock文件</span></span><br><span class="line">        include /etc/nginx/uwsgi_params;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>好接下来回到命令行，因为我们写的只是 Nginx 的可用配置，所以还需要把这个配置文件链接到在用配置上去，即<code>/etc/nginx/sites-enabled</code>路径文件中。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">amax@amax:&#x2F;etc&#x2F;nginx&#x2F;sites-available$ sudo ln -s &#x2F;etc&#x2F;nginx&#x2F;sites-available&#x2F;10.170.60.58 &#x2F;etc&#x2F;nginx&#x2F;sites-enabled</span><br></pre></td></tr></table></figure><p>至此Nginx配置完成，下面我们来配置uwsgi</p><h2 id="三、Uwsgi结构简介与配置"><a href="#三、Uwsgi结构简介与配置" class="headerlink" title="三、Uwsgi结构简介与配置"></a>三、Uwsgi结构简介与配置</h2><p>假设你有个叫做 <code>mysite</code> 的顶级项目包，期中包含一个模板 <code>mysite/wsgi.py</code>，模块包含一个 WSGI <code>application</code> 对象。如果你使用的是较新的 Django，这就是你运行 <code>django-admin startproject mysite</code> （使用你的项目名替换 <code>mysite</code>）后得到的目录结构。</p><p>那么Uwsgi包含了哪儿几个“桥梁”的部分呢？</p><p><code>uwsgi.ini</code>是我们最起始的配置文件，在这个文件中，我们对我们的桥梁进行最简单的配置。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">chdir&#x3D;&#x2F;home&#x2F;amax&#x2F;mysite</span><br><span class="line">module&#x3D;mysite.wsgi:application</span><br><span class="line">master&#x3D;True</span><br><span class="line">pidfile&#x3D;.&#x2F;mysite-master.pid</span><br><span class="line">vacuum&#x3D;True</span><br><span class="line">max-requests&#x3D;5000</span><br><span class="line">daemonize&#x3D;.&#x2F;mysite.log</span><br><span class="line">socket&#x3D;&#x2F;home&#x2F;amax&#x2F;mysite&#x2F;site.sock</span><br><span class="line">pythonpath&#x3D;&#x2F;usr&#x2F;local&#x2F;python3.7.7&#x2F;lib&#x2F;python3.7&#x2F;site-packages&#x2F;</span><br></pre></td></tr></table></figure><p>解释下这个简单的配置文件，基本上有几个重要的部分，(1) <code>pidfile</code>中其他程序可以通过这个pid文件，获取这个后台程序的pid，然后执行一些任务。这个文件在初始化<code>uwsgi.ini</code>之后，便会出现在你的顶级目录<code>mysite</code>中。 (2) <code>mysite.log</code>这里是存放项目日志的地方，以后部署项目的时候，如果出现了报错，都可以从这个地方来查询。 (3) <code>site.sock</code>时进程中产生的socket文件。(4) 而在<code>pythonpath</code>中指定的路径就是我们上述所说的python安装的第三方库的位置。</p><h2 id="四、项目部署与常用命令"><a href="#四、项目部署与常用命令" class="headerlink" title="四、项目部署与常用命令"></a>四、项目部署与常用命令</h2><p>好的，下面完成Django与uwsgi的配置后，我们就可以开始正式部署我们的项目了，在部署命令的同时，我也会给出一些常用的命令，用于开始，结束，重启或查看当前进程。</p><h3 id="Nginx"><a href="#Nginx" class="headerlink" title="Nginx"></a>Nginx</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">~$ nginx -s reload   # 重启服务，当你修改nginx文件后，记得重启nginx服务</span><br><span class="line">~$ nginx -s stop   # 停止服务</span><br></pre></td></tr></table></figure><h3 id="Uwsgi"><a href="#Uwsgi" class="headerlink" title="Uwsgi"></a>Uwsgi</h3><p>我们的Nginx服务在之前已经启动过了，下面我们开始尝试启动Uwsgi的服务，把我们的桥梁给搭起来。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">~$ uwsgi --ini uwsgi.ini  # 启动uwsgi服务，与此同时，同目录下应该会出现log，pid，sock文件</span><br><span class="line">~$ ps -ef | grep uwsgi   # 这里检查下uwsgi的进程，查看是否正常提起</span><br><span class="line">~$ killall -s INT uwsgi   # 如果uwsgi提起异常或者其他报错，建议删除所有进程，如果成功就不需要</span><br><span class="line">~$ uwsgi --reload mysite-master.pid  # 如果之后更改了uwsgi的文件，则重启服务</span><br></pre></td></tr></table></figure><p>目前为止，所有的配置与项目部署就完成了，下面通过公网的域名或IP地址即可访问了。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;对这次web开发与项目部署进行简单的记录小结~&lt;/p&gt;
&lt;p&gt;由于最近从事了深度学习方面的科研，实验室想将其算法落地，做成一个在线系统，于是这几天和几位朋友自学的Django框架，做了一个初步的最简单的网页，实现图像到画像的深度学习算法转换，这篇博客主要记录将做好的Django框架部署到远端的过程。&lt;/p&gt;
    
    </summary>
    
    
      <category term="科研路漫漫" scheme="http://yoursite.com/categories/%E7%A7%91%E7%A0%94%E8%B7%AF%E6%BC%AB%E6%BC%AB/"/>
    
      <category term="Django" scheme="http://yoursite.com/categories/%E7%A7%91%E7%A0%94%E8%B7%AF%E6%BC%AB%E6%BC%AB/Django/"/>
    
    
      <category term="Django" scheme="http://yoursite.com/tags/Django/"/>
    
  </entry>
  
  <entry>
    <title>ssh远程连接GPU服务器进行深度学习以及常用ssh命令汇总</title>
    <link href="http://yoursite.com/2020/09/05/ssh%E8%BF%9C%E7%A8%8B%E8%BF%9E%E6%8E%A5GPU%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%BF%9B%E8%A1%8C%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%BB%A5%E5%8F%8A%E5%B8%B8%E7%94%A8ssh%E5%91%BD%E4%BB%A4%E6%B1%87%E6%80%BB/"/>
    <id>http://yoursite.com/2020/09/05/ssh%E8%BF%9C%E7%A8%8B%E8%BF%9E%E6%8E%A5GPU%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%BF%9B%E8%A1%8C%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%BB%A5%E5%8F%8A%E5%B8%B8%E7%94%A8ssh%E5%91%BD%E4%BB%A4%E6%B1%87%E6%80%BB/</id>
    <published>2020-09-04T22:13:24.000Z</published>
    <updated>2020-09-25T13:53:40.794Z</updated>
    
    <content type="html"><![CDATA[<p>在我们进行深度学习的科研任务时，我们都会遇到复杂神经网络的训练问题，这时我们都不可避免地需要一块合适的gpu服务器，我认为gpu服务器的好处有两点：一是相对而言便宜一些，虽然很多gpu服务器也是昂贵的价格，我这里推荐下<a href="https://www.jikecloud.net/" target="_blank" rel="noopener">极客云</a>，这应该是我用过最便宜和稳定的服务器了，当然我现在一般用实验室的。二是gpu服务器不同于本地，大型的深度学习项目一般需要训练几天或几周才能完成，而如果训练到一半突然断电，那本地电脑就凉凉了，所以远程挂云gpu还是相当不错的。</p><a id="more"></a><h3 id="一、ssh工具"><a href="#一、ssh工具" class="headerlink" title="一、ssh工具"></a>一、ssh工具</h3><p>ssh是远程连接的关键技术，选择合适好用的ssh工具也是相当关键的，我之前也用过xshell等工具。但最后我被实验室师兄推荐了一款超级好用的ssh工具：MobaXterm (<a href="https://mobaxterm.mobatek.net/" target="_blank" rel="noopener">官网下载地址</a>)</p><p>推荐原因很简单：功能齐全，可视化界面优雅，文件操作方便</p><h4 id="1-主要功能"><a href="#1-主要功能" class="headerlink" title="1. 主要功能"></a>1. 主要功能</h4><p><img src="/../image/ssh1.png" alt=""></p><p>我一般就用<code>Session</code>模块足够，可以自动记录密码，非常方便。通常我们远程访问，操作以及使用一台gpu服务器，我们一般需要：username，ip和password。username通常是root，hit或amax等等，ip则是一串数字，10.170.这样的东西，password就是密码啦，只要点击<code>Session</code>模块，我们就能通过ssh添加我们需要访问的gpu主机信息，然后进入服务器即可。</p><p><img src="/../image/ssh4.png" alt=""></p><p>输入<code>Remote host</code>即可，输入形式为<code>username@serverIP</code>，然后输入密码，就可以访问了，愉快地在云端gpu上进行操作。</p><h4 id="2-文件操作方便"><a href="#2-文件操作方便" class="headerlink" title="2. 文件操作方便"></a>2. 文件操作方便</h4><p>文件操作一直是我一个很难整的事情，但是在这款ssh工具中，可视化效果非常好，可以直接看到gpu的所有目录信息。</p><p><img src="/../image/ssh2.png" alt=""></p><p>还有文件的上传下载与删除等问题，虽然这些利用命令都能实现，但给出了可视化的解决方案，还是相当不错的。</p><p><img src="/../image/ssh3.png" alt=""></p><h3 id="二、通过ssh远程访问GPU的Jupyter-Notebook"><a href="#二、通过ssh远程访问GPU的Jupyter-Notebook" class="headerlink" title="二、通过ssh远程访问GPU的Jupyter Notebook"></a>二、通过ssh远程访问GPU的Jupyter Notebook</h3><p>我们编写python经常会遇到jupyter notebook的格式，即ipynb，实际上这也是经常使用的机器学习训练方法，当然做工程pycharm应该更合适。这里我们讲解如何通过ssh远程访问GPU上的Jupyter Notebook，并将它在本地电脑上可视化，分为两个步骤即可。</p><h4 id="1-首先在远程GPU服务器的terminal上启动Jupyter-Notebook的服务"><a href="#1-首先在远程GPU服务器的terminal上启动Jupyter-Notebook的服务" class="headerlink" title="1. 首先在远程GPU服务器的terminal上启动Jupyter Notebook的服务"></a>1. 首先在远程GPU服务器的terminal上启动Jupyter Notebook的服务</h4><p>在终端输入以下代码：</p><figure class="highlight cmd"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jupyter notebook --no-browser --port=<span class="number">8889</span></span><br></pre></td></tr></table></figure><p>将远端的Jupyter端口设置为8889.</p><h4 id="2-然后在本地terminal上启动ssh，对接端口"><a href="#2-然后在本地terminal上启动ssh，对接端口" class="headerlink" title="2. 然后在本地terminal上启动ssh，对接端口"></a>2. 然后在本地terminal上启动ssh，对接端口</h4><p>在本地终端cmd输入以下代码：</p><figure class="highlight cmd"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh -N -f -L localhost:<span class="number">8888</span>:localhost:<span class="number">8889</span> username@serverIP</span><br></pre></td></tr></table></figure><p>-N 告诉SSH没有命令要被远程执行； -f 告诉SSH在后台执行； -L 是指定port forwarding的配置，远端端口是8889，本地的端口号的8888。</p><h4 id="4-最后启动本地端口，并输入指令"><a href="#4-最后启动本地端口，并输入指令" class="headerlink" title="4. 最后启动本地端口，并输入指令"></a>4. 最后启动本地端口，并输入指令</h4><p>最后打开浏览器访问：<a href="http://localhost:8888/" target="_blank" rel="noopener">http://localhost:8888/</a></p><p>如果是第一次访问，他会让你输入远程端给出的指令，即token密码，可由ssh工具终端的界面上复制粘贴获得。</p><p><img src="/../image/ssh5.png" alt=""></p><p>输入token即可远程访问jupyter的内容了。</p><h3 id="三、常用ssh命令汇总"><a href="#三、常用ssh命令汇总" class="headerlink" title="三、常用ssh命令汇总"></a>三、常用ssh命令汇总</h3><h4 id="1-目录操作"><a href="#1-目录操作" class="headerlink" title="1.目录操作"></a>1.目录操作</h4><figure class="highlight cmd"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span>                                      // 前进</span><br><span class="line"><span class="built_in">cd</span> ..                                   // 后退一级</span><br><span class="line">ls                                      // 查看当前目录下的所有目录和文件</span><br><span class="line"><span class="built_in">mkdir</span> new_dir                           // 新建名为"new_dir"的文件夹</span><br><span class="line">pwd                                     // 显示当前位置路径</span><br></pre></td></tr></table></figure><h4 id="2-文件操作"><a href="#2-文件操作" class="headerlink" title="2. 文件操作"></a>2. 文件操作</h4><figure class="highlight cmd"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">touch a.txt                             // 在当前目录下新增文件a.txt</span><br><span class="line">rm a.txt                                // 删除文件a.txt</span><br><span class="line">tar -zcvf test.zip test                 // 文件打包，将文件夹test打包为文件包test.zip</span><br><span class="line">unzip test.zip                          // 解压文件test.zip</span><br><span class="line">mv a.txt b.txt                          // 将文件a.txt重命名为b.txt </span><br><span class="line">mv /a /b /c                             // 将目录a移动到目录b下，并重新命名为目录c</span><br></pre></td></tr></table></figure><p>未完待续…</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在我们进行深度学习的科研任务时，我们都会遇到复杂神经网络的训练问题，这时我们都不可避免地需要一块合适的gpu服务器，我认为gpu服务器的好处有两点：一是相对而言便宜一些，虽然很多gpu服务器也是昂贵的价格，我这里推荐下&lt;a href=&quot;https://www.jikecloud.net/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;极客云&lt;/a&gt;，这应该是我用过最便宜和稳定的服务器了，当然我现在一般用实验室的。二是gpu服务器不同于本地，大型的深度学习项目一般需要训练几天或几周才能完成，而如果训练到一半突然断电，那本地电脑就凉凉了，所以远程挂云gpu还是相当不错的。&lt;/p&gt;
    
    </summary>
    
    
      <category term="科研路漫漫" scheme="http://yoursite.com/categories/%E7%A7%91%E7%A0%94%E8%B7%AF%E6%BC%AB%E6%BC%AB/"/>
    
      <category term="ssh" scheme="http://yoursite.com/categories/%E7%A7%91%E7%A0%94%E8%B7%AF%E6%BC%AB%E6%BC%AB/ssh/"/>
    
    
      <category term="深度学习" scheme="http://yoursite.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>【进阶篇】MATLAB科研制图常用代码命令</title>
    <link href="http://yoursite.com/2020/07/13/%E3%80%90%E8%BF%9B%E9%98%B6%E7%AF%87%E3%80%91MATLAB%E7%A7%91%E7%A0%94%E5%88%B6%E5%9B%BE%E5%B8%B8%E7%94%A8%E4%BB%A3%E7%A0%81%E5%91%BD%E4%BB%A4/"/>
    <id>http://yoursite.com/2020/07/13/%E3%80%90%E8%BF%9B%E9%98%B6%E7%AF%87%E3%80%91MATLAB%E7%A7%91%E7%A0%94%E5%88%B6%E5%9B%BE%E5%B8%B8%E7%94%A8%E4%BB%A3%E7%A0%81%E5%91%BD%E4%BB%A4/</id>
    <published>2020-07-12T23:55:11.000Z</published>
    <updated>2020-07-13T05:07:24.571Z</updated>
    
    <content type="html"><![CDATA[<p>本博客基于上一篇的基础上做了一些稍微进阶的命令汇总，由于本人很菜，所以这些命令可能对于大佬而言，依旧是基础，所以请大佬们略过轻喷。在这部分内容中，我添加了一些实用的以及我喜欢用的绘图方式，例如坐标轴绘制等等，本博客也会持续更新，包括三维颜色填充等等内容。</p><ul><li>绘制三维图形</li><li>设置坐标轴范围</li><li>绘制坐标轴箭头</li><li>绘制非线型箭头</li></ul><a id="more"></a><h4 id="绘制三维图形"><a href="#绘制三维图形" class="headerlink" title="绘制三维图形"></a>绘制三维图形</h4><p>在一些特定的问题里，二维已经不能满足我们的研究需求了，这时我们需要绘制三维的图形，其实很简单，其他基本的命令与二维图形完全一样，只需要使用<code>plot3</code>即可。我们这里绘制两条三维曲线，分别是$y_1=2cos(x),z_1=2sin(x)$和$y_2=sin(x),z_2=cos(x)$。学过物理的人都知道，这是两条螺旋曲线。</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">clear,clc</span><br><span class="line">x = <span class="built_in">linspace</span>(<span class="number">0</span>,<span class="number">20</span>,<span class="number">1000</span>); </span><br><span class="line">y1 = <span class="number">2</span>*<span class="built_in">cos</span>(x);</span><br><span class="line">z1 = <span class="number">2</span>*<span class="built_in">sin</span>(x);</span><br><span class="line">y2 = <span class="built_in">sin</span>(x);</span><br><span class="line">z2 = <span class="built_in">cos</span>(x);</span><br><span class="line"><span class="built_in">figure</span>(<span class="number">3</span>);</span><br><span class="line"><span class="built_in">plot3</span>(x,y1,z1,<span class="string">'r'</span>,<span class="string">'LineWidth'</span>,<span class="number">1.5</span>);</span><br><span class="line"><span class="built_in">hold</span> on</span><br><span class="line"><span class="built_in">plot3</span>(x,y2,z2,<span class="string">'b:'</span>,<span class="string">'LineWidth'</span>,<span class="number">1.5</span>);</span><br><span class="line">grid on</span><br><span class="line">xlabel(<span class="string">'x'</span>); ylabel(<span class="string">'y'</span>);zlabel(<span class="string">'z'</span>);</span><br><span class="line">set(gca,<span class="string">'Fontname'</span>,<span class="string">'Monospaced'</span>,<span class="string">'Fontsize'</span>,<span class="number">10</span>,<span class="string">'FontWeight'</span>,<span class="string">'bold'</span>);</span><br><span class="line">title(<span class="string">'三维例子：x\sim y_1,y_2 \sim z_1,z_2'</span>);</span><br></pre></td></tr></table></figure><p>效果如下图所示：</p><p><img src="/../image/mat6.png" alt=""></p><h4 id="设置坐标轴范围"><a href="#设置坐标轴范围" class="headerlink" title="设置坐标轴范围"></a>设置坐标轴范围</h4><p>在科研制图的过程中，我们还常常遇到一个非常常见的问题，就是坐标轴的范围选定，例如在上一张所示的图片中，我们可以很清楚地看到，由于x的范围在[0,20]之间，所以绘图默认的x轴坐标也是[0,20]，y轴与z轴同理。如果为了能使得整个坐标轴不那么挤，在这种情况下，我们通常想让整个图像的坐标范围变大一些，例如x轴我们希望范围为[0,25]，y轴我们希望范围为[-3,3]，z轴我们希望范围为[-3,3]。我们可以用以下方法：</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">clear,clc</span><br><span class="line">x = <span class="built_in">linspace</span>(<span class="number">0</span>,<span class="number">20</span>,<span class="number">1000</span>); </span><br><span class="line">y1 = <span class="number">2</span>*<span class="built_in">cos</span>(x);</span><br><span class="line">z1 = <span class="number">2</span>*<span class="built_in">sin</span>(x);</span><br><span class="line">y2 = <span class="built_in">sin</span>(x);</span><br><span class="line">z2 = <span class="built_in">cos</span>(x);</span><br><span class="line"><span class="built_in">figure</span>(<span class="number">3</span>);</span><br><span class="line"><span class="built_in">plot3</span>(x,y1,z1,<span class="string">'r'</span>,<span class="string">'LineWidth'</span>,<span class="number">1.5</span>);</span><br><span class="line"><span class="built_in">hold</span> on</span><br><span class="line"><span class="built_in">plot3</span>(x,y2,z2,<span class="string">'b:'</span>,<span class="string">'LineWidth'</span>,<span class="number">1.5</span>);</span><br><span class="line">grid on</span><br><span class="line">set(gca,<span class="string">'XLim'</span>,[<span class="number">0</span> <span class="number">25</span>]); <span class="comment">% 设置x轴的范围为[0,25]</span></span><br><span class="line">set(gca,<span class="string">'YLim'</span>,[<span class="number">-3</span> <span class="number">3</span>]);</span><br><span class="line">set(gca,<span class="string">'ZLim'</span>,[<span class="number">-3</span> <span class="number">3</span>]);</span><br><span class="line">xlabel(<span class="string">'x'</span>); ylabel(<span class="string">'y'</span>);zlabel(<span class="string">'z'</span>);</span><br><span class="line">set(gca,<span class="string">'Fontname'</span>,<span class="string">'Monospaced'</span>,<span class="string">'Fontsize'</span>,<span class="number">10</span>,<span class="string">'FontWeight'</span>,<span class="string">'bold'</span>);</span><br><span class="line">title(<span class="string">'三维例子：x\sim y_1,y_2 \sim z_1,z_2'</span>);</span><br></pre></td></tr></table></figure><p>效果如下图所示：</p><p><img src="/../image/mat7.png" alt=""></p><h4 id="绘制坐标轴箭头"><a href="#绘制坐标轴箭头" class="headerlink" title="绘制坐标轴箭头"></a>绘制坐标轴箭头</h4><p>绘制坐标轴的箭头是困扰了我很久的问题，我使用过非常多的办法，但通常往往差强人意或者新版本的编译错误，这里我提供一个很好用的函数<code>arrow.m</code>，我把它放在了我的github仓库<a href="https://github.com/Alpha-Yang/Matlab_arrowPlot" target="_blank" rel="noopener">Matlab_arrowPlot</a>中，大家可自行下载使用。下面我来说明该函数的使用方法，该函数不光可以画坐标轴，所有箭头都是同理。</p><p><code>arrow.m</code>函数绘制命令如下<code>arrow([x1 y1],[x2 y2])</code>，(三维也同理)表示绘制从(x1,y1)到(x2,y2)的箭头，非框图坐标是大家自己定义的坐标轴。还有两个我通常使用的命令，<code>BaseAngle</code>设置箭头的夹角，我通常设置30，以及<code>LineWidth</code>设置1即可。</p><p>下面我们来绘制上图的坐标轴，比如x轴绘制从(0,0,0)到(25,0,0)，y轴绘制从(0,-3,0)到(0,3,0)，z轴绘制从(0,0,-3)到(0,0,3)，好让我们直接来看代码。</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">clear,clc</span><br><span class="line">x = <span class="built_in">linspace</span>(<span class="number">0</span>,<span class="number">20</span>,<span class="number">1000</span>); </span><br><span class="line">y1 = <span class="number">2</span>*<span class="built_in">cos</span>(x);</span><br><span class="line">z1 = <span class="number">2</span>*<span class="built_in">sin</span>(x);</span><br><span class="line">y2 = <span class="built_in">sin</span>(x);</span><br><span class="line">z2 = <span class="built_in">cos</span>(x);</span><br><span class="line"><span class="built_in">figure</span>(<span class="number">3</span>);</span><br><span class="line"><span class="built_in">plot3</span>(x,y1,z1,<span class="string">'r'</span>,<span class="string">'LineWidth'</span>,<span class="number">1.5</span>);</span><br><span class="line"><span class="built_in">hold</span> on</span><br><span class="line"><span class="built_in">plot3</span>(x,y2,z2,<span class="string">'b:'</span>,<span class="string">'LineWidth'</span>,<span class="number">1.5</span>);</span><br><span class="line">grid on</span><br><span class="line">set(gca,<span class="string">'XLim'</span>,[<span class="number">0</span> <span class="number">25</span>]);</span><br><span class="line">set(gca,<span class="string">'YLim'</span>,[<span class="number">-3</span> <span class="number">3</span>]);</span><br><span class="line">set(gca,<span class="string">'ZLim'</span>,[<span class="number">-3</span> <span class="number">3</span>]);</span><br><span class="line">xlabel(<span class="string">'x'</span>); ylabel(<span class="string">'y'</span>);zlabel(<span class="string">'z'</span>);</span><br><span class="line">arrow([<span class="number">0</span> <span class="number">0</span> <span class="number">0</span>],[<span class="number">25</span> <span class="number">0</span> <span class="number">0</span>],<span class="string">'BaseAngle'</span>,<span class="number">30</span>,<span class="string">'LineWidth'</span>,<span class="number">1</span>); <span class="comment">% x轴绘制从(0,0,0)到(25,0,0)</span></span><br><span class="line">arrow([<span class="number">0</span> <span class="number">-3</span> <span class="number">0</span>],[<span class="number">0</span> <span class="number">3</span> <span class="number">0</span>],<span class="string">'BaseAngle'</span>,<span class="number">30</span>,<span class="string">'LineWidth'</span>,<span class="number">1</span>); <span class="comment">% y轴绘制从(0,-3,0)到(0,3,0)</span></span><br><span class="line">arrow([<span class="number">0</span> <span class="number">0</span> <span class="number">-3</span>],[<span class="number">0</span> <span class="number">0</span> <span class="number">3</span>],<span class="string">'BaseAngle'</span>,<span class="number">30</span>,<span class="string">'LineWidth'</span>,<span class="number">1</span>); <span class="comment">% z轴绘制从(0,0,-3)到(0,0,3)</span></span><br><span class="line">set(gca,<span class="string">'Fontname'</span>,<span class="string">'Monospaced'</span>,<span class="string">'Fontsize'</span>,<span class="number">10</span>,<span class="string">'FontWeight'</span>,<span class="string">'bold'</span>);</span><br><span class="line">title(<span class="string">'三维例子：x\sim y_1,y_2 \sim z_1,z_2'</span>);</span><br></pre></td></tr></table></figure><p>效果如下图所示，再次强调不光是坐标轴箭头，坐标空间任意两点的箭头都可以绘制：</p><p><img src="/../image/mat8.png" alt=""></p><h4 id="绘制非线型箭头"><a href="#绘制非线型箭头" class="headerlink" title="绘制非线型箭头"></a>绘制非线型箭头</h4><p>在我们绘图的过程中，我们还有另外一种情况，就是我们想表示某条曲线的变化趋势，比如$sin(x)$，我们希望在正弦函数上绘制一些箭头来表示，同样我找到了开源的绘制代码，放在了我的github仓库<a href="https://github.com/Alpha-Yang/Matlab_arrowPlot" target="_blank" rel="noopener">Matlab_arrowPlot</a>中。</p><p>使用<code>arrowPlot.m</code>函数绘制非线型箭头，<code>arrowPlot(x,y)</code>代表绘制x,y曲线上的箭头，常用的命令还有<code>number</code>代表曲线上的箭头个数，<code>LineWidth</code>代表线宽，<code>color</code>代表颜色。</p><p>例如以下的example：</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">clear,clc</span><br><span class="line">t = [<span class="number">0</span>:<span class="number">0.01</span>:<span class="number">20</span>];</span><br><span class="line">x = t.*<span class="built_in">cos</span>(t);</span><br><span class="line">y = t.*<span class="built_in">sin</span>(t);</span><br><span class="line">arrowPlot(x, y, <span class="string">'number'</span>, <span class="number">5</span>, <span class="string">'color'</span>, <span class="string">'r'</span>, <span class="string">'LineWidth'</span>, <span class="number">1</span>)</span><br></pre></td></tr></table></figure><p>效果图如下图所示，可惜的是此函数暂不支持三维图形的箭头绘制：</p><p><img src="/../image/mat9.png" alt=""></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本博客基于上一篇的基础上做了一些稍微进阶的命令汇总，由于本人很菜，所以这些命令可能对于大佬而言，依旧是基础，所以请大佬们略过轻喷。在这部分内容中，我添加了一些实用的以及我喜欢用的绘图方式，例如坐标轴绘制等等，本博客也会持续更新，包括三维颜色填充等等内容。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;绘制三维图形&lt;/li&gt;
&lt;li&gt;设置坐标轴范围&lt;/li&gt;
&lt;li&gt;绘制坐标轴箭头&lt;/li&gt;
&lt;li&gt;绘制非线型箭头&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    
      <category term="科研路漫漫" scheme="http://yoursite.com/categories/%E7%A7%91%E7%A0%94%E8%B7%AF%E6%BC%AB%E6%BC%AB/"/>
    
      <category term="科研制图" scheme="http://yoursite.com/categories/%E7%A7%91%E7%A0%94%E8%B7%AF%E6%BC%AB%E6%BC%AB/%E7%A7%91%E7%A0%94%E5%88%B6%E5%9B%BE/"/>
    
    
      <category term="MATLAB" scheme="http://yoursite.com/tags/MATLAB/"/>
    
  </entry>
  
  <entry>
    <title>【基础篇】MATLAB科研制图常用代码命令</title>
    <link href="http://yoursite.com/2020/07/13/%E3%80%90%E5%9F%BA%E7%A1%80%E7%AF%87%E3%80%91MATLAB%E7%A7%91%E7%A0%94%E5%88%B6%E5%9B%BE%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/"/>
    <id>http://yoursite.com/2020/07/13/%E3%80%90%E5%9F%BA%E7%A1%80%E7%AF%87%E3%80%91MATLAB%E7%A7%91%E7%A0%94%E5%88%B6%E5%9B%BE%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/</id>
    <published>2020-07-12T22:20:01.000Z</published>
    <updated>2020-07-12T16:09:04.035Z</updated>
    
    <content type="html"><![CDATA[<p>最近更新了不少关于数学建模算法与机器学习的博客，今天我来写写关于科研制图的MATLAB常用命令，众所周知，在未来的科研生涯中，只要是学工科的同学们，MATLAB都是大家必学的工具之一，而发paper中的制图更是重中之重，虽然科研制图讲究一个<strong>“丑”</strong>，但是不会画想必是不行的。本文应该是持续更新的，本博客我会总结一些较为细节处理的代码，如果你是个使用MATLAB科研制图的小白，我会强烈推荐<a href="https://www.bilibili.com/video/BV1GJ41137UH?p=5" target="_blank" rel="noopener">b站郭彦甫的MATLAB入门教程</a>，是我特别推荐的视屏系列。当然现在python科研制图也十分流行了，之后我也会整理。</p><a id="more"></a><h4 id="清屏、清除所有变量"><a href="#清屏、清除所有变量" class="headerlink" title="清屏、清除所有变量"></a>清屏、清除所有变量</h4><p>我有个习惯就是每个主程序的开头我都会清除所有变量以及进行清屏操作，这个习惯我个人认为还是防止我们代码重复运行的有效办法。</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">clear,clc <span class="comment">% clear清除所有变量，clc清屏</span></span><br></pre></td></tr></table></figure><h4 id="在同一坐标系下绘制多条曲线"><a href="#在同一坐标系下绘制多条曲线" class="headerlink" title="在同一坐标系下绘制多条曲线"></a>在同一坐标系下绘制多条曲线</h4><p>这依然是个十分基础的问题，我们可以使用<code>hold on</code>命令，这个命令在matlab中就是继续使用当前坐标轴的意思，与之对应的是<code>hold off</code>。当然大部分时候，后半部分命令可以不用写，下面我们以$y_1=2cos(x),y_2=sin(2x),y_3=3sin(x)$为例，进行图的绘制。</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">clear,clc</span><br><span class="line">x = <span class="built_in">linspace</span>(<span class="number">0</span>,<span class="number">20</span>,<span class="number">1000</span>); <span class="comment">% linspace(a,b,k)表示在区间[a,b]中任取k个点</span></span><br><span class="line">y1 = <span class="number">2</span>*<span class="built_in">cos</span>(x);</span><br><span class="line">y2 = <span class="built_in">sin</span>(<span class="number">2</span>*x);</span><br><span class="line">y3 = <span class="number">3</span>*<span class="built_in">sin</span>(x);</span><br><span class="line"><span class="built_in">figure</span>(<span class="number">1</span>); <span class="comment">% 其实可以不写，代表图画框1，但是通常为了标记图像，我一般都会这样写</span></span><br><span class="line"><span class="built_in">plot</span>(x,y1);</span><br><span class="line"><span class="built_in">hold</span> on <span class="comment">% 只需要一个hold on就可以了</span></span><br><span class="line"><span class="built_in">plot</span>(x,y2);</span><br><span class="line"><span class="built_in">plot</span>(x,y3);</span><br></pre></td></tr></table></figure><p>绘制效果如下图所示：</p><p><img src="/../image/mat1.png" alt=""></p><h4 id="在不同坐标系下绘制曲线，同框显示"><a href="#在不同坐标系下绘制曲线，同框显示" class="headerlink" title="在不同坐标系下绘制曲线，同框显示"></a>在不同坐标系下绘制曲线，同框显示</h4><p>相信学过的人都知道，这种情况我们一般使用<code>subplot</code>这样的命令，<code>subplot(a,b,k)</code>命令一般出现于每个<code>plot</code>命令前，代表的意思是绘制a*b的框图，目前绘制第k个图(顺序从上至下，从左至右)，比如我们实现以下代码会发生什么情况？</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">clear,clc</span><br><span class="line">x = <span class="built_in">linspace</span>(<span class="number">0</span>,<span class="number">20</span>,<span class="number">1000</span>);</span><br><span class="line">y1 = <span class="number">2</span>*<span class="built_in">cos</span>(x);</span><br><span class="line">y2 = <span class="built_in">sin</span>(<span class="number">2</span>*x);</span><br><span class="line">y3 = <span class="number">3</span>*<span class="built_in">sin</span>(x);</span><br><span class="line"><span class="comment">% figure 1: 2*3</span></span><br><span class="line"><span class="built_in">figure</span>(<span class="number">1</span>);</span><br><span class="line">subplot(<span class="number">2</span>,<span class="number">3</span>,<span class="number">1</span>); <span class="built_in">plot</span>(x,y1);</span><br><span class="line">subplot(<span class="number">2</span>,<span class="number">3</span>,<span class="number">2</span>); <span class="built_in">plot</span>(x,y2);</span><br><span class="line">subplot(<span class="number">2</span>,<span class="number">3</span>,<span class="number">3</span>); <span class="built_in">plot</span>(x,y3);</span><br><span class="line">subplot(<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>); <span class="built_in">plot</span>(x,y1);</span><br><span class="line">subplot(<span class="number">2</span>,<span class="number">3</span>,<span class="number">5</span>); <span class="built_in">plot</span>(x,y2);</span><br><span class="line">subplot(<span class="number">2</span>,<span class="number">3</span>,<span class="number">6</span>); <span class="built_in">plot</span>(x,y3);</span><br><span class="line"><span class="comment">% figure 2: 3*2</span></span><br><span class="line"><span class="built_in">figure</span>(<span class="number">2</span>);</span><br><span class="line">subplot(<span class="number">3</span>,<span class="number">2</span>,<span class="number">1</span>); <span class="built_in">plot</span>(x,y1);</span><br><span class="line">subplot(<span class="number">3</span>,<span class="number">2</span>,<span class="number">2</span>); <span class="built_in">plot</span>(x,y2);</span><br><span class="line">subplot(<span class="number">3</span>,<span class="number">2</span>,<span class="number">3</span>); <span class="built_in">plot</span>(x,y3);</span><br><span class="line">subplot(<span class="number">3</span>,<span class="number">2</span>,<span class="number">4</span>); <span class="built_in">plot</span>(x,y1);</span><br><span class="line">subplot(<span class="number">3</span>,<span class="number">2</span>,<span class="number">5</span>); <span class="built_in">plot</span>(x,y2);</span><br><span class="line">subplot(<span class="number">3</span>,<span class="number">2</span>,<span class="number">6</span>); <span class="built_in">plot</span>(x,y3);</span><br></pre></td></tr></table></figure><p>绘制效果如下图所示：</p><p><img src="/../image/mat2.png" alt=""></p><h4 id="开启坐标轴网格"><a href="#开启坐标轴网格" class="headerlink" title="开启坐标轴网格"></a>开启坐标轴网格</h4><p>在我们绘图的时候这样白色的界面实际上真的非常影响我们的对于数据分布情况的总结，于是我们想在坐标轴中添加相应的分割线，采用<code>grid on</code>命令即可。</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">clear,clc</span><br><span class="line">x = <span class="built_in">linspace</span>(<span class="number">0</span>,<span class="number">20</span>,<span class="number">1000</span>); </span><br><span class="line">y1 = <span class="number">2</span>*<span class="built_in">cos</span>(x);</span><br><span class="line">y2 = <span class="built_in">sin</span>(<span class="number">2</span>*x);</span><br><span class="line">y3 = <span class="number">3</span>*<span class="built_in">sin</span>(x);</span><br><span class="line"><span class="built_in">figure</span>(<span class="number">1</span>); </span><br><span class="line"><span class="built_in">plot</span>(x,y1);</span><br><span class="line"><span class="built_in">hold</span> on </span><br><span class="line"><span class="built_in">plot</span>(x,y2);</span><br><span class="line"><span class="built_in">plot</span>(x,y3);</span><br><span class="line">grid on</span><br></pre></td></tr></table></figure><p>效果如下图所示：</p><p><img src="/../image/mat3.png" alt=""></p><h4 id="改变曲线颜色，设置线宽"><a href="#改变曲线颜色，设置线宽" class="headerlink" title="改变曲线颜色，设置线宽"></a>改变曲线颜色，设置线宽</h4><p>在我们绘图的时候设置曲线的颜色同样重要，如果我们不设置的话，matlab会给所有曲线默认的颜色排列，以及宽度(默认1)。然而，事实上我们知道，通常我们并不适合他给的颜色以及默认线宽有些太细了。先来说说，matlab如何调整曲线颜色以及坐标点的问题，大家可参考博客：<a href="https://blog.csdn.net/sinat_21026543/article/details/80215281" target="_blank" rel="noopener">Matlab画图常用的符号和颜色</a></p><p>同样我们其实还有其他方法调整颜色，我们知道颜色的表示都是使用三维向量RGB表示，所以我们可以调整参数，来调整曲线的特殊颜色，如深红浅红等等。先上代码：</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">clear,clc</span><br><span class="line">x = <span class="built_in">linspace</span>(<span class="number">0</span>,<span class="number">20</span>,<span class="number">1000</span>); </span><br><span class="line">y1 = <span class="number">2</span>*<span class="built_in">cos</span>(x);</span><br><span class="line">y2 = <span class="built_in">sin</span>(<span class="number">2</span>*x);</span><br><span class="line">y3 = <span class="number">3</span>*<span class="built_in">sin</span>(x);</span><br><span class="line"><span class="built_in">figure</span>(<span class="number">1</span>); </span><br><span class="line"><span class="built_in">plot</span>(x,y1,<span class="string">'k'</span>,<span class="string">'LineWidth'</span>,<span class="number">1.5</span>); <span class="comment">% 黑色线性曲线，曲线宽度为1.5，我通常使用的线宽</span></span><br><span class="line"><span class="built_in">hold</span> on </span><br><span class="line"><span class="built_in">plot</span>(x,y2,<span class="string">'Color'</span>,[<span class="number">0.7</span> <span class="number">0</span> <span class="number">0</span>],<span class="string">'LineWidth'</span>,<span class="number">1.5</span>); <span class="comment">% RGB的R为0.7即深红</span></span><br><span class="line"><span class="built_in">plot</span>(x,y3,<span class="string">'b:'</span>,<span class="string">'LineWidth'</span>,<span class="number">1.5</span>); <span class="comment">% 蓝色虚线的曲线</span></span><br><span class="line">grid on</span><br></pre></td></tr></table></figure><p>效果图如下：</p><p><img src="/../image/mat4.png" alt=""></p><h4 id="设置坐标轴、标题与图例"><a href="#设置坐标轴、标题与图例" class="headerlink" title="设置坐标轴、标题与图例"></a>设置坐标轴、标题与图例</h4><p>最后一个基础的命令，就是设置坐标轴与图例。这两个命令都十分简单，分别使用<code>xlabel(&#39;x轴名称&#39;)</code>与<code>legend(&#39;第1条曲线名称&#39;,&#39;第2条曲线名称&#39;,&#39;第3条曲线名称&#39;)</code>。当然也可以这样设置y轴，z轴都没问题。关于标题的设置，<code>title</code>命令就能搞定，但是matlab往往不支持中文的格式，也就是说如果你在标题、坐标轴或图例中出现中文，往往会引发乱码。我在网上找到了一个比较不错的办法，就是添加一条命令<code>set(gca,&#39;Fontname&#39;,&#39;Monospaced&#39;,&#39;Fontsize&#39;,10,&#39;FontWeight&#39;,&#39;bold&#39;);</code>便可解决无法用中文命令标题的问题，当然你使用英文就不需要这行命令了。btw，所有matlab的文字部分都支持的是latex语法。</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">clear,clc</span><br><span class="line">x = <span class="built_in">linspace</span>(<span class="number">0</span>,<span class="number">20</span>,<span class="number">1000</span>); </span><br><span class="line">y1 = <span class="number">2</span>*<span class="built_in">cos</span>(x);</span><br><span class="line">y2 = <span class="built_in">sin</span>(<span class="number">2</span>*x);</span><br><span class="line">y3 = <span class="number">3</span>*<span class="built_in">sin</span>(x);</span><br><span class="line"><span class="built_in">figure</span>(<span class="number">1</span>); </span><br><span class="line"><span class="built_in">plot</span>(x,y1,<span class="string">'k'</span>,<span class="string">'LineWidth'</span>,<span class="number">1.5</span>); <span class="comment">% 黑色线性曲线，曲线宽度为1.5，我通常使用的线宽</span></span><br><span class="line"><span class="built_in">hold</span> on </span><br><span class="line"><span class="built_in">plot</span>(x,y2,<span class="string">'Color'</span>,[<span class="number">0.7</span> <span class="number">0</span> <span class="number">0</span>],<span class="string">'LineWidth'</span>,<span class="number">1.5</span>); <span class="comment">% RGB的R为0.7即深红</span></span><br><span class="line"><span class="built_in">plot</span>(x,y3,<span class="string">'b:'</span>,<span class="string">'LineWidth'</span>,<span class="number">1.5</span>); <span class="comment">% 蓝色虚线的曲线</span></span><br><span class="line">grid on</span><br><span class="line">xlabel(<span class="string">'x'</span>); ylabel(<span class="string">'y'</span>);</span><br><span class="line"><span class="built_in">legend</span>(<span class="string">'y_1'</span>,<span class="string">'y_2'</span>,<span class="string">'y_3'</span>); </span><br><span class="line">set(gca,<span class="string">'Fontname'</span>,<span class="string">'Monospaced'</span>,<span class="string">'Fontsize'</span>,<span class="number">10</span>,<span class="string">'FontWeight'</span>,<span class="string">'bold'</span>);</span><br><span class="line">title(<span class="string">'例子：x\sim y_1,y_2,y_3'</span>);</span><br></pre></td></tr></table></figure><p>效果图如下图所示：</p><p><img src="/../image/mat5.png" alt=""></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最近更新了不少关于数学建模算法与机器学习的博客，今天我来写写关于科研制图的MATLAB常用命令，众所周知，在未来的科研生涯中，只要是学工科的同学们，MATLAB都是大家必学的工具之一，而发paper中的制图更是重中之重，虽然科研制图讲究一个&lt;strong&gt;“丑”&lt;/strong&gt;，但是不会画想必是不行的。本文应该是持续更新的，本博客我会总结一些较为细节处理的代码，如果你是个使用MATLAB科研制图的小白，我会强烈推荐&lt;a href=&quot;https://www.bilibili.com/video/BV1GJ41137UH?p=5&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;b站郭彦甫的MATLAB入门教程&lt;/a&gt;，是我特别推荐的视屏系列。当然现在python科研制图也十分流行了，之后我也会整理。&lt;/p&gt;
    
    </summary>
    
    
      <category term="科研路漫漫" scheme="http://yoursite.com/categories/%E7%A7%91%E7%A0%94%E8%B7%AF%E6%BC%AB%E6%BC%AB/"/>
    
      <category term="科研制图" scheme="http://yoursite.com/categories/%E7%A7%91%E7%A0%94%E8%B7%AF%E6%BC%AB%E6%BC%AB/%E7%A7%91%E7%A0%94%E5%88%B6%E5%9B%BE/"/>
    
    
      <category term="MATLAB" scheme="http://yoursite.com/tags/MATLAB/"/>
    
  </entry>
  
  <entry>
    <title>【降维模型】主成分分析PCA</title>
    <link href="http://yoursite.com/2020/07/10/%E3%80%90%E9%99%8D%E7%BB%B4%E6%A8%A1%E5%9E%8B%E3%80%91%E4%B8%BB%E6%88%90%E5%88%86%E5%88%86%E6%9E%90PCA/"/>
    <id>http://yoursite.com/2020/07/10/%E3%80%90%E9%99%8D%E7%BB%B4%E6%A8%A1%E5%9E%8B%E3%80%91%E4%B8%BB%E6%88%90%E5%88%86%E5%88%86%E6%9E%90PCA/</id>
    <published>2020-07-10T15:09:52.000Z</published>
    <updated>2020-08-27T14:24:31.686Z</updated>
    
    <content type="html"><![CDATA[<p><strong>主成分分析(Principal Component Analysis)</strong>的主要目的是希望用较少的变量去解释原来资料中的大部分变异，选出比原始特征值个数少的变量，构建能解释最终输出的新变量，即为主成分，简单而言，如果我们有题目给出了十几个变量制约的数学模型，我们便可通过PCA将其变化成为4个、5个变量制约的数学模型，这就是所谓的<strong>降维模型(Dimensionality Reduction Model)</strong>。</p><a id="more"></a><h3 id="数据压缩-Data-Compression"><a href="#数据压缩-Data-Compression" class="headerlink" title="数据压缩(Data Compression)"></a>数据压缩(Data Compression)</h3><p>数据压缩，其实我们可以把它理解为降维，这是一个狭义与广义的定义，我们首先来理解数据压缩的原理，比如我们有三个特征变量，现在我们希望仅用两个特征变量来反应数据特征。当然这是个非常简单的例子，在实际问题中，例如计算机视觉中，我们通常有上万个特征向量，我们也要有用PCA或白化等其他方法，对数据进行降维处理。而这就是PCA其中一个非常重要的作用。</p><p><img src="/../image/ml61.jpg" alt=""></p><h3 id="主成分维数设定-Number-of-principal-components"><a href="#主成分维数设定-Number-of-principal-components" class="headerlink" title="主成分维数设定(Number of principal components)"></a>主成分维数设定(Number of principal components)</h3><p>在我们的实际任务中，当我们需要对模型中的数据进行降维操作时，我们都要进行从$n$维到$k$维的转换，如何选取k维这个超参数，就是我们下面需要讨论的问题。事实上，我这里只写出如何实现选取k维数的方法，在这里我就不介绍内在原理了，如果感兴趣的可以自行去查阅相关资料。</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Sigma = (<span class="number">1</span>/m) * X' * X;</span><br><span class="line">[U, S, V] = svd(Sigma);</span><br><span class="line">Ureduce = U(:,<span class="number">1</span>:k);</span><br><span class="line">z = Ureduce' * x;</span><br></pre></td></tr></table></figure><p>核心的matlab代码仅有四行，其中</p><script type="math/tex; mode=display">Sigma = \frac{1}{m}\Sigma_{i=1}^{m}(x^{(i)})(x^{(i)})^T\\What\; we\; need \; to \; check\; : \frac{\Sigma_{i=1}^kS_{ii}}{\Sigma_{i=1}^mS_{ii}}\geq 0.99</script><p>这样我们通过选取k值去满足我们所需要的方程即可。当然降维的方法还有很多种，大家可以自行查阅。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;strong&gt;主成分分析(Principal Component Analysis)&lt;/strong&gt;的主要目的是希望用较少的变量去解释原来资料中的大部分变异，选出比原始特征值个数少的变量，构建能解释最终输出的新变量，即为主成分，简单而言，如果我们有题目给出了十几个变量制约的数学模型，我们便可通过PCA将其变化成为4个、5个变量制约的数学模型，这就是所谓的&lt;strong&gt;降维模型(Dimensionality Reduction Model)&lt;/strong&gt;。&lt;/p&gt;
    
    </summary>
    
    
      <category term="数学建模" scheme="http://yoursite.com/categories/%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1/"/>
    
      <category term="模型篇" scheme="http://yoursite.com/categories/%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1/%E6%A8%A1%E5%9E%8B%E7%AF%87/"/>
    
    
      <category term="PCA" scheme="http://yoursite.com/tags/PCA/"/>
    
  </entry>
  
  <entry>
    <title>【吴恩达笔记】PCA降维</title>
    <link href="http://yoursite.com/2020/07/10/%E3%80%90%E5%90%B4%E6%81%A9%E8%BE%BE%E7%AC%94%E8%AE%B0%E3%80%91PCA%E9%99%8D%E7%BB%B4/"/>
    <id>http://yoursite.com/2020/07/10/%E3%80%90%E5%90%B4%E6%81%A9%E8%BE%BE%E7%AC%94%E8%AE%B0%E3%80%91PCA%E9%99%8D%E7%BB%B4/</id>
    <published>2020-07-10T15:09:05.000Z</published>
    <updated>2020-08-27T14:26:57.417Z</updated>
    
    <content type="html"><![CDATA[<p><strong>主成分分析(Principal Component Analysis)</strong>的主要目的是希望用较少的变量去解释原来资料中的大部分变异，选出比原始特征值个数少的变量，构建能解释最终输出的新变量，即为主成分，简单而言，如果我们有题目给出了十几个变量制约的数学模型，我们便可通过PCA将其变化成为4个、5个变量制约的数学模型，这就是所谓的<strong>降维模型(Dimensionality Reduction Model)</strong>。</p><a id="more"></a><h3 id="数据压缩-Data-Compression"><a href="#数据压缩-Data-Compression" class="headerlink" title="数据压缩(Data Compression)"></a>数据压缩(Data Compression)</h3><p>数据压缩，其实我们可以把它理解为降维，这是一个狭义与广义的定义，我们首先来理解数据压缩的原理，比如我们有三个特征变量，现在我们希望仅用两个特征变量来反应数据特征。当然这是个非常简单的例子，在实际问题中，例如计算机视觉中，我们通常有上万个特征向量，我们也要有用PCA或白化等其他方法，对数据进行降维处理。而这就是PCA其中一个非常重要的作用。</p><p><img src="/../image/ml61.jpg" alt=""></p><h3 id="主成分维数设定-Number-of-principal-components"><a href="#主成分维数设定-Number-of-principal-components" class="headerlink" title="主成分维数设定(Number of principal components)"></a>主成分维数设定(Number of principal components)</h3><p>在我们的实际任务中，当我们需要对模型中的数据进行降维操作时，我们都要进行从$n$维到$k$维的转换，如何选取k维这个超参数，就是我们下面需要讨论的问题。事实上，我这里只写出如何实现选取k维数的方法，在这里我就不介绍内在原理了，如果感兴趣的可以自行去查阅相关资料。</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Sigma = (<span class="number">1</span>/m) * X' * X;</span><br><span class="line">[U, S, V] = svd(Sigma);</span><br><span class="line">Ureduce = U(:,<span class="number">1</span>:k);</span><br><span class="line">z = Ureduce' * x;</span><br></pre></td></tr></table></figure><p>核心的matlab代码仅有四行，其中</p><script type="math/tex; mode=display">Sigma = \frac{1}{m}\Sigma_{i=1}^{m}(x^{(i)})(x^{(i)})^T\\What\; we\; need \; to \; check\; : \frac{\Sigma_{i=1}^kS_{ii}}{\Sigma_{i=1}^mS_{ii}}\geq 0.99</script><p>这样我们通过选取k值去满足我们所需要的方程即可。当然降维的方法还有很多种，大家可以自行查阅。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;strong&gt;主成分分析(Principal Component Analysis)&lt;/strong&gt;的主要目的是希望用较少的变量去解释原来资料中的大部分变异，选出比原始特征值个数少的变量，构建能解释最终输出的新变量，即为主成分，简单而言，如果我们有题目给出了十几个变量制约的数学模型，我们便可通过PCA将其变化成为4个、5个变量制约的数学模型，这就是所谓的&lt;strong&gt;降维模型(Dimensionality Reduction Model)&lt;/strong&gt;。&lt;/p&gt;
    
    </summary>
    
    
      <category term="机器学习" scheme="http://yoursite.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="吴恩达课程笔记" scheme="http://yoursite.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%90%B4%E6%81%A9%E8%BE%BE%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="PCA" scheme="http://yoursite.com/tags/PCA/"/>
    
  </entry>
  
  <entry>
    <title>【聚类算法】K-means无监督学习</title>
    <link href="http://yoursite.com/2020/07/06/%E3%80%90%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95%E3%80%91K-means%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/"/>
    <id>http://yoursite.com/2020/07/06/%E3%80%90%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95%E3%80%91K-means%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/</id>
    <published>2020-07-05T19:48:34.000Z</published>
    <updated>2020-07-10T07:12:55.123Z</updated>
    
    <content type="html"><![CDATA[<p>之前我们讨论过关于线性回归、Logistic回归与SVM等模型与算法，然而之前讨论的事物在机器学习中，我们都统称为监督学习。在这之后，我将花两篇博客的内容来介绍一些无监督学习的算法，机器学习算法广义而言分为两类：监督学习与无监督学习，其判断标准其实就是我们所拥有的样本是否含有标签信息。当然，现在的学者们都专注在弱监督学习领域，一个更适用于工业的学习方法。下面我将会介绍无监督学习即不含标签的样本，并对其进行分类，我们称为<strong>聚类</strong>。</p><a id="more"></a><h3 id="聚类问题-Clustering"><a href="#聚类问题-Clustering" class="headerlink" title="聚类问题(Clustering)"></a>聚类问题(Clustering)</h3><p>我们经常在数学建模竞赛中，会遇到不少类似这样的问题，比如拍照定价给城市分类(参考国赛2017B)，球员之间联系的紧密性研究(参考今年2020美赛D题)等等，这些就是非常明显的聚类问题，我们再举几个平时生活的例子，比如市场消费调研，社交网络分析，衣服尺码分布等等，这些问题所给出的样本，不像之前监督学习问题中的垃圾邮件的判别或房价预测等问题，他们并没有带标签，而我们把这样没有带标签的样本进行算法学习，由参数体现出的分类情况成为<strong>聚类</strong>，也就是<strong>Clustering</strong>。</p><h3 id="K-means聚类算法"><a href="#K-means聚类算法" class="headerlink" title="K-means聚类算法"></a>K-means聚类算法</h3><p>这里我们介绍一种典型的聚类算法，就是所谓的<strong>K-means聚类算法</strong>，下面我给出这个算法流程，首先我们给出无标签的绿色样本，我们要求把样本分为两个聚类：</p><p><img src="/../image/ml51.jpg" alt=""></p><p><img src="/../image/ml52.jpg" alt=""></p><p>我们先随机生成两个<strong>聚类中心(cluster centroids)</strong>，然后将离它近的点标注成和它一样的颜色，根据红色/蓝色所有点再取它们的均值位置作为新的聚类中心，如此反复，直到收敛到最优解停止。</p><p>这个算法其实原理就我所说的那样，非常简单。下面是整个一般性算法的流程，也就是分成k类的情况下：</p><script type="math/tex; mode=display">\begin{align}Randomly&\ initialize\ K\ cluster\ centroids\ \mu_1,\mu_2,...,\mu_K\in \mathbb{R}^n\\for\ iter&=1\ to \ 100\\for&\ i=1\ to\ m\\c&^{(i)}:=index\ (from\ 1\ to\ K)\ of\ cluster\ centroid\ closest\ to\ x^{(1)}\\for&\ k=1\ to\ K\\\mu&_k:=average\ (mean)\ of\ points\ assigned\ to\ cluster\ k\\\end{align}</script><p>这里我们举的例子是迭代100次，其实K-means算法中主要就是迭代的思想，至于具体迭代到什么时候截止，这个问题我之后会说明清楚。</p><h3 id="优化目标-Optimization-Objective"><a href="#优化目标-Optimization-Objective" class="headerlink" title="优化目标(Optimization Objective)"></a>优化目标(Optimization Objective)</h3><p>在决定优化目标之前，我们先确定几个变量的名称：</p><ul><li>$c^{(i)}$=index of cluster (1,2,…,K) to which example $x^{(i)}$ is currently assigned</li><li>$\mu_k$=cluster centroid k ($\mu_k\in \mathbb{R}^n$)</li><li>$\mu_{c^{(i)}}$=cluster centroid of cluster to which example $x^{(i)}$ has been assigned</li></ul><p>我来简单解释下几个变量的含义，对于K-means聚类算法，最重要的是两个过程：</p><ul><li>S1：初始化K个聚类中心$\mu_k$</li><li>S2：计算与每个点即$x^{(i)}$距离最近的聚类中心，将每个点所属的聚类中心编号标记为$c^{(i)}$，这样每个点的聚类中心的位置就是$\mu_{c^{(i)}}$了。</li><li>S3：计算从属于同一个聚类中心$c^{(i)}$的均值位置，并将它作为新的聚类中心位置，即$\mu_{c^{(i)}}$。</li><li>S4：重复步骤S2和S3，进行迭代，收敛至最优解。</li></ul><p>这样我们便可以很轻易地写出我们的代价函数，而我们的优化目标则是最小化代价函数：</p><script type="math/tex; mode=display">min\ J(c^{(1)},...,c^{(m)},\mu_1,...,\mu_K)=\frac{1}{m}\sum^{m}_{i=1}\|x^{(i)}-\mu_{c^{(i)}}\|^2</script><p>代价函数表示的就是每个点距离聚类中心距离的平方和的均值。</p><h3 id="随机初始化-Random-Initialization"><a href="#随机初始化-Random-Initialization" class="headerlink" title="随机初始化(Random Initialization)"></a>随机初始化(Random Initialization)</h3><h4 id="如何随机选择初始点？"><a href="#如何随机选择初始点？" class="headerlink" title="如何随机选择初始点？"></a>如何随机选择初始点？</h4><p>在K-means算法中，我们还有一个悬而未决的问题，到现在也没有说明。那就是如何初始化K个聚类中心，实际上我能给出最好的答案就是，按照样本来选择，随机选择K个样本作为初始化的点，但是这样确实也会出现一些问题：</p><p><img src="/../image/ml53.jpg" alt=""></p><p>如上图所示，假设我们的K=2，那我们随机选取两个样本作为初始化的起点，我们可以看到上述两种情况，第二种随机的选择很明显效果很糟糕，甚至有可能因此得到不是我们所期望的聚类。</p><p>很遗憾，对于这种问题，我唯一的解决办法就是尝试多次初始化，并分别迭代到最优再进行比较，由于本人太菜，除此之外我可能不能分享更好理解的办法了。</p><h4 id="如何选择聚类的数量K？"><a href="#如何选择聚类的数量K？" class="headerlink" title="如何选择聚类的数量K？"></a>如何选择聚类的数量K？</h4><p>在聚类问题中，大部分情况我们都是能知道我们需要分成几类，或者说我们希望将整体样本分为几类的，这时候可以根据实际要求选择K，比如为不同的受众定制衣服，假设我们就三个尺码：S，M，L。那么很容易，我们得到我们希望的K是3，进行计算即可。</p><p>在很少的情况下，我们需要手动选择一个最优的聚类种数，这是个非常复杂的问题，很遗憾地说，到目前为止都没有什么好办法，我这里只介绍一种方法：<strong>Elbow method</strong></p><p><img src="/../image/ml54.jpg" alt=""></p><p>我们分别试验不同的K，并画出最小代价函数的折线图，如果是左边图的情况下，那么恭喜你们，随着收敛的渐渐平缓，毫无疑问K=3将会是聚类种数的最好选择。但是，往往我们的实际问题中，我们遇到的折线图都是右边这样的情况，其实你通过图像很难得出K的最优解，因为曲线一直是平缓下降的。这个时候，还是多问问自己，关于此题聚类算法应用的目的，从而自己规定聚类的数量吧。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;之前我们讨论过关于线性回归、Logistic回归与SVM等模型与算法，然而之前讨论的事物在机器学习中，我们都统称为监督学习。在这之后，我将花两篇博客的内容来介绍一些无监督学习的算法，机器学习算法广义而言分为两类：监督学习与无监督学习，其判断标准其实就是我们所拥有的样本是否含有标签信息。当然，现在的学者们都专注在弱监督学习领域，一个更适用于工业的学习方法。下面我将会介绍无监督学习即不含标签的样本，并对其进行分类，我们称为&lt;strong&gt;聚类&lt;/strong&gt;。&lt;/p&gt;
    
    </summary>
    
    
      <category term="数学建模" scheme="http://yoursite.com/categories/%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1/"/>
    
      <category term="算法篇" scheme="http://yoursite.com/categories/%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1/%E7%AE%97%E6%B3%95%E7%AF%87/"/>
    
    
      <category term="聚类" scheme="http://yoursite.com/tags/%E8%81%9A%E7%B1%BB/"/>
    
  </entry>
  
  <entry>
    <title>【吴恩达笔记】无监督学习K-means聚类算法</title>
    <link href="http://yoursite.com/2020/07/06/%E3%80%90%E5%90%B4%E6%81%A9%E8%BE%BE%E7%AC%94%E8%AE%B0%E3%80%91%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0K-means%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95/"/>
    <id>http://yoursite.com/2020/07/06/%E3%80%90%E5%90%B4%E6%81%A9%E8%BE%BE%E7%AC%94%E8%AE%B0%E3%80%91%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0K-means%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95/</id>
    <published>2020-07-05T19:48:02.000Z</published>
    <updated>2020-07-10T07:13:05.260Z</updated>
    
    <content type="html"><![CDATA[<p>之前我们讨论过关于线性回归、Logistic回归与SVM等模型与算法，然而之前讨论的事物在机器学习中，我们都统称为监督学习。在这之后，我将花两篇博客的内容来介绍一些无监督学习的算法，机器学习算法广义而言分为两类：监督学习与无监督学习，其判断标准其实就是我们所拥有的样本是否含有标签信息。当然，现在的学者们都专注在弱监督学习领域，一个更适用于工业的学习方法。下面我将会介绍无监督学习即不含标签的样本，并对其进行分类，我们称为<strong>聚类</strong>。</p><a id="more"></a><h3 id="聚类问题-Clustering"><a href="#聚类问题-Clustering" class="headerlink" title="聚类问题(Clustering)"></a>聚类问题(Clustering)</h3><p>我们经常在数学建模竞赛中，会遇到不少类似这样的问题，比如拍照定价给城市分类(参考国赛2017B)，球员之间联系的紧密性研究(参考今年2020美赛D题)等等，这些就是非常明显的聚类问题，我们再举几个平时生活的例子，比如市场消费调研，社交网络分析，衣服尺码分布等等，这些问题所给出的样本，不像之前监督学习问题中的垃圾邮件的判别或房价预测等问题，他们并没有带标签，而我们把这样没有带标签的样本进行算法学习，由参数体现出的分类情况成为<strong>聚类</strong>，也就是<strong>Clustering</strong>。</p><h3 id="K-means聚类算法"><a href="#K-means聚类算法" class="headerlink" title="K-means聚类算法"></a>K-means聚类算法</h3><p>这里我们介绍一种典型的聚类算法，就是所谓的<strong>K-means聚类算法</strong>，下面我给出这个算法流程，首先我们给出无标签的绿色样本，我们要求把样本分为两个聚类：</p><p><img src="/../image/ml51.jpg" alt=""></p><p><img src="/../image/ml52.jpg" alt=""></p><p>我们先随机生成两个<strong>聚类中心(cluster centroids)</strong>，然后将离它近的点标注成和它一样的颜色，根据红色/蓝色所有点再取它们的均值位置作为新的聚类中心，如此反复，直到收敛到最优解停止。</p><p>这个算法其实原理就我所说的那样，非常简单。下面是整个一般性算法的流程，也就是分成k类的情况下：</p><script type="math/tex; mode=display">\begin{align}Randomly&\ initialize\ K\ cluster\ centroids\ \mu_1,\mu_2,...,\mu_K\in \mathbb{R}^n\\for\ iter&=1\ to \ 100\\for&\ i=1\ to\ m\\c&^{(i)}:=index\ (from\ 1\ to\ K)\ of\ cluster\ centroid\ closest\ to\ x^{(1)}\\for&\ k=1\ to\ K\\\mu&_k:=average\ (mean)\ of\ points\ assigned\ to\ cluster\ k\\\end{align}</script><p>这里我们举的例子是迭代100次，其实K-means算法中主要就是迭代的思想，至于具体迭代到什么时候截止，这个问题我之后会说明清楚。</p><h3 id="优化目标-Optimization-Objective"><a href="#优化目标-Optimization-Objective" class="headerlink" title="优化目标(Optimization Objective)"></a>优化目标(Optimization Objective)</h3><p>在决定优化目标之前，我们先确定几个变量的名称：</p><ul><li>$c^{(i)}$=index of cluster (1,2,…,K) to which example $x^{(i)}$ is currently assigned</li><li>$\mu_k$=cluster centroid k ($\mu_k\in \mathbb{R}^n$)</li><li>$\mu_{c^{(i)}}$=cluster centroid of cluster to which example $x^{(i)}$ has been assigned</li></ul><p>我来简单解释下几个变量的含义，对于K-means聚类算法，最重要的是两个过程：</p><ul><li>S1：初始化K个聚类中心$\mu_k$</li><li>S2：计算与每个点即$x^{(i)}$距离最近的聚类中心，将每个点所属的聚类中心编号标记为$c^{(i)}$，这样每个点的聚类中心的位置就是$\mu_{c^{(i)}}$了。</li><li>S3：计算从属于同一个聚类中心$c^{(i)}$的均值位置，并将它作为新的聚类中心位置，即$\mu_{c^{(i)}}$。</li><li>S4：重复步骤S2和S3，进行迭代，收敛至最优解。</li></ul><p>这样我们便可以很轻易地写出我们的代价函数，而我们的优化目标则是最小化代价函数：</p><script type="math/tex; mode=display">min\ J(c^{(1)},...,c^{(m)},\mu_1,...,\mu_K)=\frac{1}{m}\sum^{m}_{i=1}\|x^{(i)}-\mu_{c^{(i)}}\|^2</script><p>代价函数表示的就是每个点距离聚类中心距离的平方和的均值。</p><h3 id="随机初始化-Random-Initialization"><a href="#随机初始化-Random-Initialization" class="headerlink" title="随机初始化(Random Initialization)"></a>随机初始化(Random Initialization)</h3><h4 id="如何随机选择初始点？"><a href="#如何随机选择初始点？" class="headerlink" title="如何随机选择初始点？"></a>如何随机选择初始点？</h4><p>在K-means算法中，我们还有一个悬而未决的问题，到现在也没有说明。那就是如何初始化K个聚类中心，实际上我能给出最好的答案就是，按照样本来选择，随机选择K个样本作为初始化的点，但是这样确实也会出现一些问题：</p><p><img src="/../image/ml53.jpg" alt=""></p><p>如上图所示，假设我们的K=2，那我们随机选取两个样本作为初始化的起点，我们可以看到上述两种情况，第二种随机的选择很明显效果很糟糕，甚至有可能因此得到不是我们所期望的聚类。</p><p>很遗憾，对于这种问题，我唯一的解决办法就是尝试多次初始化，并分别迭代到最优再进行比较，由于本人太菜，除此之外我可能不能分享更好理解的办法了。</p><h4 id="如何选择聚类的数量K？"><a href="#如何选择聚类的数量K？" class="headerlink" title="如何选择聚类的数量K？"></a>如何选择聚类的数量K？</h4><p>在聚类问题中，大部分情况我们都是能知道我们需要分成几类，或者说我们希望将整体样本分为几类的，这时候可以根据实际要求选择K，比如为不同的受众定制衣服，假设我们就三个尺码：S，M，L。那么很容易，我们得到我们希望的K是3，进行计算即可。</p><p>在很少的情况下，我们需要手动选择一个最优的聚类种数，这是个非常复杂的问题，很遗憾地说，到目前为止都没有什么好办法，我这里只介绍一种方法：<strong>Elbow method</strong></p><p><img src="/../image/ml54.jpg" alt=""></p><p>我们分别试验不同的K，并画出最小代价函数的折线图，如果是左边图的情况下，那么恭喜你们，随着收敛的渐渐平缓，毫无疑问K=3将会是聚类种数的最好选择。但是，往往我们的实际问题中，我们遇到的折线图都是右边这样的情况，其实你通过图像很难得出K的最优解，因为曲线一直是平缓下降的。这个时候，还是多问问自己，关于此题聚类算法应用的目的，从而自己规定聚类的数量吧。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;之前我们讨论过关于线性回归、Logistic回归与SVM等模型与算法，然而之前讨论的事物在机器学习中，我们都统称为监督学习。在这之后，我将花两篇博客的内容来介绍一些无监督学习的算法，机器学习算法广义而言分为两类：监督学习与无监督学习，其判断标准其实就是我们所拥有的样本是否含有标签信息。当然，现在的学者们都专注在弱监督学习领域，一个更适用于工业的学习方法。下面我将会介绍无监督学习即不含标签的样本，并对其进行分类，我们称为&lt;strong&gt;聚类&lt;/strong&gt;。&lt;/p&gt;
    
    </summary>
    
    
      <category term="机器学习" scheme="http://yoursite.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="吴恩达课程笔记" scheme="http://yoursite.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%90%B4%E6%81%A9%E8%BE%BE%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="Kmeans" scheme="http://yoursite.com/tags/Kmeans/"/>
    
  </entry>
  
  <entry>
    <title>【吴恩达笔记】支持向量机SVM</title>
    <link href="http://yoursite.com/2020/07/04/%E3%80%90%E5%90%B4%E6%81%A9%E8%BE%BE%E7%AC%94%E8%AE%B0%E3%80%91%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BASVM/"/>
    <id>http://yoursite.com/2020/07/04/%E3%80%90%E5%90%B4%E6%81%A9%E8%BE%BE%E7%AC%94%E8%AE%B0%E3%80%91%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BASVM/</id>
    <published>2020-07-04T11:01:10.000Z</published>
    <updated>2020-07-04T05:18:11.567Z</updated>
    
    <content type="html"><![CDATA[<p><strong>Support Vector Machines(简称SVM)支持向量机</strong>是机器学习中非常重要的一种算法，一般用于分类与判别，你可以能还会见到<strong>Support Vector Classification(简称SVC)、Support Vector Regression(简称SVR)</strong>，分别用于分类与回归，别担心他们的内理是一模一样的，只是功能不同而进行了划分罢了。</p><a id="more"></a><h3 id="优化目标-Optimization-Objective"><a href="#优化目标-Optimization-Objective" class="headerlink" title="优化目标(Optimization Objective)"></a>优化目标(Optimization Objective)</h3><p>我们先从Logistic回归说起，我们知道在Logistic回归中，Sigmoid函数的作用$z=\theta^Tx$，如果我们需要让$y=1$，那我们就想要$h(x)\approx1$，即$z\gg0$，反之则是，$z\ll0$。下面我们为远大于和远小于划定一定的界限，首先我们还是以代价函数的例子来说明，我们之前定义了：</p><script type="math/tex; mode=display">Cost(h(x),y)=-ylog\frac{1}{1+e^{-\theta^Tx}}-(1-y)log\left(1-\frac{1}{1+e^{-\theta^Tx}}\right)</script><p>我们分别画出当$y=0,1$时的函数图像：</p><p><img src="/../image/ml41.jpg" alt=""></p><p>我们可以很明显地看出当$y=1,z&gt;1$时，代价z就差不多变成0了，反之则是$z&lt;-1$。这里注意一下，关于1和-1，基本是我们约定俗成的，请大家不用过分在意。于是我们得到了新的代价，在机器学习，我们把它成为支持向量：</p><script type="math/tex; mode=display">\begin{align}cost_1(z)&=0 \text{ if } z>1\\cost_0(z)&=0 \text{ if } z<-1\end{align}</script><p>下面我们重写SVM的整体代价函数，我们加入了正则项，并与logistic作对比：</p><script type="math/tex; mode=display">\begin{align}Logistic: J(\theta)&=min\frac{1}{m}[\sum_{i=1}^my^{(i)}\left(-logh(x^{(i)})\right)+(1-y^{(i)})\left(-log(1-h(x^{(i)}))\right)]+\frac{\lambda}{2m}\sum_{j=1}^n\theta_j^2\\SVM: J(\theta)&=minC\sum_{i=1}^m[y^{(i)}cost_1(\theta^Tx^{(i)})+(1-y^{(i)})cost_0(\theta^Tx^{(i)})]+\frac{1}{2}\sum_{i=1}^n\theta_j^2\end{align}</script><p>我们可以看出SVM中有一个常数C，没有关系，你可以把他当做和正则化参数一样的东西，用于调整权重的比例，防止过拟合的问题。这就是SVM的优化目标，即代价函数。</p><h3 id="大间隔学习-Large-Margin-Learning"><a href="#大间隔学习-Large-Margin-Learning" class="headerlink" title="大间隔学习(Large Margin Learning)"></a>大间隔学习(Large Margin Learning)</h3><p>支持向量机还有一个名称，就是大间隔学习，下面我会用可视化的方式来告诉你为何它是大间隔学习，以及为何它的效果要优于我们的Logistic回归。假设我们有一个二分类的样本，如下图所示：</p><p><img src="/../image/ml42.jpg" alt=""></p><p>在这里分类问题中，L1和L2是我们Logsitic回归可能得到的决策界限，可以看出的是，虽然这两条直线，确实分开了两个样本，但是分类效果并不太好。而支持向量机划分的决策界限，则是S1，其中S2和S3为初始划定界限，最终选择S1作为决策界限，而S1与S2、S3的距离被称为Margin。这就是我们称SVM为大间隔学习的原因，其中关于SVM为何能做到这样的原因，就牵扯到了其背后的数学原理，在这里不做展开，比较复杂，建议基础扎实后看西瓜书或<a href="http://blog.pluskid.org/" target="_blank" rel="noopener">我老板朋友Free Mind的博客</a>。ps：之前听说有位学长面试时手推SVM，被lamda录取了。</p><h3 id="核函数-Kernel"><a href="#核函数-Kernel" class="headerlink" title="核函数(Kernel)"></a>核函数(Kernel)</h3><p>其实核函数核方法这些东西在所有的模型算法中都能应用到，但是其在SVM中的效果明显，所以核函数常常后来和SVM一起出现。我们在解决非线性问题的时候，常常会为假设函数的选择而困扰，选择单变量一次项$x_1$，还是单变量高次项$x_1^n$，还是选择多变量的积$x_1x_2x_3$，这常常会给我们的分类问题的解决造成障碍，于是我们可以得到一个较为统一的式子：</p><script type="math/tex; mode=display">h_{\theta}(x)=\theta_0+\theta_1f_1+\theta_2f_2+\theta_3f_3+...</script><p>下面我们就来谈谈如何选择这项通用式子中的$f_1,f_2,f_3$。对于给定的特征向量x，我们定义三个坐标点$l^{(1)},l^{(2)},l^{(3)}$。我们以此来决定通向式中的三个权重：</p><script type="math/tex; mode=display">\begin{align}f_1=similarity(x,l^{(1)})=exp(-\frac{\left\|x-l^{(1)}\right\|^2}{2\sigma^2})\\f_2=similarity(x,l^{(2)})=exp(-\frac{\left\|x-l^{(2)}\right\|^2}{2\sigma^2})\\f_3=similarity(x,l^{(3)})=exp(-\frac{\left\|x-l^{(3)}\right\|^2}{2\sigma^2})\end{align}</script><p>其中similarity函数就是我们所经常使用<strong>高斯核函数(Gaussion Kernels)</strong>，如果特征值离我们的定义坐标点越近，则$f\approx1$，反之则是$f\approx0 $。</p><p>简单说说，我们如何选择坐标点$l^{(1)},l^{(2)},l^{(3)},…$，我通常的选择方法笔记比较简单(当然还有很多复杂的选择方法)，比如我们有m个特征向量样本即$x^{(1)},x^{(2)},…,x^{(m)}$。</p><p>那我们便选择m个坐标点，$l^{(1)}=x^{(1)},l^{(2)}=x^{(2)},…,l^{(m)}=x^{(m)}$。一般而言，我会这么选择。然而核函数还有很多种，我这里列举一些：</p><ul><li>String kernel</li><li>chi-square kernel</li><li>histogram intersection kernel</li></ul><p>不过最常用且较为容易的还是高斯核函数。</p><h3 id="与Logistic如何选择"><a href="#与Logistic如何选择" class="headerlink" title="与Logistic如何选择"></a>与Logistic如何选择</h3><p>我们假设$n=number\text{ }of\text{ }features(x\in\mathbb{R}^{n+1}),m=number\;of\;trainingg\;examples$。</p><ul><li>如果n相对于m来说非常大：我们选用Logistic回归，或者不用核函数的SVM(不用核函数就相当于线性核函数Linear Kernel)。</li><li>如果n比较小，m中等：我们选用高斯核函数的SVM。</li><li>如果n小，m大：那我们需要增加特征向量的种类，然后同理第一种情况</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;strong&gt;Support Vector Machines(简称SVM)支持向量机&lt;/strong&gt;是机器学习中非常重要的一种算法，一般用于分类与判别，你可以能还会见到&lt;strong&gt;Support Vector Classification(简称SVC)、Support Vector Regression(简称SVR)&lt;/strong&gt;，分别用于分类与回归，别担心他们的内理是一模一样的，只是功能不同而进行了划分罢了。&lt;/p&gt;
    
    </summary>
    
    
      <category term="机器学习" scheme="http://yoursite.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="吴恩达课程笔记" scheme="http://yoursite.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%90%B4%E6%81%A9%E8%BE%BE%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="SVM" scheme="http://yoursite.com/tags/SVM/"/>
    
  </entry>
  
  <entry>
    <title>【分类与判别算法】支持向量机SVM</title>
    <link href="http://yoursite.com/2020/07/04/%E3%80%90%E5%88%86%E7%B1%BB%E4%B8%8E%E5%88%A4%E5%88%AB%E7%AE%97%E6%B3%95%E3%80%91%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BASVM/"/>
    <id>http://yoursite.com/2020/07/04/%E3%80%90%E5%88%86%E7%B1%BB%E4%B8%8E%E5%88%A4%E5%88%AB%E7%AE%97%E6%B3%95%E3%80%91%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BASVM/</id>
    <published>2020-07-04T11:00:36.000Z</published>
    <updated>2020-07-04T05:18:51.239Z</updated>
    
    <content type="html"><![CDATA[<p>终于讲到了算法的内容了，<strong>Support Vector Machines(简称SVM)支持向量机</strong>是机器学习与数学建模中非常重要的一种算法，一般用于分类与判别，你可以能还会见到<strong>Support Vector Classification(简称SVC)、Support Vector Regression(简称SVR)</strong>，分别用于分类与回归，别担心他们的内理是一模一样的，只是功能不同而进行了划分罢了。</p><a id="more"></a><h3 id="优化目标-Optimization-Objective"><a href="#优化目标-Optimization-Objective" class="headerlink" title="优化目标(Optimization Objective)"></a>优化目标(Optimization Objective)</h3><p>我们先从Logistic回归说起，我们知道在Logistic回归中，Sigmoid函数的作用$z=\theta^Tx$，如果我们需要让$y=1$，那我们就想要$h(x)\approx1$，即$z\gg0$，反之则是，$z\ll0$。下面我们为远大于和远小于划定一定的界限，首先我们还是以代价函数的例子来说明，我们之前定义了：</p><script type="math/tex; mode=display">Cost(h(x),y)=-ylog\frac{1}{1+e^{-\theta^Tx}}-(1-y)log\left(1-\frac{1}{1+e^{-\theta^Tx}}\right)</script><p>我们分别画出当$y=0,1$时的函数图像：</p><p><img src="/../image/ml41.jpg" alt=""></p><p>我们可以很明显地看出当$y=1,z&gt;1$时，代价z就差不多变成0了，反之则是$z&lt;-1$。这里注意一下，关于1和-1，基本是我们约定俗成的，请大家不用过分在意。于是我们得到了新的代价，在机器学习，我们把它成为支持向量：</p><script type="math/tex; mode=display">\begin{align}cost_1(z)&=0 \text{ if } z>1\\cost_0(z)&=0 \text{ if } z<-1\end{align}</script><p>下面我们重写SVM的整体代价函数，我们加入了正则项，并与logistic作对比：</p><script type="math/tex; mode=display">\begin{align}Logistic: J(\theta)&=min\frac{1}{m}[\sum_{i=1}^my^{(i)}\left(-logh(x^{(i)})\right)+(1-y^{(i)})\left(-log(1-h(x^{(i)}))\right)]+\frac{\lambda}{2m}\sum_{j=1}^n\theta_j^2\\SVM: J(\theta)&=minC\sum_{i=1}^m[y^{(i)}cost_1(\theta^Tx^{(i)})+(1-y^{(i)})cost_0(\theta^Tx^{(i)})]+\frac{1}{2}\sum_{i=1}^n\theta_j^2\end{align}</script><p>我们可以看出SVM中有一个常数C，没有关系，你可以把他当做和正则化参数一样的东西，用于调整权重的比例，防止过拟合的问题。这就是SVM的优化目标，即代价函数。</p><h3 id="大间隔学习-Large-Margin-Learning"><a href="#大间隔学习-Large-Margin-Learning" class="headerlink" title="大间隔学习(Large Margin Learning)"></a>大间隔学习(Large Margin Learning)</h3><p>支持向量机还有一个名称，就是大间隔学习，下面我会用可视化的方式来告诉你为何它是大间隔学习，以及为何它的效果要优于我们的Logistic回归。假设我们有一个二分类的样本，如下图所示：</p><p><img src="/../image/ml42.jpg" alt=""></p><p>在这里分类问题中，L1和L2是我们Logsitic回归可能得到的决策界限，可以看出的是，虽然这两条直线，确实分开了两个样本，但是分类效果并不太好。而支持向量机划分的决策界限，则是S1，其中S2和S3为初始划定界限，最终选择S1作为决策界限，而S1与S2、S3的距离被称为Margin。这就是我们称SVM为大间隔学习的原因，其中关于SVM为何能做到这样的原因，就牵扯到了其背后的数学原理，在这里不做展开，比较复杂，建议基础扎实后看西瓜书或<a href="http://blog.pluskid.org/" target="_blank" rel="noopener">我老板朋友Free Mind的博客</a>。ps：之前听说有位学长面试时手推SVM，被lamda录取了。</p><h3 id="核函数-Kernel"><a href="#核函数-Kernel" class="headerlink" title="核函数(Kernel)"></a>核函数(Kernel)</h3><p>其实核函数核方法这些东西在所有的模型算法中都能应用到，但是其在SVM中的效果明显，所以核函数常常后来和SVM一起出现。我们在解决非线性问题的时候，常常会为假设函数的选择而困扰，选择单变量一次项$x_1$，还是单变量高次项$x_1^n$，还是选择多变量的积$x_1x_2x_3$，这常常会给我们的分类问题的解决造成障碍，于是我们可以得到一个较为统一的式子：</p><script type="math/tex; mode=display">h_{\theta}(x)=\theta_0+\theta_1f_1+\theta_2f_2+\theta_3f_3+...</script><p>下面我们就来谈谈如何选择这项通用式子中的$f_1,f_2,f_3$。对于给定的特征向量x，我们定义三个坐标点$l^{(1)},l^{(2)},l^{(3)}$。我们以此来决定通向式中的三个权重：</p><script type="math/tex; mode=display">\begin{align}f_1=similarity(x,l^{(1)})=exp(-\frac{\left\|x-l^{(1)}\right\|^2}{2\sigma^2})\\f_2=similarity(x,l^{(2)})=exp(-\frac{\left\|x-l^{(2)}\right\|^2}{2\sigma^2})\\f_3=similarity(x,l^{(3)})=exp(-\frac{\left\|x-l^{(3)}\right\|^2}{2\sigma^2})\end{align}</script><p>其中similarity函数就是我们所经常使用<strong>高斯核函数(Gaussion Kernels)</strong>，如果特征值离我们的定义坐标点越近，则$f\approx1$，反之则是$f\approx0 $。</p><p>简单说说，我们如何选择坐标点$l^{(1)},l^{(2)},l^{(3)},…$，我通常的选择方法笔记比较简单(当然还有很多复杂的选择方法)，比如我们有m个特征向量样本即$x^{(1)},x^{(2)},…,x^{(m)}$。</p><p>那我们便选择m个坐标点，$l^{(1)}=x^{(1)},l^{(2)}=x^{(2)},…,l^{(m)}=x^{(m)}$。一般而言，我会这么选择。然而核函数还有很多种，我这里列举一些：</p><ul><li>String kernel</li><li>chi-square kernel</li><li>histogram intersection kernel</li></ul><p>不过最常用且较为容易的还是高斯核函数。</p><h3 id="与Logistic如何选择"><a href="#与Logistic如何选择" class="headerlink" title="与Logistic如何选择"></a>与Logistic如何选择</h3><p>我们假设$n=number\text{ }of\text{ }features(x\in\mathbb{R}^{n+1}),m=number\;of\;trainingg\;examples$。</p><ul><li>如果n相对于m来说非常大：我们选用Logistic回归，或者不用核函数的SVM(不用核函数就相当于线性核函数Linear Kernel)。</li><li>如果n比较小，m中等：我们选用高斯核函数的SVM。</li><li>如果n小，m大：那我们需要增加特征向量的种类，然后同理第一种情况</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;终于讲到了算法的内容了，&lt;strong&gt;Support Vector Machines(简称SVM)支持向量机&lt;/strong&gt;是机器学习与数学建模中非常重要的一种算法，一般用于分类与判别，你可以能还会见到&lt;strong&gt;Support Vector Classification(简称SVC)、Support Vector Regression(简称SVR)&lt;/strong&gt;，分别用于分类与回归，别担心他们的内理是一模一样的，只是功能不同而进行了划分罢了。&lt;/p&gt;
    
    </summary>
    
    
      <category term="数学建模" scheme="http://yoursite.com/categories/%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1/"/>
    
      <category term="算法篇" scheme="http://yoursite.com/categories/%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1/%E7%AE%97%E6%B3%95%E7%AF%87/"/>
    
    
      <category term="SVM" scheme="http://yoursite.com/tags/SVM/"/>
    
  </entry>
  
  <entry>
    <title>【吴恩达笔记】正则化</title>
    <link href="http://yoursite.com/2020/07/03/%E3%80%90%E5%90%B4%E6%81%A9%E8%BE%BE%E7%AC%94%E8%AE%B0%E3%80%91%E6%AD%A3%E5%88%99%E5%8C%96/"/>
    <id>http://yoursite.com/2020/07/03/%E3%80%90%E5%90%B4%E6%81%A9%E8%BE%BE%E7%AC%94%E8%AE%B0%E3%80%91%E6%AD%A3%E5%88%99%E5%8C%96/</id>
    <published>2020-07-03T11:44:01.000Z</published>
    <updated>2020-07-04T05:17:53.202Z</updated>
    
    <content type="html"><![CDATA[<p>关于<strong>Regularization(正则化)</strong>的问题，这实际上在数学模型优化以及机器学习系统设计中，都是特别难处理的问题，所以我这里也只能用我浅显的认知和大家讲述正则化中最基本的知识。</p><a id="more"></a><h3 id="关于拟合：Underfitting-VS-Overfitting"><a href="#关于拟合：Underfitting-VS-Overfitting" class="headerlink" title="关于拟合：Underfitting VS Overfitting"></a>关于拟合：Underfitting VS Overfitting</h3><p><img src="/../image/ml31.jpg" alt=""></p><p>还是之前关于房价的例子，如果我们尝试用不同的函数进行拟合，选用一次函数，我们会发现，我们并没有完成一个比较好的拟合效果，所以我们称这种拟合为<strong>欠拟合(Underfitting)</strong>。而选用四次函数，我们会发现这样的拟合可能会误差很小，即<script type="math/tex">J(\theta)=\frac{1}{2m}\sum\limits_{i=1}^n\left(h_\theta(x)-y^{(i)}\right)^2\approx0</script>，但是很显然这个，函数拟合的并不满足实际情况(实际曲线根本不可能这么陡峭)，也就是说这个拟合的泛化效果不好，这种情况我们称为过拟合。而正则化正是为我们解决过拟合问题的。</p><h3 id="正则化代价函数"><a href="#正则化代价函数" class="headerlink" title="正则化代价函数"></a>正则化代价函数</h3><p>我们考虑一个问题，会出现过拟合现象的原因可能是我们对于参数的权重选用不得当，所以我们得像个办法来进行约束，引入一个新的正则化参数$\lambda$，<strong>regularization parament</strong> 。从而我们可以得到新的代价函数：</p><script type="math/tex; mode=display">J(\theta)=\frac{1}{2m}[\sum_{i=1}^{m}\left(h_\theta(x^{(i)})-y^{(i)}\right)^2+\lambda\sum_{i=1}^n\theta_j^2]</script><p>这样我们通过控制正则化参数的值就能对模型或者系统进行一定程度的优化或者说可视化的控制。</p><p>不管是正则化任何模型，我们控制的都是我们待定的权重，通过这样的方式，我们可以固定函数的类别，得到更合理的模型，在处理非线性的问题中广泛应用。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;关于&lt;strong&gt;Regularization(正则化)&lt;/strong&gt;的问题，这实际上在数学模型优化以及机器学习系统设计中，都是特别难处理的问题，所以我这里也只能用我浅显的认知和大家讲述正则化中最基本的知识。&lt;/p&gt;
    
    </summary>
    
    
      <category term="机器学习" scheme="http://yoursite.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="吴恩达课程笔记" scheme="http://yoursite.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%90%B4%E6%81%A9%E8%BE%BE%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="正则化" scheme="http://yoursite.com/tags/%E6%AD%A3%E5%88%99%E5%8C%96/"/>
    
  </entry>
  
  <entry>
    <title>【模型优化】浅谈正则化</title>
    <link href="http://yoursite.com/2020/07/03/%E3%80%90%E6%A8%A1%E5%9E%8B%E4%BC%98%E5%8C%96%E3%80%91%E6%B5%85%E8%B0%88%E6%AD%A3%E5%88%99%E5%8C%96/"/>
    <id>http://yoursite.com/2020/07/03/%E3%80%90%E6%A8%A1%E5%9E%8B%E4%BC%98%E5%8C%96%E3%80%91%E6%B5%85%E8%B0%88%E6%AD%A3%E5%88%99%E5%8C%96/</id>
    <published>2020-07-03T11:43:35.000Z</published>
    <updated>2020-07-04T05:18:02.374Z</updated>
    
    <content type="html"><![CDATA[<p>关于<strong>Regularization(正则化)</strong>的问题，这实际上在数学模型优化以及机器学习系统设计中，都是特别难处理的问题，所以我这里也只能用我浅显的认知和大家讲述正则化中最基本的知识。</p><a id="more"></a><h3 id="关于拟合：Underfitting-VS-Overfitting"><a href="#关于拟合：Underfitting-VS-Overfitting" class="headerlink" title="关于拟合：Underfitting VS Overfitting"></a>关于拟合：Underfitting VS Overfitting</h3><p><img src="/../image/ml31.jpg" alt=""></p><p>还是之前关于房价的例子，如果我们尝试用不同的函数进行拟合，选用一次函数，我们会发现，我们并没有完成一个比较好的拟合效果，所以我们称这种拟合为<strong>欠拟合(Underfitting)</strong>。而选用四次函数，我们会发现这样的拟合可能会误差很小，即<script type="math/tex">J(\theta)=\frac{1}{2m}\sum\limits_{i=1}^n\left(h_\theta(x)-y^{(i)}\right)^2\approx0</script>，但是很显然这个，函数拟合的并不满足实际情况(实际曲线根本不可能这么陡峭)，也就是说这个拟合的泛化效果不好，这种情况我们称为过拟合。而正则化正是为我们解决过拟合问题的。</p><h3 id="正则化代价函数"><a href="#正则化代价函数" class="headerlink" title="正则化代价函数"></a>正则化代价函数</h3><p>我们考虑一个问题，会出现过拟合现象的原因可能是我们对于参数的权重选用不得当，所以我们得像个办法来进行约束，引入一个新的正则化参数$\lambda$，<strong>regularization parament</strong> 。从而我们可以得到新的代价函数：</p><script type="math/tex; mode=display">J(\theta)=\frac{1}{2m}[\sum_{i=1}^{m}\left(h_\theta(x^{(i)})-y^{(i)}\right)^2+\lambda\sum_{i=1}^n\theta_j^2]</script><p>这样我们通过控制正则化参数的值就能对模型或者系统进行一定程度的优化或者说可视化的控制。</p><p>不管是正则化任何模型，我们控制的都是我们待定的权重，通过这样的方式，我们可以固定函数的类别，得到更合理的模型，在处理非线性的问题中广泛应用。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;关于&lt;strong&gt;Regularization(正则化)&lt;/strong&gt;的问题，这实际上在数学模型优化以及机器学习系统设计中，都是特别难处理的问题，所以我这里也只能用我浅显的认知和大家讲述正则化中最基本的知识。&lt;/p&gt;
    
    </summary>
    
    
      <category term="数学建模" scheme="http://yoursite.com/categories/%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1/"/>
    
      <category term="模型篇" scheme="http://yoursite.com/categories/%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1/%E6%A8%A1%E5%9E%8B%E7%AF%87/"/>
    
    
      <category term="正则化" scheme="http://yoursite.com/tags/%E6%AD%A3%E5%88%99%E5%8C%96/"/>
    
  </entry>
  
  <entry>
    <title>【初等模型】Logistic回归模型</title>
    <link href="http://yoursite.com/2020/06/29/%E3%80%90%E5%88%9D%E7%AD%89%E6%A8%A1%E5%9E%8B%E3%80%91Logistic%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B/"/>
    <id>http://yoursite.com/2020/06/29/%E3%80%90%E5%88%9D%E7%AD%89%E6%A8%A1%E5%9E%8B%E3%80%91Logistic%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B/</id>
    <published>2020-06-28T21:14:03.000Z</published>
    <updated>2020-07-02T16:09:56.294Z</updated>
    
    <content type="html"><![CDATA[<p>上一篇博客中，我们讲到了线性回归模型，是监督学习中的一个做预测工作的例子。而这里的Logistic回归则是监督学习的一个做分类工作例子，在数学建模与机器学习中，Logistic回归通常用于分类的目的，例如邮件的垃圾邮件分类，肿瘤的恶性良性分类等等。By the way，Logistic回归和Logistic分类是一回事，大家完全可以将两者等价。</p><p>Logistic回归有两种任务情况，分别是二元分类和多元分类问题，从字面上理解来说，binary problem是二元问题：非此即彼，非0即1 。而多元分类则是有多个分类组别，下面我们先从易入难，从binary的Logistic回归说起。</p><a id="more"></a><h3 id="Logistic模型描述"><a href="#Logistic模型描述" class="headerlink" title="Logistic模型描述"></a>Logistic模型描述</h3><p>和线性回归模型思想一项，也会存在单特征或多个特征$x^{(1)}_j$的情况，但是我们的目标值或者是输出值只有两种，0或1，即$y\in \{0,1\}$。其中”0”代表”Negative Class”，”1”代表”Positive Class”。</p><p>但是我们通过假设函数计算的输出值即$h_{\theta}(x)$可不可能只有0或1两个情况，很显然，根本没有连续函数能达到这个功能，所以在输出值有一段连续值得情况下，我们设置一个<strong>阈值(threshold)</strong>。例如我们讨论关于肿瘤恶性与良性的分类，设置阈值为0.5，这是什么意思呢？</p><p>如果$h_{\theta}(x)\geq 0.5$，那我们预测$y=1$，即在这种情况下，我们更倾向于将这个肿瘤划分为恶性的。反之$h_{\theta}(x)&lt;0.5$，则$y=0$。在这方面，后来也有很多扩展，比如应用于年龄估计和情感计算的多标签分布学习与标记增强，拜读过东南大学耿新老师的论文，如果有兴趣可以去看看。</p><p>为了使得分类任务靠设定阈值顺利进行，我们其实还得保证输出$h(x)$的范围的确定性，如果范围过于不确定，那阈值的选择会比较困难，所以之后我们会讲到这种方法，使得$0\leq h_{\theta}(x)\leq 1$。</p><h3 id="假设函数的新表示方法-区别于线性回归"><a href="#假设函数的新表示方法-区别于线性回归" class="headerlink" title="假设函数的新表示方法(区别于线性回归)"></a>假设函数的新表示方法(区别于线性回归)</h3><p>在上文中提到，我们为了想让$0\leq h_{\theta}(x)\leq 1$满足在这个范围内，我们引入一个神奇的函数，在机器学习中这个函数当真反复出现，<strong>Sigmoid function/Logistic function</strong>(这两个函数就是等价的，一个意思)：</p><p><img src="/../image/ml21.jpg" alt=""></p><p>这是个生物学函数，为了显示它的重要性，我单独列一行出来：</p><script type="math/tex; mode=display">g(z)=\frac{1}{1+e^{-z}}</script><p>现在我们写出Logistic回归模型的假设函数，并与之前的线性回归模型的进行对比：</p><script type="math/tex; mode=display">\begin{align}Linear&:h_{\theta}(x)=\theta^Tx\\Logistic&:h_{\theta}(x)=g(\theta^Tx)=\frac{1}{1+e^{-\theta^Tx}}\end{align}</script><p>事实上，就是区别于Sigmoid函数，还是之前恶性与良性肿瘤的例子。根据我输入的特征向量，求出的假设函数$h(x)$实际上代表着预测$y=1$的概率，即：</p><script type="math/tex; mode=display">h(x)=P(y=1|x;\theta),y=0,1</script><p>比如输出一组特征值，我们输出$h(x)=0.7$代表肿瘤为恶性的可能性为$70\%$，考虑到我们之前所定阈值为0.5，所以这个肿瘤我们划分在恶性中去。</p><h3 id="决策界限-Decision-Boundary"><a href="#决策界限-Decision-Boundary" class="headerlink" title="决策界限(Decision Boundary)"></a>决策界限(Decision Boundary)</h3><h4 id="线性"><a href="#线性" class="headerlink" title="线性"></a>线性</h4><p><img src="/../image/ml22.jpg" alt=""></p><p>通常选择线性or非线性，主要还是观察数据集的分布情况。比如上图，我们采用线性Boundary，$z=\theta^Tx$我们通过现有的数据集计算出了，$\theta^T=\begin{bmatrix}-3 &amp; 1&amp; 1\end{bmatrix}$，由于我们知道Sigmoid函数的性质我们知道，当$z\geq0$时，$g(z)\geq0.5$，我们认为它属于恶性肿瘤，反之相对即可。即我们最终计算出的线性决策界限，就是$z\geq0$时为恶性肿瘤，即$-3+x_1+x_2\geq0$。我们通过$\theta$反推得出了决策界限。</p><h4 id="非线性"><a href="#非线性" class="headerlink" title="非线性"></a>非线性</h4><p><img src="/../image/ml23.jpg" alt=""></p><p>在这个非线性的例子中，我们处理非线性的决策边界问题，令假设函数的表达式为：</p><script type="math/tex; mode=display">h(x)=g(\theta_0+\theta_1x_1+\theta_2x_2+\theta_3x_1^2+\theta_4x_2^2)</script><p>当然你可能会觉得这个假设函数的设置过于主观，that’s ok. 这可能是我通常不会选择Logistic来处理非线性分类问题的原因。在这种分类问题，我更喜欢构建SVM的模型，这个我们之后会提到。好了，话说回来，这个我们通过计算得到，$\theta^T=\begin{bmatrix}-1 &amp; 0 &amp; 0 &amp; 1 &amp; 1\end{bmatrix}$，由Sigmoid的性质可得，当$z\geq 0$时，即$x_1^2+x^2_2\geq 1$，在这个情况下，我们更希望相信这个分类成为恶性肿瘤，反之也相对。下面我们来说说，Logistic回归的代价函数。</p><h3 id="代价函数-Cost-Function"><a href="#代价函数-Cost-Function" class="headerlink" title="代价函数(Cost Function)"></a>代价函数(Cost Function)</h3><h4 id="引入"><a href="#引入" class="headerlink" title="引入"></a>引入</h4><p>我们上述讨论了决策边界的问题，那么我们现在需要解决的问题就是如何选取最优的$\theta$值，即代价函数最小。首先，我先说Logistic的代价函数，和我们之前的线性回归的表达形式一模一样：</p><script type="math/tex; mode=display">J(\theta)=\frac{1}{2m}\sum_{i=1}^m\left(h_\theta(x^{(i)})-y^{(i)}\right)^2</script><p>你可能觉得这个代价函数和线性回归的一模一样，但是有一些细微的差别，在这里$h(x)=g(z)$，而线性回归则没有加入sigmoid函数。但是，我们其实通常并不选择这个函数为我们所要的代价函数，我这里简单说下原因，由于我们的假设函数是关于sigmoid的函数，是一个非线性的函数。代入计算，我们的代价函数会是一个非凸函数。</p><p><img src="/../image/ml24.jpg" alt=""></p><p>在这个情况下，非凸函数如左图所示，他有很多的局部最优点，所以我们使用梯度下降法是找不到全局最优点的。而我们需要找一个<strong>凸函数(convex function)</strong>，也就是弓形函数，仅有一个全局最优解，所以我们通过梯度下降法就能很好做到找到代价函数的最优点。</p><h4 id="改进Cost，重新化简代价函数"><a href="#改进Cost，重新化简代价函数" class="headerlink" title="改进Cost，重新化简代价函数"></a>改进Cost，重新化简代价函数</h4><p>在上个引入部分中，我们令代价函数的部分为：</p><script type="math/tex; mode=display">\begin{align}J(\theta)&=\frac{1}{m}\sum_{i=1}^m\frac{1}{2}\left(h_\theta(x^{(i)})-y^{(i)}\right)^2\\Cost(h_\theta(x^{(i)}),y^{(i)})&=\frac{1}{2}\left(h_\theta(x^{(i)})-y^{(i)}\right)^2\\\end{align}</script><p>下面我们来改进一个新的Cost从而得到新的代价函数，而这个代价函数我们希望他是convex的，还是以二分类问题来举例：</p><script type="math/tex; mode=display">Cost(h_\theta(x),y)=\begin{cases}-log(h_\theta(x)) & \text{if } y=1\\-log(1-h_\theta(x)) & \text{if } y=0\\\end{cases}</script><p>在binary的问题中，我们注意到y的值总是0或1，所以我们重新化简代价函数：</p><script type="math/tex; mode=display">J(\theta)=-\frac{1}{m}[\sum_{i=1}^my^{(i)}logh_{\theta}(x^{(i)})+(1-y^{(i)})log(1-h_{\theta}(x^{(i)}))]</script><p>然后我们又可以愉快地用梯度下降算法啦！！</p><h3 id="多元分类问题-Multi-class-classification"><a href="#多元分类问题-Multi-class-classification" class="headerlink" title="多元分类问题(Multi-class classification)"></a>多元分类问题(Multi-class classification)</h3><p>其实，多元分类与二元分类基本类似，我们现在假设我们有三个类别(更多的也一样)，Class 1~3，我们简单用下图来说明下问题。</p><p><img src="/../image/ml25.jpg" alt=""></p><p>吴恩达老师上课的课件，看到$h_{\theta}^{(i)}=P(y=i|x;\theta)$这个公式(julao不愧是julao)，让我茅塞顿开。其实多元分类问题就可以写成二元分类，如果你还没看懂，我来做下简单的解释。</p><script type="math/tex; mode=display">J^{(i)}(\theta)=-\frac{1}{m}[\sum_{i=1}^mylogh^{(i)}_{\theta}(x)+(i-y)log(1-h^{(i)}_{\theta}(x))]</script><p>这样，我们便依然可以采用梯度下降法去求解。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;上一篇博客中，我们讲到了线性回归模型，是监督学习中的一个做预测工作的例子。而这里的Logistic回归则是监督学习的一个做分类工作例子，在数学建模与机器学习中，Logistic回归通常用于分类的目的，例如邮件的垃圾邮件分类，肿瘤的恶性良性分类等等。By the way，Logistic回归和Logistic分类是一回事，大家完全可以将两者等价。&lt;/p&gt;
&lt;p&gt;Logistic回归有两种任务情况，分别是二元分类和多元分类问题，从字面上理解来说，binary problem是二元问题：非此即彼，非0即1 。而多元分类则是有多个分类组别，下面我们先从易入难，从binary的Logistic回归说起。&lt;/p&gt;
    
    </summary>
    
    
      <category term="数学建模" scheme="http://yoursite.com/categories/%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1/"/>
    
      <category term="模型篇" scheme="http://yoursite.com/categories/%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1/%E6%A8%A1%E5%9E%8B%E7%AF%87/"/>
    
    
      <category term="Logistic" scheme="http://yoursite.com/tags/Logistic/"/>
    
  </entry>
  
  <entry>
    <title>【吴恩达笔记】Logistic回归</title>
    <link href="http://yoursite.com/2020/06/29/%E3%80%90%E5%90%B4%E6%81%A9%E8%BE%BE%E7%AC%94%E8%AE%B0%E3%80%91Logistic%E5%9B%9E%E5%BD%92/"/>
    <id>http://yoursite.com/2020/06/29/%E3%80%90%E5%90%B4%E6%81%A9%E8%BE%BE%E7%AC%94%E8%AE%B0%E3%80%91Logistic%E5%9B%9E%E5%BD%92/</id>
    <published>2020-06-28T21:13:21.000Z</published>
    <updated>2020-07-03T02:31:53.704Z</updated>
    
    <content type="html"><![CDATA[<p>上一篇博客中，我们讲到了线性回归模型，是监督学习中的一个做预测工作的例子。而这里的Logistic回归则是监督学习的一个做分类工作例子，在数学建模与机器学习中，Logistic回归通常用于分类的目的，例如邮件的垃圾邮件分类，肿瘤的恶性良性分类等等。By the way，Logistic回归和Logistic分类是一回事，大家完全可以将两者等价。</p><p>Logistic回归有两种任务情况，分别是二元分类和多元分类问题，从字面上理解来说，binary problem是二元问题：非此即彼，非0即1 。而多元分类则是有多个分类组别，下面我们先从易入难，从binary的Logistic回归说起。</p><a id="more"></a><h3 id="Logistic模型描述"><a href="#Logistic模型描述" class="headerlink" title="Logistic模型描述"></a>Logistic模型描述</h3><p>和线性回归模型思想一项，也会存在单特征或多个特征$x^{(1)}_j$的情况，但是我们的目标值或者是输出值只有两种，0或1，即$y\in \{0,1\}$。其中”0”代表”Negative Class”，”1”代表”Positive Class”。</p><p>但是我们通过假设函数计算的输出值即$h_{\theta}(x)$可不可能只有0或1两个情况，很显然，根本没有连续函数能达到这个功能，所以在输出值有一段连续值得情况下，我们设置一个<strong>阈值(threshold)</strong>。例如我们讨论关于肿瘤恶性与良性的分类，设置阈值为0.5，这是什么意思呢？</p><p>如果$h_{\theta}(x)\geq 0.5$，那我们预测$y=1$，即在这种情况下，我们更倾向于将这个肿瘤划分为恶性的。反之$h_{\theta}(x)&lt;0.5$，则$y=0$。在这方面，后来也有很多扩展，比如应用于年龄估计和情感计算的多标签分布学习与标记增强，拜读过东南大学耿新老师的论文，如果有兴趣可以去看看。</p><p>为了使得分类任务靠设定阈值顺利进行，我们其实还得保证输出$h(x)$的范围的确定性，如果范围过于不确定，那阈值的选择会比较困难，所以之后我们会讲到这种方法，使得$0\leq h_{\theta}(x)\leq 1$。</p><h3 id="假设函数的新表示方法-区别于线性回归"><a href="#假设函数的新表示方法-区别于线性回归" class="headerlink" title="假设函数的新表示方法(区别于线性回归)"></a>假设函数的新表示方法(区别于线性回归)</h3><p>在上文中提到，我们为了想让$0\leq h_{\theta}(x)\leq 1$满足在这个范围内，我们引入一个神奇的函数，在机器学习中这个函数当真反复出现，<strong>Sigmoid function/Logistic function</strong>(这两个函数就是等价的，一个意思)：</p><p><img src="/../image/ml21.jpg" alt=""></p><p>这是个生物学函数，为了显示它的重要性，我单独列一行出来：</p><script type="math/tex; mode=display">g(z)=\frac{1}{1+e^{-z}}</script><p>现在我们写出Logistic回归模型的假设函数，并与之前的线性回归模型的进行对比：</p><script type="math/tex; mode=display">\begin{align}Linear&:h_{\theta}(x)=\theta^Tx\\Logistic&:h_{\theta}(x)=g(\theta^Tx)=\frac{1}{1+e^{-\theta^Tx}}\end{align}</script><p>事实上，就是区别于Sigmoid函数，还是之前恶性与良性肿瘤的例子。根据我输入的特征向量，求出的假设函数$h(x)$实际上代表着预测$y=1$的概率，即：</p><script type="math/tex; mode=display">h(x)=P(y=1|x;\theta),y=0,1</script><p>比如输出一组特征值，我们输出$h(x)=0.7$代表肿瘤为恶性的可能性为$70\%$，考虑到我们之前所定阈值为0.5，所以这个肿瘤我们划分在恶性中去。</p><h3 id="决策界限-Decision-Boundary"><a href="#决策界限-Decision-Boundary" class="headerlink" title="决策界限(Decision Boundary)"></a>决策界限(Decision Boundary)</h3><h4 id="线性"><a href="#线性" class="headerlink" title="线性"></a>线性</h4><p><img src="/../image/ml22.jpg" alt=""></p><p>通常选择线性or非线性，主要还是观察数据集的分布情况。比如上图，我们采用线性Boundary，$z=\theta^Tx$我们通过现有的数据集计算出了，$\theta^T=\begin{bmatrix}-3 &amp; 1&amp; 1\end{bmatrix}$，由于我们知道Sigmoid函数的性质我们知道，当$z\geq0$时，$g(z)\geq0.5$，我们认为它属于恶性肿瘤，反之相对即可。即我们最终计算出的线性决策界限，就是$z\geq0$时为恶性肿瘤，即$-3+x_1+x_2\geq0$。我们通过$\theta$反推得出了决策界限。</p><h4 id="非线性"><a href="#非线性" class="headerlink" title="非线性"></a>非线性</h4><p><img src="/../image/ml23.jpg" alt=""></p><p>在这个非线性的例子中，我们处理非线性的决策边界问题，令假设函数的表达式为：</p><script type="math/tex; mode=display">h(x)=g(\theta_0+\theta_1x_1+\theta_2x_2+\theta_3x_1^2+\theta_4x_2^2)</script><p>当然你可能会觉得这个假设函数的设置过于主观，that’s ok. 这可能是我通常不会选择Logistic来处理非线性分类问题的原因。在这种分类问题，我更喜欢构建SVM的模型，这个我们之后会提到。好了，话说回来，这个我们通过计算得到，$\theta^T=\begin{bmatrix}-1 &amp; 0 &amp; 0 &amp; 1 &amp; 1\end{bmatrix}$，由Sigmoid的性质可得，当$z\geq 0$时，即$x_1^2+x^2_2\geq 1$，在这个情况下，我们更希望相信这个分类成为恶性肿瘤，反之也相对。下面我们来说说，Logistic回归的代价函数。</p><h3 id="代价函数-Cost-Function"><a href="#代价函数-Cost-Function" class="headerlink" title="代价函数(Cost Function)"></a>代价函数(Cost Function)</h3><h4 id="引入"><a href="#引入" class="headerlink" title="引入"></a>引入</h4><p>我们上述讨论了决策边界的问题，那么我们现在需要解决的问题就是如何选取最优的$\theta$值，即代价函数最小。首先，我先说Logistic的代价函数，和我们之前的线性回归的表达形式一模一样：</p><script type="math/tex; mode=display">J(\theta)=\frac{1}{2m}\sum_{i=1}^m\left(h_\theta(x^{(i)})-y^{(i)}\right)^2</script><p>你可能觉得这个代价函数和线性回归的一模一样，但是有一些细微的差别，在这里$h(x)=g(z)$，而线性回归则没有加入sigmoid函数。但是，我们其实通常并不选择这个函数为我们所要的代价函数，我这里简单说下原因，由于我们的假设函数是关于sigmoid的函数，是一个非线性的函数。代入计算，我们的代价函数会是一个非凸函数。</p><p><img src="/../image/ml24.jpg" alt=""></p><p>在这个情况下，非凸函数如左图所示，他有很多的局部最优点，所以我们使用梯度下降法是找不到全局最优点的。而我们需要找一个<strong>凸函数(convex function)</strong>，也就是弓形函数，仅有一个全局最优解，所以我们通过梯度下降法就能很好做到找到代价函数的最优点。</p><h4 id="改进Cost，重新化简代价函数"><a href="#改进Cost，重新化简代价函数" class="headerlink" title="改进Cost，重新化简代价函数"></a>改进Cost，重新化简代价函数</h4><p>在上个引入部分中，我们令代价函数的部分为：</p><script type="math/tex; mode=display">\begin{align}J(\theta)&=\frac{1}{m}\sum_{i=1}^m\frac{1}{2}\left(h_\theta(x^{(i)})-y^{(i)}\right)^2\\Cost(h_\theta(x^{(i)}),y^{(i)})&=\frac{1}{2}\left(h_\theta(x^{(i)})-y^{(i)}\right)^2\\\end{align}</script><p>下面我们来改进一个新的Cost从而得到新的代价函数，而这个代价函数我们希望他是convex的，还是以二分类问题来举例：</p><script type="math/tex; mode=display">Cost(h_\theta(x),y)=\begin{cases}-log(h_\theta(x)) & \text{if } y=1\\-log(1-h_\theta(x)) & \text{if } y=0\\\end{cases}</script><p>在binary的问题中，我们注意到y的值总是0或1，所以我们重新化简代价函数：</p><script type="math/tex; mode=display">J(\theta)=-\frac{1}{m}[\sum_{i=1}^my^{(i)}logh_{\theta}(x^{(i)})+(1-y^{(i)})log(1-h_{\theta}(x^{(i)}))]</script><p>然后我们又可以愉快地用梯度下降算法啦！！</p><h3 id="多元分类问题-Multi-class-classification"><a href="#多元分类问题-Multi-class-classification" class="headerlink" title="多元分类问题(Multi-class classification)"></a>多元分类问题(Multi-class classification)</h3><p>其实，多元分类与二元分类基本类似，我们现在假设我们有三个类别(更多的也一样)，Class 1~3，我们简单用下图来说明下问题。</p><p><img src="/../image/ml25.jpg" alt=""></p><p>吴恩达老师上课的课件，看到$h_{\theta}^{(i)}=P(y=i|x;\theta)$这个公式(julao不愧是julao)，让我茅塞顿开。其实多元分类问题就可以写成二元分类，如果你还没看懂，我来做下简单的解释。</p><script type="math/tex; mode=display">J^{(i)}(\theta)=-\frac{1}{m}[\sum_{i=1}^mylogh^{(i)}_{\theta}(x)+(i-y)log(1-h^{(i)}_{\theta}(x))]</script><p>这样，我们便依然可以采用梯度下降法去求解。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;上一篇博客中，我们讲到了线性回归模型，是监督学习中的一个做预测工作的例子。而这里的Logistic回归则是监督学习的一个做分类工作例子，在数学建模与机器学习中，Logistic回归通常用于分类的目的，例如邮件的垃圾邮件分类，肿瘤的恶性良性分类等等。By the way，Logistic回归和Logistic分类是一回事，大家完全可以将两者等价。&lt;/p&gt;
&lt;p&gt;Logistic回归有两种任务情况，分别是二元分类和多元分类问题，从字面上理解来说，binary problem是二元问题：非此即彼，非0即1 。而多元分类则是有多个分类组别，下面我们先从易入难，从binary的Logistic回归说起。&lt;/p&gt;
    
    </summary>
    
    
      <category term="机器学习" scheme="http://yoursite.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="吴恩达课程笔记" scheme="http://yoursite.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%90%B4%E6%81%A9%E8%BE%BE%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="Logistic" scheme="http://yoursite.com/tags/Logistic/"/>
    
  </entry>
  
  <entry>
    <title>【初等模型】线性回归</title>
    <link href="http://yoursite.com/2020/06/29/%E3%80%90%E5%88%9D%E7%AD%89%E6%A8%A1%E5%9E%8B%E3%80%91%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/"/>
    <id>http://yoursite.com/2020/06/29/%E3%80%90%E5%88%9D%E7%AD%89%E6%A8%A1%E5%9E%8B%E3%80%91%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/</id>
    <published>2020-06-28T20:19:57.000Z</published>
    <updated>2020-06-28T13:29:45.296Z</updated>
    
    <content type="html"><![CDATA[<p>你可能会发现这篇博客与我之前的机器学习的线性回归完全一样，没错，就是一样的。知识点都是线性回归，所以能有什么区别呢，线性回归模型都是数学模型与机器学习中最基础的模型，需要注意的是，学校老师培训的数学建模竞赛培训可能更重视原理，导致大部分同学听了个寂寞。但是往往比赛我们会使用就行，不用太过于纠结，另外题目与源代码之后补上2333。</p><h3 id="一元线性回归-单变量线性回归-Linear-Regression-with-one-variable"><a href="#一元线性回归-单变量线性回归-Linear-Regression-with-one-variable" class="headerlink" title="一元线性回归(单变量线性回归)  Linear Regression with one variable"></a>一元线性回归(单变量线性回归)  Linear Regression with one variable</h3><a id="more"></a><h4 id="1-模型描述"><a href="#1-模型描述" class="headerlink" title="1. 模型描述"></a>1. 模型描述</h4><p>首先明确线性回归的作用，在机器学习中，我们可以广义的把机器学习划分为两类学习，监督学习与无监督学习。简单而言，监督学习就是给出了准确答案，期望计算机能学习其中的原理，并对我们未知的事情做出一定的预测。无监督学习就是指，我们并不知道准确结果的事情，希望机器通过学习，能从中抽取有效信息，举个简单的例子，例如邮箱垃圾邮件分类，新闻栏目划分等等，这些我们都能通过无监督学习去解决。</p><p>好了下面再举一个关于监督学习的例子，吴老师上课的例子是房价预估，如下图所示。</p><p><img src="/../image/ml1.jpg" alt=""></p><p>给你一定数量的数据集，代表房屋尺寸与价格的散点图，现在你希望知道除这些数据集以外的Size所对应的Price，相当于我之前说的预测。比如Size为1250时，那Price可能为2200左右这样子。那这个过程，我们实际就是想从现已知的数据集中学习某些知识内容，从而达到预测的效果。而这个过程就是我们所说的，<strong>回归</strong>。</p><p>其实就是拟合函数曲线，从而达到其与数据集的最优拟合，然后预测所有的Size。由于这个房子的单价这个假设中只与Size有关，所以我们称它为单变量或是一元。</p><p>下图是关于机器学习的基本流程图，你可以认为几乎所有机器学习问题都是这个框架的东西。</p><p><img src="/../image/ml2.jpg" alt=""></p><p>而这其中的$h$，代表$hypothesis$，由流程图可以看出，它是由数据集与学习算法得来的，在数学模型中，它代表回归模型，在机器学习中，我们通常把它称作假设函数。</p><script type="math/tex; mode=display">\begin{align}how\quad &to \quad represent \quad h \quad ?\\h_{\theta}(x)&=\theta_0+\theta_1x\end{align}</script><p>以上便是我们在一元线性回归模型中的假设函数了，可以看出，实际上我们是对数据集拟合了一个一次函数，所以我们才说是线性回归，那么实际的问题中，当然不是所有问题都是线性的关系，这个我们之后再去说。好了，目前为止，我已经解释了所有关于一元线性回归模型的意义了，下面我们来看点重要的。</p><h4 id="2-代价函数-cost-function"><a href="#2-代价函数-cost-function" class="headerlink" title="2. 代价函数 cost function"></a>2. 代价函数 cost function</h4><p><img src="/../image/ml3.jpg" alt=""></p><p>下面我们来看个更具体的例子，我们已经给出了数据集，要求求出Size和Price的内在关系，可以很明显的知道这是个一元回归问题，至于线性，这个我们不是我们现在需要考虑的，我们就当它拟合为线性一次函数。首先先解释数据集中几个变量符号的意义：</p><ul><li><strong>m：数据集的数量</strong></li><li><strong>x：特征/输入变量</strong>      $x^{(i)}$代表第i个特征$(i=1,2,…,m)$</li><li><strong>y：目标/输出变量</strong>      $y^{(i)}$代表第i个目标$(i=1,2,…,m)$</li></ul><p>当然不同的人有不同的表示方法，我相信这不是比较关键的东西，whatever。我们还是需要得到我们的假设函数$h_{\theta}(x)=\theta_0+\theta_1x$，如何选择$\theta_i$，即参数，才是我们需要关注的问题。ps：之后的$h_{\theta}(x)$全部简写为$h(x)$</p><p>我们的目的当然是，一次线性函数与原数据集有高度的拟合，即我们假设函数$h(x)$得到的结果与原目标$y$差距越小越好，于是我们得到了我们所谓的回归目标：</p><script type="math/tex; mode=display">min_{\theta_i}:\frac{1}{2m}\sum_{i=1}^m \left(h(x^{(i)})-y^{(i)}\right)^2</script><p>这其实是个方差公式的形式，我们添上了系数1/2。然后很明显地，我们完全可以用这个函数来判断我们的拟合程度，这个值越小就说明我们的拟合效果越好。于是，我们就规定了一个函数：</p><script type="math/tex; mode=display">J(\theta_i)=\frac{1}{2m}\sum_{i=1}^m \left(h(x^{(i)})-y^{(i)}\right)^2</script><p>然而这个函数就是<strong>代价函数(cost function)</strong>，表面意思就是为了拟合某个数据集，我们所需要付出的代价。在所有机器学习的问题中，我们都在研究如何使得代价函数最小，也就是我们上面所说的回归目标。</p><p><img src="/../image/ml4.jpg" alt=""></p><p>解决问题时，我们通常会有两张常见的可视化图片，第一张是$h(x)$的图，也就是Size和Price的数据集的图，第二张图是关于代价函数的，也有画三维图的，当然也有这种画等高线的。在接下来的问题中，我们会研究通过何种算法，让机器帮助我们找到最优目标的参数值。</p><h4 id="3-梯度下降算法-Gradient-Descent-Algorithm"><a href="#3-梯度下降算法-Gradient-Descent-Algorithm" class="headerlink" title="3. 梯度下降算法  Gradient Descent Algorithm"></a>3. 梯度下降算法  Gradient Descent Algorithm</h4><p>再次明确我们的模型函数，我们现在有$J(\theta_i)$,目标是让这个函数得到最小值。朴素的思想就是我们可以定起始的$\theta_i$，然后不断地改变他们，直到他们最后到达了最小值。很明显，这样的想法我们还需要更可靠的算法，毕竟全部遍历是不可能的。</p><p>所以这也就引入了梯度下降算法来解决这个问题，先给大家看某个代价函数，以及算法实现的某个过程。</p><p><img src="/../image/ml5.jpg" alt=""></p><p>想法不变，我们从某个$(\theta_0,\theta_1)$开始，不断改变他们的值，直到收敛到局部最优。而这个改变的过程我们称为梯度下降，为了方便理解，我直接给出参数改变的公式，也就是$\theta_i$不断更新的依据，假设仅有两个参数的时候。</p><script type="math/tex; mode=display">\theta_j:=\theta_j-\alpha \frac{\partial}{\partial \theta_j}J(\theta_0,\theta_1) \quad (j=0,1)</script><p>这便是梯度下降最关键的地方，其中有了偏导数符号，这个如果看不懂的话，还是要先学微积分的。仔细想想的话，这样确实能通过下降的方式，使得代价函数收敛到局部最优解。其中$\alpha$代表学习率，你可以理解为每次更新的步长，这个也很关键，但是之后我们也会提到。</p><p>还有需要强调的是，我们的$\theta_i$是同步更新(Simultaneous update)的，这个如果你学过计算方法这门课中求解微分方程的两种方法或许你应该深有体会。</p><p>下面这个例子是同步更新</p><script type="math/tex; mode=display">\begin{align}\\Correct&:Simultaneous \quad update\\temp0&:=\theta_0-\alpha \frac{\partial}{\partial \theta_0}J(\theta_0,\theta_1)\\temp1&:=\theta_1-\alpha \frac{\partial}{\partial \theta_1}J(\theta_0,\theta_1)\\\theta_0&:=temp0\\\theta_1&:=temp1\end{align}</script><p>然后这是不同步更新的例子</p><script type="math/tex; mode=display">\begin{align}Inco&rrect:\\temp0&:=\theta_0-\alpha \frac{\partial}{\partial \theta_0}J(\theta_0,\theta_1)\\\theta_0&:=temp0\\temp1&:=\theta_1-\alpha \frac{\partial}{\partial \theta_1}J(\theta_0,\theta_1)\\\theta_1&:=temp1\end{align}</script><p>在不同步更新的例子中我们发现，$\theta_0$更新后带入了$\theta_1$的更新公式中，这不是我们想要的。</p><p>理解清楚了这个后，我们就明白了梯度下降法的公式了，你可能会说选择不同的开始的起始值会导致不同的收敛点，确实是这样，比如下面这个图。</p><p><img src="/../image/ml6.jpg" alt=""></p><p>很显然因为选择了不同的$\theta_i$会导致两种不同的路线，通过梯度下降算法我们只能找到局部收敛点，而不是全局最优点。不过这也没关系，我们处理问题的时候都尽量会选择弓形函数，也就是<strong>凸函数(convex function)</strong>.这种函数我们保证它仅有一个收敛点，即全局最优解。</p><h3 id="多元线性回归-Linear-Regression-with-Multiple-Variables"><a href="#多元线性回归-Linear-Regression-with-Multiple-Variables" class="headerlink" title="多元线性回归  Linear Regression with Multiple Variables"></a>多元线性回归  Linear Regression with Multiple Variables</h3><h4 id="1-模型描述-多特征"><a href="#1-模型描述-多特征" class="headerlink" title="1. 模型描述 多特征"></a>1. 模型描述 多特征</h4><p>我们根据上面那个房价的例子，很显然在实际的生活中，房价Price绝不可能只与其Size有关系的，你的北京六环和二环的房子能比得起来吗？哦，我知道你没有。这里还是根据那个房价的例子，不过我们提出了更多的影响因素。</p><p><img src="/../image/ml7.jpg" alt=""></p><p>我们还是首先来规定下符号：</p><ul><li><strong>m：数据集的数量</strong></li><li><strong>n：特征的个数</strong>  例如此例n=4</li><li><strong>$x^{(i)}$：序号为i的数据集的特征向量</strong></li><li><strong>$x_j^{(i)}$：序号为i的数据集的第j个特征</strong>  比如40年我们如何表示？ $x_4^{(2)}$=40</li></ul><p>假设函数那当然也是多变量的了，我默认大家都学完了矩阵的东西，所以我就直接用矩阵的表示形式来列了。</p><script type="math/tex; mode=display">\begin{align}h(x)&=\theta_0+\theta_1x_1+\theta_2x_2+...+\theta_nx_n\\define \quad x_0&=1\\x=\begin{bmatrix} x_0\\x_1\\x_2\\\vdots\\x_n \end{bmatrix} \quad& \theta=\begin{bmatrix} \theta_0\\\theta_1\\\theta_2\\\vdots\\\theta_n \end{bmatrix}\\h(x)&=\theta^Tx\end{align}</script><p>我们采用矩阵的表达方式，已经写出了假设函数的矩阵形式，很简单，那下面就来说说如何在这个假设函数中进行梯度下降。</p><h4 id="2-多变量梯度下降"><a href="#2-多变量梯度下降" class="headerlink" title="2. 多变量梯度下降"></a>2. 多变量梯度下降</h4><p>其实梯度下降的公式都是一样的，只不过原来一元的时候只需要更新两个$\theta$值，现在需要更新n个，仅此而已。</p><script type="math/tex; mode=display">\theta_j:=\theta_j-\alpha \frac{\partial}{\partial \theta_j}J(\theta) \quad (j=0,1,...,n)</script><p>但是我们需要注意的，可不是这些。</p><h5 id="1-特征缩放"><a href="#1-特征缩放" class="headerlink" title="(1) 特征缩放"></a>(1) 特征缩放</h5><p>线性回归的目的就是在于求出我们所需要的权重，即$\theta$值，而权重和每个特征量的大小相关。试想一下，如果一个房间的Size的范围是1000左右，而房子的楼层是3以内的数，那我们直接拟合出来的权重，肯定更偏向于Size啊，而这显然不符合实际情况。这就是多元回归区别于一元回归的事情，一元回归就一个变量，咱们不需要考虑其大小范围。但是多元我们必须考虑，我们最好能够将所有变量统一缩放到某个区间，比如$-1\leq x_i\leq 1$。当然这个区间不是必须的，这里只给个参考范围。而对于所有的变量，我们都需要先进行<strong>均值标准化(Mean Normalization)</strong> 的处理。</p><script type="math/tex; mode=display">\begin{align}Mean &\quad Normalization:\\x_j&:=\frac{x_j-\mu_j}{\sigma_j}\end{align}</script><p>我相信如果你学过概率论的话，这个式子应该经常出现，不管是在八大公式还是假设检验里面。还是需要解释一下，这其中$\mu_j$表示第j组特征向量的均值，而$\sigma_j$表示第j组数据的标准差。</p><h5 id="2-特征合并"><a href="#2-特征合并" class="headerlink" title="(2) 特征合并"></a>(2) 特征合并</h5><p>这个是很好理解，也算是多元线性回归里面的一点技巧。比如题目给出的因素中，Price与房子的frontage和depth有关，那我们就要想到$Size=Frontage\times Depth$。于是我们就能把这个两个特征当成一个来处理，其实实际问题中这样的例子还是挺常见的。</p><h5 id="3-学习率与假设函数选择"><a href="#3-学习率与假设函数选择" class="headerlink" title="(3) 学习率与假设函数选择"></a>(3) 学习率与假设函数选择</h5><p>关于学习率$\alpha$与假设函数次项的选择，我在这里就不明说了，因为我自己也不是很能给出一个具体的方案。以及这样的情况遇到的较少。</p><h3 id="正规方程求解参数-Normal-Equation"><a href="#正规方程求解参数-Normal-Equation" class="headerlink" title="正规方程求解参数  Normal Equation"></a>正规方程求解参数  Normal Equation</h3><p>事实上，我们除了梯度下降法，还有另一种方法求解我们所需要的参数以及权重$\theta$的方法，就是用普通的方程求解，剩下的交给MATLAB就好，以上面那个例子来说明。</p><p><img src="/../image/ml7.jpg" alt=""></p><p>我们希望求得一组$\theta$值，能够假设函数能够很好地拟合最终的Price，其实我们不难列出我们的假设函数：</p><script type="math/tex; mode=display">h(x)=\begin{bmatrix}1 & 2104 & 5 &1 &45\\1 & 1416 & 3 &2 &40\\\vdots & \vdots & \vdots & \vdots & \vdots\end{bmatrix}\times\begin{bmatrix}\theta_0 \\\theta_1 \\\vdots \\\theta_n\end{bmatrix}=X\theta</script><p>实际上我们添加了$x_0=1$这一项，如果能够理解的话，那说明你基本明白了线性回归的知识点。然后我们要用Normal的方法解得我们需要的$\theta$：</p><script type="math/tex; mode=display">\theta = (X^TX)^{-1}X^Ty \quad ,\quad y=\begin{bmatrix} 460\\232\\315\\178\\ \vdots\end{bmatrix}</script><p>很遗憾地告诉你，我并不能告诉你这个方程是怎么推出来的，其实你也不需要理解。在数学建模竞赛或是机器学习研究中，我们大部分情况下只需要会用即可。</p><p>ok，到这里关于线性回归模型的求解，你已经学会了两种方法，梯度下降算法与正规方程解法，你可能会觉得正规方程解法会比较方便，下面我就来说说正规方程解法的局限性。</p><ul><li>正规方程解法需要计算矩阵的逆，当特征数大于样本数时，矩阵为奇异矩阵，无逆矩阵，虽然MATLAB命令<code>pinv</code>也能得到近似解，但是这往往不符合我们的预测要求。</li><li>当样本数量也特别大的时候，矩阵计算会非常缓慢，通常几千以内的矩阵，MATLAB计算还是比梯度下降快的，数量再往上我们可能就要选择梯度下降法了。</li></ul><p>当然梯度下降法也要选择学习率与迭代次数，这就需要我们理解代价函数，并根据此来判断。Emmm，说到这里，线性回归的内容基本就结束了，我可能会遗憾的告诉你，大部分数学建模竞赛或是机器学习问题，光靠线性回归模型基本不可能解决问题，因为真正的实际问题是线性关系的真的很少，但是这并不影响线性回归依旧是你最需要掌握的算法，这是所有其他问题的基础。</p><p>Good Luck！</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;你可能会发现这篇博客与我之前的机器学习的线性回归完全一样，没错，就是一样的。知识点都是线性回归，所以能有什么区别呢，线性回归模型都是数学模型与机器学习中最基础的模型，需要注意的是，学校老师培训的数学建模竞赛培训可能更重视原理，导致大部分同学听了个寂寞。但是往往比赛我们会使用就行，不用太过于纠结，另外题目与源代码之后补上2333。&lt;/p&gt;
&lt;h3 id=&quot;一元线性回归-单变量线性回归-Linear-Regression-with-one-variable&quot;&gt;&lt;a href=&quot;#一元线性回归-单变量线性回归-Linear-Regression-with-one-variable&quot; class=&quot;headerlink&quot; title=&quot;一元线性回归(单变量线性回归)  Linear Regression with one variable&quot;&gt;&lt;/a&gt;一元线性回归(单变量线性回归)  Linear Regression with one variable&lt;/h3&gt;
    
    </summary>
    
    
      <category term="数学建模" scheme="http://yoursite.com/categories/%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1/"/>
    
      <category term="模型篇" scheme="http://yoursite.com/categories/%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1/%E6%A8%A1%E5%9E%8B%E7%AF%87/"/>
    
    
      <category term="线性回归" scheme="http://yoursite.com/tags/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/"/>
    
  </entry>
  
</feed>
