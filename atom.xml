<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>杨文昊的个人博客</title>
  
  <subtitle>愿你出走半生，归来仍是少年。</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2020-09-26T16:33:39.227Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>Alpha Yang</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Pycharm通过ssh远程连接GPU服务器训练深度学习代码</title>
    <link href="http://yoursite.com/2020/09/26/Pycharm%E9%80%9A%E8%BF%87ssh%E8%BF%9C%E7%A8%8B%E8%BF%9E%E6%8E%A5GPU%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%AE%AD%E7%BB%83%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%BB%A3%E7%A0%81/"/>
    <id>http://yoursite.com/2020/09/26/Pycharm%E9%80%9A%E8%BF%87ssh%E8%BF%9C%E7%A8%8B%E8%BF%9E%E6%8E%A5GPU%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%AE%AD%E7%BB%83%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%BB%A3%E7%A0%81/</id>
    <published>2020-09-25T21:54:29.000Z</published>
    <updated>2020-09-26T16:33:39.227Z</updated>
    
    <content type="html"><![CDATA[<p>我相信大家在进行深度学习的科研时，都会遇到这个问题：(1) 使用的是租借的或者是实验室的云端服务器 (2) 自己在本地写代码，但是需要gpu来验证，而不是瞎眼写代码。 我平时使用python编译器基本是Pycharm，如果是轻量级的项目，我一般使用vscode (只要你用vsc我们就是异父异母的亲兄弟)。而一般写大平台项目我用的都是<strong>专业版</strong>的Pycharm，注意我以下教程的功能只能professional版本能用，community版本不能使用哦~</p><p>我这里想要把远端gpu云服务器和本地Pycharm代码项目给连接起来，这对于我们的代码调试与修改，是相当方便的。下面我就来记录一下我具体的操作过程。</p><a id="more"></a><h2 id="一、deployment远程配置"><a href="#一、deployment远程配置" class="headerlink" title="一、deployment远程配置"></a>一、deployment远程配置</h2><p><img src="/../image/d1.png" alt=""></p><p>首先我们需要配置我们的远程配置链接，打开Tools-&gt;Deployment-&gt;Configuration</p><p>然后我们点击<code>+</code>，输入服务器的IP与密码，选择<code>SFTP</code>类型，新建服务器的配置。</p><p><img src="/../image/d2.png" alt=""></p><p>最后选择<code>Mappings</code>，将本地路径与远端路径进行选择，远端路径就市部署到Linux上的路径，即本地文件上传的位置，进行保存，远端配置文件就配置完成了。</p><p><img src="/../image/d3.png" alt=""></p><h2 id="二、本地项目选择远端python解释器"><a href="#二、本地项目选择远端python解释器" class="headerlink" title="二、本地项目选择远端python解释器"></a>二、本地项目选择远端python解释器</h2><p>通过Files-&gt;settings路径进入配置界面，然后我们选择项目解释器<strong>Project Interpreter</strong>，选择ssh解释器已经存在的配置，并创造一个新copy，注意一下这里的逻辑关系，刚开始我并没有理解<code>Create</code>与<code>Move</code>的关系。</p><p><img src="/../image/d4.png" alt=""></p><p>这里如果点击<code>Move</code>则是表示把这个服务器上的默认解释器直接转移到当前项目中，并且不方便修改解释器路径(一台服务器上一般是多个python环境组成)。而<code>Create</code>选项则是创建了一个复制的环境，这样的好处显而易见，方便管理不用项目代码的连接位置，与编译器，如下图所示。</p><p><img src="/../image/d5.png" alt=""></p><p>在这里我选择的是python解释器是anaconda，由于电脑上有多个环境，而且有时候我需要使用特定的虚拟环境，那么如何知晓解释器的路径呢？打开远端服务器的命令行</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">~$ python        # 进入想要作为解释器的python环境</span><br><span class="line">&gt;&gt;&gt; import sys   </span><br><span class="line">&gt;&gt;&gt; print(sys.executable)  # 这里就是输出了python的解释器路径</span><br></pre></td></tr></table></figure><h2 id="三、将项目代码上传到远端服务器"><a href="#三、将项目代码上传到远端服务器" class="headerlink" title="三、将项目代码上传到远端服务器"></a>三、将项目代码上传到远端服务器</h2><p>最后我们还得选择上传到远端服务器的位置，这里我放在了我的文件夹中，勾选<code>Automatically upload</code>选项就是在<code>Finish</code>之后将所有项目代码自动上传。</p><p><img src="/../image/d6.png" alt=""></p><p>上传速度很快，耐心等待后，整个项目就完全部署到远端服务器上了，这时候你在本地运行，实际上代码是跑在远端服务器上的，如下图所示。</p><p><img src="/../image/d7.png" alt=""></p><p>这里可以看到，我们代码已经是跑在远端服务器上了，Pycharm这样的功能是极其方便的。</p><p>那么，如果我们需要修改某个文件的代码，还需要把所有项目重新上传吗？</p><p>这很显然，没必要，我们只需要把修改过的文件更新到远端即可。比如，我们修改了<code>test_image.py</code>文件，我们只需要右击，单独把它上传到远端，然后运行即可。</p><p><img src="/../image/d8.png" alt=""></p><p>OK，关于Pycharm如何通过ssh连接远端GPU服务器训练深度学习的代码教程就讲到这里了 ~</p><p>祝大家深度学习愉快 ~ 之后我要开始更新数模教程了</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;我相信大家在进行深度学习的科研时，都会遇到这个问题：(1) 使用的是租借的或者是实验室的云端服务器 (2) 自己在本地写代码，但是需要gpu来验证，而不是瞎眼写代码。 我平时使用python编译器基本是Pycharm，如果是轻量级的项目，我一般使用vscode (只要你用vsc我们就是异父异母的亲兄弟)。而一般写大平台项目我用的都是&lt;strong&gt;专业版&lt;/strong&gt;的Pycharm，注意我以下教程的功能只能professional版本能用，community版本不能使用哦~&lt;/p&gt;
&lt;p&gt;我这里想要把远端gpu云服务器和本地Pycharm代码项目给连接起来，这对于我们的代码调试与修改，是相当方便的。下面我就来记录一下我具体的操作过程。&lt;/p&gt;
    
    </summary>
    
    
      <category term="科研路漫漫" scheme="http://yoursite.com/categories/%E7%A7%91%E7%A0%94%E8%B7%AF%E6%BC%AB%E6%BC%AB/"/>
    
      <category term="ssh" scheme="http://yoursite.com/categories/%E7%A7%91%E7%A0%94%E8%B7%AF%E6%BC%AB%E6%BC%AB/ssh/"/>
    
    
      <category term="ssh" scheme="http://yoursite.com/tags/ssh/"/>
    
  </entry>
  
  <entry>
    <title>Django项目框架部署到远端服务器</title>
    <link href="http://yoursite.com/2020/09/22/Django%E9%A1%B9%E7%9B%AE%E6%A1%86%E6%9E%B6%E9%83%A8%E7%BD%B2%E5%88%B0%E8%BF%9C%E7%AB%AF%E6%9C%8D%E5%8A%A1%E5%99%A8/"/>
    <id>http://yoursite.com/2020/09/22/Django%E9%A1%B9%E7%9B%AE%E6%A1%86%E6%9E%B6%E9%83%A8%E7%BD%B2%E5%88%B0%E8%BF%9C%E7%AB%AF%E6%9C%8D%E5%8A%A1%E5%99%A8/</id>
    <published>2020-09-21T16:11:54.000Z</published>
    <updated>2020-09-25T13:55:27.060Z</updated>
    
    <content type="html"><![CDATA[<p>对这次web开发与项目部署进行简单的记录小结~</p><p>由于最近从事了深度学习方面的科研，实验室想将其算法落地，做成一个在线系统，于是这几天和几位朋友自学的Django框架，做了一个初步的最简单的网页，实现图像到画像的深度学习算法转换，这篇博客主要记录将做好的Django框架部署到远端的过程。</p><a id="more"></a><p>我们的系统虽然还有很多不完善的地方，但是没关系，越早把它部署到互联网上，才能越早发现线上特有的问题。现在也提倡渐进式开发，让产品在迭代中快速成长。</p><p>那么我们如何才能把Django框架推到远端呢，这里我们首先介绍下原理，其实很好理解，我们项目部署到远端，客户端发来http请求，Nginx作为直接对外的服务器接口，对http请求进行静态分析，而uwsgi则像是两个框架之间的静态“桥梁”，负责处理资源分析的问题。</p><p><img src="..\image\dj1.png" alt=""></p><p>好，下面我们来看具体的操作。</p><h2 id="一、合适的服务器与版本库需求"><a href="#一、合适的服务器与版本库需求" class="headerlink" title="一、合适的服务器与版本库需求"></a>一、合适的服务器与版本库需求</h2><p>我们把项目部署到远端服务器上，并要求能够通过公网访问。首先我们得选择一块合适的服务器，可以是阿里云，也可以是腾讯云等，区别不大，这里我直接使用的是实验室的服务器。</p><p>下面我们来讲解所有需要安装的库，这里需要注意一个问题，在我们推网站的过程中，<strong>请使用Python3.7版本来完成此事</strong>，由于实验室的服务器上当时只有conda，所以我们尝试用conda部署项目的时候，怎么也无法安装uwsgi库，最后是新建了虚拟环境才解决的，反正强烈不建议。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">~$ sudo apt-get nginx</span><br></pre></td></tr></table></figure><p>首先安装nginx版本库，使用最新的即可，下面我们通过pip3来安装剩下的支持库，在远端服务器上运行指令。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">~$ pip install uwsgi</span><br><span class="line">~$ pip install django</span><br></pre></td></tr></table></figure><p>安装两个需要依赖的库，下面一定记得检查一下，是否安装在了python3.7的库中，教大家一些简单的命令来验证。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">~$ python  # 进入python，这里会显示</span><br><span class="line">&gt;&gt;&gt; import sys   # 自带的system库</span><br><span class="line">&gt;&gt;&gt; print(sys.executable)   # 在这里可以查看python的路径与版本</span><br><span class="line">&gt;&gt;&gt; exit(0)   # 退出python</span><br><span class="line">~$ whereis python  # 查看当前主机上所有的python版本</span><br><span class="line">~$ which python  # 查看默认指向的python路径</span><br></pre></td></tr></table></figure><p>下面我再教大家如何查看自己刚刚装的第三方库的路径，这个很重要，因为之后的配置文件会让你填写进去。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">~$ python</span><br><span class="line">&gt;&gt;&gt; import django  # 检查django</span><br><span class="line">&gt;&gt;&gt; print(django.__file__)  # 这里便会输出django的安装path</span><br><span class="line">&gt;&gt;&gt; exit(0)</span><br></pre></td></tr></table></figure><p>基本上掌握了这些，然后安装完我们所需要的版本库，就能愉快地开始部署啦~</p><h2 id="二、Nginx配置与代码部署"><a href="#二、Nginx配置与代码部署" class="headerlink" title="二、Nginx配置与代码部署"></a>二、Nginx配置与代码部署</h2><p>下面我们检查下Nginx作为接受http请求的工具，是否能成功提起，我们首先在服务器(记得将你的Django项目上传到服务器上)上打开<code>/mysite/mysite/settings.py</code>，修改如下部分：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">DEBUG = <span class="literal">True</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># comment by yihao for anywhere to visit</span></span><br><span class="line"><span class="comment"># ALLOWED_HOSTS = ['10.170.60.58']</span></span><br><span class="line">ALLOWED_HOSTS = [<span class="string">'*'</span>]</span><br></pre></td></tr></table></figure><p>首先关于Debug模式，建议改成False，为了避免安全性问题。这里由于我们的网站还需要改进，为了防止报错看不到，所以暂时选择的True，但实际上线还是需要改成False。</p><p>关于<code>ALLOWED_HOSTS</code>部分，’*’表示允许所有请求，这是师兄改的，其实还可以改成域名或ip的形式，例如<code>ALLOWED_HOSTS = [&#39;ywh.com&#39;,&#39;10.170.60.58&#39;]</code></p><p>好，完成这些后，我们检查下Nginx是否能正常运行。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">~$ sudo service nginx start  # 这里必须要sudo，否则请求会被拒绝</span><br></pre></td></tr></table></figure><p>这是你就能看到Nginx的欢迎界面了，但显然这里的配置还是不可以的，现在只是提起了整个网站，现在我们还要让Nginx指向我们对应的服务器地址，这里我们进入Nginx的配置文件中。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">~$ cd &#x2F;etc&#x2F;nginx&#x2F;sites-available    # 进入配置文件</span><br></pre></td></tr></table></figure><p>这里是Nginx可以配置的地方，我们新建一个文件，命名为IP地址或已经选定的域名，或者直接本主机地址。</p><p>假设IP地址为<code>10.170.60.58</code>，新建该文件，无后缀名，并在文件中添加如下配置</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">server&#123;</span><br><span class="line">    charset utf<span class="number">-8</span>;</span><br><span class="line">    listen <span class="number">80</span>;</span><br><span class="line">    server_name <span class="number">10.170</span><span class="number">.60</span><span class="number">.58</span>;    <span class="comment"># 指定你的IP地址或域名   </span></span><br><span class="line"></span><br><span class="line">    location / &#123;</span><br><span class="line">        proxy_set_header Host $host;</span><br><span class="line">        uwsgi_pass unix:///home/amax/mysite/site.sock;     <span class="comment"># 设置监听的sock文件</span></span><br><span class="line">        include /etc/nginx/uwsgi_params;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>好接下来回到命令行，因为我们写的只是 Nginx 的可用配置，所以还需要把这个配置文件链接到在用配置上去，即<code>/etc/nginx/sites-enabled</code>路径文件中。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">amax@amax:&#x2F;etc&#x2F;nginx&#x2F;sites-available$ sudo ln -s &#x2F;etc&#x2F;nginx&#x2F;sites-available&#x2F;10.170.60.58 &#x2F;etc&#x2F;nginx&#x2F;sites-enabled</span><br></pre></td></tr></table></figure><p>至此Nginx配置完成，下面我们来配置uwsgi</p><h2 id="三、Uwsgi结构简介与配置"><a href="#三、Uwsgi结构简介与配置" class="headerlink" title="三、Uwsgi结构简介与配置"></a>三、Uwsgi结构简介与配置</h2><p>假设你有个叫做 <code>mysite</code> 的顶级项目包，期中包含一个模板 <code>mysite/wsgi.py</code>，模块包含一个 WSGI <code>application</code> 对象。如果你使用的是较新的 Django，这就是你运行 <code>django-admin startproject mysite</code> （使用你的项目名替换 <code>mysite</code>）后得到的目录结构。</p><p>那么Uwsgi包含了哪儿几个“桥梁”的部分呢？</p><p><code>uwsgi.ini</code>是我们最起始的配置文件，在这个文件中，我们对我们的桥梁进行最简单的配置。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">chdir&#x3D;&#x2F;home&#x2F;amax&#x2F;mysite</span><br><span class="line">module&#x3D;mysite.wsgi:application</span><br><span class="line">master&#x3D;True</span><br><span class="line">pidfile&#x3D;.&#x2F;mysite-master.pid</span><br><span class="line">vacuum&#x3D;True</span><br><span class="line">max-requests&#x3D;5000</span><br><span class="line">daemonize&#x3D;.&#x2F;mysite.log</span><br><span class="line">socket&#x3D;&#x2F;home&#x2F;amax&#x2F;mysite&#x2F;site.sock</span><br><span class="line">pythonpath&#x3D;&#x2F;usr&#x2F;local&#x2F;python3.7.7&#x2F;lib&#x2F;python3.7&#x2F;site-packages&#x2F;</span><br></pre></td></tr></table></figure><p>解释下这个简单的配置文件，基本上有几个重要的部分，(1) <code>pidfile</code>中其他程序可以通过这个pid文件，获取这个后台程序的pid，然后执行一些任务。这个文件在初始化<code>uwsgi.ini</code>之后，便会出现在你的顶级目录<code>mysite</code>中。 (2) <code>mysite.log</code>这里是存放项目日志的地方，以后部署项目的时候，如果出现了报错，都可以从这个地方来查询。 (3) <code>site.sock</code>时进程中产生的socket文件。(4) 而在<code>pythonpath</code>中指定的路径就是我们上述所说的python安装的第三方库的位置。</p><h2 id="四、项目部署与常用命令"><a href="#四、项目部署与常用命令" class="headerlink" title="四、项目部署与常用命令"></a>四、项目部署与常用命令</h2><p>好的，下面完成Django与uwsgi的配置后，我们就可以开始正式部署我们的项目了，在部署命令的同时，我也会给出一些常用的命令，用于开始，结束，重启或查看当前进程。</p><h3 id="Nginx"><a href="#Nginx" class="headerlink" title="Nginx"></a>Nginx</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">~$ nginx -s reload   # 重启服务，当你修改nginx文件后，记得重启nginx服务</span><br><span class="line">~$ nginx -s stop   # 停止服务</span><br></pre></td></tr></table></figure><h3 id="Uwsgi"><a href="#Uwsgi" class="headerlink" title="Uwsgi"></a>Uwsgi</h3><p>我们的Nginx服务在之前已经启动过了，下面我们开始尝试启动Uwsgi的服务，把我们的桥梁给搭起来。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">~$ uwsgi --ini uwsgi.ini  # 启动uwsgi服务，与此同时，同目录下应该会出现log，pid，sock文件</span><br><span class="line">~$ ps -ef | grep uwsgi   # 这里检查下uwsgi的进程，查看是否正常提起</span><br><span class="line">~$ killall -s INT uwsgi   # 如果uwsgi提起异常或者其他报错，建议删除所有进程，如果成功就不需要</span><br><span class="line">~$ uwsgi --reload mysite-master.pid  # 如果之后更改了uwsgi的文件，则重启服务</span><br></pre></td></tr></table></figure><p>目前为止，所有的配置与项目部署就完成了，下面通过公网的域名或IP地址即可访问了。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;对这次web开发与项目部署进行简单的记录小结~&lt;/p&gt;
&lt;p&gt;由于最近从事了深度学习方面的科研，实验室想将其算法落地，做成一个在线系统，于是这几天和几位朋友自学的Django框架，做了一个初步的最简单的网页，实现图像到画像的深度学习算法转换，这篇博客主要记录将做好的Django框架部署到远端的过程。&lt;/p&gt;
    
    </summary>
    
    
      <category term="科研路漫漫" scheme="http://yoursite.com/categories/%E7%A7%91%E7%A0%94%E8%B7%AF%E6%BC%AB%E6%BC%AB/"/>
    
      <category term="Django" scheme="http://yoursite.com/categories/%E7%A7%91%E7%A0%94%E8%B7%AF%E6%BC%AB%E6%BC%AB/Django/"/>
    
    
      <category term="Django" scheme="http://yoursite.com/tags/Django/"/>
    
  </entry>
  
  <entry>
    <title>ssh远程连接GPU服务器进行深度学习以及常用ssh命令汇总</title>
    <link href="http://yoursite.com/2020/09/05/ssh%E8%BF%9C%E7%A8%8B%E8%BF%9E%E6%8E%A5GPU%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%BF%9B%E8%A1%8C%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%BB%A5%E5%8F%8A%E5%B8%B8%E7%94%A8ssh%E5%91%BD%E4%BB%A4%E6%B1%87%E6%80%BB/"/>
    <id>http://yoursite.com/2020/09/05/ssh%E8%BF%9C%E7%A8%8B%E8%BF%9E%E6%8E%A5GPU%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%BF%9B%E8%A1%8C%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%BB%A5%E5%8F%8A%E5%B8%B8%E7%94%A8ssh%E5%91%BD%E4%BB%A4%E6%B1%87%E6%80%BB/</id>
    <published>2020-09-04T22:13:24.000Z</published>
    <updated>2020-09-25T13:53:40.794Z</updated>
    
    <content type="html"><![CDATA[<p>在我们进行深度学习的科研任务时，我们都会遇到复杂神经网络的训练问题，这时我们都不可避免地需要一块合适的gpu服务器，我认为gpu服务器的好处有两点：一是相对而言便宜一些，虽然很多gpu服务器也是昂贵的价格，我这里推荐下<a href="https://www.jikecloud.net/" target="_blank" rel="noopener">极客云</a>，这应该是我用过最便宜和稳定的服务器了，当然我现在一般用实验室的。二是gpu服务器不同于本地，大型的深度学习项目一般需要训练几天或几周才能完成，而如果训练到一半突然断电，那本地电脑就凉凉了，所以远程挂云gpu还是相当不错的。</p><a id="more"></a><h3 id="一、ssh工具"><a href="#一、ssh工具" class="headerlink" title="一、ssh工具"></a>一、ssh工具</h3><p>ssh是远程连接的关键技术，选择合适好用的ssh工具也是相当关键的，我之前也用过xshell等工具。但最后我被实验室师兄推荐了一款超级好用的ssh工具：MobaXterm (<a href="https://mobaxterm.mobatek.net/" target="_blank" rel="noopener">官网下载地址</a>)</p><p>推荐原因很简单：功能齐全，可视化界面优雅，文件操作方便</p><h4 id="1-主要功能"><a href="#1-主要功能" class="headerlink" title="1. 主要功能"></a>1. 主要功能</h4><p><img src="/../image/ssh1.png" alt=""></p><p>我一般就用<code>Session</code>模块足够，可以自动记录密码，非常方便。通常我们远程访问，操作以及使用一台gpu服务器，我们一般需要：username，ip和password。username通常是root，hit或amax等等，ip则是一串数字，10.170.这样的东西，password就是密码啦，只要点击<code>Session</code>模块，我们就能通过ssh添加我们需要访问的gpu主机信息，然后进入服务器即可。</p><p><img src="/../image/ssh4.png" alt=""></p><p>输入<code>Remote host</code>即可，输入形式为<code>username@serverIP</code>，然后输入密码，就可以访问了，愉快地在云端gpu上进行操作。</p><h4 id="2-文件操作方便"><a href="#2-文件操作方便" class="headerlink" title="2. 文件操作方便"></a>2. 文件操作方便</h4><p>文件操作一直是我一个很难整的事情，但是在这款ssh工具中，可视化效果非常好，可以直接看到gpu的所有目录信息。</p><p><img src="/../image/ssh2.png" alt=""></p><p>还有文件的上传下载与删除等问题，虽然这些利用命令都能实现，但给出了可视化的解决方案，还是相当不错的。</p><p><img src="/../image/ssh3.png" alt=""></p><h3 id="二、通过ssh远程访问GPU的Jupyter-Notebook"><a href="#二、通过ssh远程访问GPU的Jupyter-Notebook" class="headerlink" title="二、通过ssh远程访问GPU的Jupyter Notebook"></a>二、通过ssh远程访问GPU的Jupyter Notebook</h3><p>我们编写python经常会遇到jupyter notebook的格式，即ipynb，实际上这也是经常使用的机器学习训练方法，当然做工程pycharm应该更合适。这里我们讲解如何通过ssh远程访问GPU上的Jupyter Notebook，并将它在本地电脑上可视化，分为两个步骤即可。</p><h4 id="1-首先在远程GPU服务器的terminal上启动Jupyter-Notebook的服务"><a href="#1-首先在远程GPU服务器的terminal上启动Jupyter-Notebook的服务" class="headerlink" title="1. 首先在远程GPU服务器的terminal上启动Jupyter Notebook的服务"></a>1. 首先在远程GPU服务器的terminal上启动Jupyter Notebook的服务</h4><p>在终端输入以下代码：</p><figure class="highlight cmd"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jupyter notebook --no-browser --port=<span class="number">8889</span></span><br></pre></td></tr></table></figure><p>将远端的Jupyter端口设置为8889.</p><h4 id="2-然后在本地terminal上启动ssh，对接端口"><a href="#2-然后在本地terminal上启动ssh，对接端口" class="headerlink" title="2. 然后在本地terminal上启动ssh，对接端口"></a>2. 然后在本地terminal上启动ssh，对接端口</h4><p>在本地终端cmd输入以下代码：</p><figure class="highlight cmd"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh -N -f -L localhost:<span class="number">8888</span>:localhost:<span class="number">8889</span> username@serverIP</span><br></pre></td></tr></table></figure><p>-N 告诉SSH没有命令要被远程执行； -f 告诉SSH在后台执行； -L 是指定port forwarding的配置，远端端口是8889，本地的端口号的8888。</p><h4 id="4-最后启动本地端口，并输入指令"><a href="#4-最后启动本地端口，并输入指令" class="headerlink" title="4. 最后启动本地端口，并输入指令"></a>4. 最后启动本地端口，并输入指令</h4><p>最后打开浏览器访问：<a href="http://localhost:8888/" target="_blank" rel="noopener">http://localhost:8888/</a></p><p>如果是第一次访问，他会让你输入远程端给出的指令，即token密码，可由ssh工具终端的界面上复制粘贴获得。</p><p><img src="/../image/ssh5.png" alt=""></p><p>输入token即可远程访问jupyter的内容了。</p><h3 id="三、常用ssh命令汇总"><a href="#三、常用ssh命令汇总" class="headerlink" title="三、常用ssh命令汇总"></a>三、常用ssh命令汇总</h3><h4 id="1-目录操作"><a href="#1-目录操作" class="headerlink" title="1.目录操作"></a>1.目录操作</h4><figure class="highlight cmd"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span>                                      // 前进</span><br><span class="line"><span class="built_in">cd</span> ..                                   // 后退一级</span><br><span class="line">ls                                      // 查看当前目录下的所有目录和文件</span><br><span class="line"><span class="built_in">mkdir</span> new_dir                           // 新建名为"new_dir"的文件夹</span><br><span class="line">pwd                                     // 显示当前位置路径</span><br></pre></td></tr></table></figure><h4 id="2-文件操作"><a href="#2-文件操作" class="headerlink" title="2. 文件操作"></a>2. 文件操作</h4><figure class="highlight cmd"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">touch a.txt                             // 在当前目录下新增文件a.txt</span><br><span class="line">rm a.txt                                // 删除文件a.txt</span><br><span class="line">tar -zcvf test.zip test                 // 文件打包，将文件夹test打包为文件包test.zip</span><br><span class="line">unzip test.zip                          // 解压文件test.zip</span><br><span class="line">mv a.txt b.txt                          // 将文件a.txt重命名为b.txt </span><br><span class="line">mv /a /b /c                             // 将目录a移动到目录b下，并重新命名为目录c</span><br></pre></td></tr></table></figure><p>未完待续…</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在我们进行深度学习的科研任务时，我们都会遇到复杂神经网络的训练问题，这时我们都不可避免地需要一块合适的gpu服务器，我认为gpu服务器的好处有两点：一是相对而言便宜一些，虽然很多gpu服务器也是昂贵的价格，我这里推荐下&lt;a href=&quot;https://www.jikecloud.net/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;极客云&lt;/a&gt;，这应该是我用过最便宜和稳定的服务器了，当然我现在一般用实验室的。二是gpu服务器不同于本地，大型的深度学习项目一般需要训练几天或几周才能完成，而如果训练到一半突然断电，那本地电脑就凉凉了，所以远程挂云gpu还是相当不错的。&lt;/p&gt;
    
    </summary>
    
    
      <category term="科研路漫漫" scheme="http://yoursite.com/categories/%E7%A7%91%E7%A0%94%E8%B7%AF%E6%BC%AB%E6%BC%AB/"/>
    
      <category term="ssh" scheme="http://yoursite.com/categories/%E7%A7%91%E7%A0%94%E8%B7%AF%E6%BC%AB%E6%BC%AB/ssh/"/>
    
    
      <category term="深度学习" scheme="http://yoursite.com/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>【进阶篇】MATLAB科研制图常用代码命令</title>
    <link href="http://yoursite.com/2020/07/13/%E3%80%90%E8%BF%9B%E9%98%B6%E7%AF%87%E3%80%91MATLAB%E7%A7%91%E7%A0%94%E5%88%B6%E5%9B%BE%E5%B8%B8%E7%94%A8%E4%BB%A3%E7%A0%81%E5%91%BD%E4%BB%A4/"/>
    <id>http://yoursite.com/2020/07/13/%E3%80%90%E8%BF%9B%E9%98%B6%E7%AF%87%E3%80%91MATLAB%E7%A7%91%E7%A0%94%E5%88%B6%E5%9B%BE%E5%B8%B8%E7%94%A8%E4%BB%A3%E7%A0%81%E5%91%BD%E4%BB%A4/</id>
    <published>2020-07-12T23:55:11.000Z</published>
    <updated>2020-07-13T05:07:24.571Z</updated>
    
    <content type="html"><![CDATA[<p>本博客基于上一篇的基础上做了一些稍微进阶的命令汇总，由于本人很菜，所以这些命令可能对于大佬而言，依旧是基础，所以请大佬们略过轻喷。在这部分内容中，我添加了一些实用的以及我喜欢用的绘图方式，例如坐标轴绘制等等，本博客也会持续更新，包括三维颜色填充等等内容。</p><ul><li>绘制三维图形</li><li>设置坐标轴范围</li><li>绘制坐标轴箭头</li><li>绘制非线型箭头</li></ul><a id="more"></a><h4 id="绘制三维图形"><a href="#绘制三维图形" class="headerlink" title="绘制三维图形"></a>绘制三维图形</h4><p>在一些特定的问题里，二维已经不能满足我们的研究需求了，这时我们需要绘制三维的图形，其实很简单，其他基本的命令与二维图形完全一样，只需要使用<code>plot3</code>即可。我们这里绘制两条三维曲线，分别是$y_1=2cos(x),z_1=2sin(x)$和$y_2=sin(x),z_2=cos(x)$。学过物理的人都知道，这是两条螺旋曲线。</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">clear,clc</span><br><span class="line">x = <span class="built_in">linspace</span>(<span class="number">0</span>,<span class="number">20</span>,<span class="number">1000</span>); </span><br><span class="line">y1 = <span class="number">2</span>*<span class="built_in">cos</span>(x);</span><br><span class="line">z1 = <span class="number">2</span>*<span class="built_in">sin</span>(x);</span><br><span class="line">y2 = <span class="built_in">sin</span>(x);</span><br><span class="line">z2 = <span class="built_in">cos</span>(x);</span><br><span class="line"><span class="built_in">figure</span>(<span class="number">3</span>);</span><br><span class="line"><span class="built_in">plot3</span>(x,y1,z1,<span class="string">'r'</span>,<span class="string">'LineWidth'</span>,<span class="number">1.5</span>);</span><br><span class="line"><span class="built_in">hold</span> on</span><br><span class="line"><span class="built_in">plot3</span>(x,y2,z2,<span class="string">'b:'</span>,<span class="string">'LineWidth'</span>,<span class="number">1.5</span>);</span><br><span class="line">grid on</span><br><span class="line">xlabel(<span class="string">'x'</span>); ylabel(<span class="string">'y'</span>);zlabel(<span class="string">'z'</span>);</span><br><span class="line">set(gca,<span class="string">'Fontname'</span>,<span class="string">'Monospaced'</span>,<span class="string">'Fontsize'</span>,<span class="number">10</span>,<span class="string">'FontWeight'</span>,<span class="string">'bold'</span>);</span><br><span class="line">title(<span class="string">'三维例子：x\sim y_1,y_2 \sim z_1,z_2'</span>);</span><br></pre></td></tr></table></figure><p>效果如下图所示：</p><p><img src="/../image/mat6.png" alt=""></p><h4 id="设置坐标轴范围"><a href="#设置坐标轴范围" class="headerlink" title="设置坐标轴范围"></a>设置坐标轴范围</h4><p>在科研制图的过程中，我们还常常遇到一个非常常见的问题，就是坐标轴的范围选定，例如在上一张所示的图片中，我们可以很清楚地看到，由于x的范围在[0,20]之间，所以绘图默认的x轴坐标也是[0,20]，y轴与z轴同理。如果为了能使得整个坐标轴不那么挤，在这种情况下，我们通常想让整个图像的坐标范围变大一些，例如x轴我们希望范围为[0,25]，y轴我们希望范围为[-3,3]，z轴我们希望范围为[-3,3]。我们可以用以下方法：</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">clear,clc</span><br><span class="line">x = <span class="built_in">linspace</span>(<span class="number">0</span>,<span class="number">20</span>,<span class="number">1000</span>); </span><br><span class="line">y1 = <span class="number">2</span>*<span class="built_in">cos</span>(x);</span><br><span class="line">z1 = <span class="number">2</span>*<span class="built_in">sin</span>(x);</span><br><span class="line">y2 = <span class="built_in">sin</span>(x);</span><br><span class="line">z2 = <span class="built_in">cos</span>(x);</span><br><span class="line"><span class="built_in">figure</span>(<span class="number">3</span>);</span><br><span class="line"><span class="built_in">plot3</span>(x,y1,z1,<span class="string">'r'</span>,<span class="string">'LineWidth'</span>,<span class="number">1.5</span>);</span><br><span class="line"><span class="built_in">hold</span> on</span><br><span class="line"><span class="built_in">plot3</span>(x,y2,z2,<span class="string">'b:'</span>,<span class="string">'LineWidth'</span>,<span class="number">1.5</span>);</span><br><span class="line">grid on</span><br><span class="line">set(gca,<span class="string">'XLim'</span>,[<span class="number">0</span> <span class="number">25</span>]); <span class="comment">% 设置x轴的范围为[0,25]</span></span><br><span class="line">set(gca,<span class="string">'YLim'</span>,[<span class="number">-3</span> <span class="number">3</span>]);</span><br><span class="line">set(gca,<span class="string">'ZLim'</span>,[<span class="number">-3</span> <span class="number">3</span>]);</span><br><span class="line">xlabel(<span class="string">'x'</span>); ylabel(<span class="string">'y'</span>);zlabel(<span class="string">'z'</span>);</span><br><span class="line">set(gca,<span class="string">'Fontname'</span>,<span class="string">'Monospaced'</span>,<span class="string">'Fontsize'</span>,<span class="number">10</span>,<span class="string">'FontWeight'</span>,<span class="string">'bold'</span>);</span><br><span class="line">title(<span class="string">'三维例子：x\sim y_1,y_2 \sim z_1,z_2'</span>);</span><br></pre></td></tr></table></figure><p>效果如下图所示：</p><p><img src="/../image/mat7.png" alt=""></p><h4 id="绘制坐标轴箭头"><a href="#绘制坐标轴箭头" class="headerlink" title="绘制坐标轴箭头"></a>绘制坐标轴箭头</h4><p>绘制坐标轴的箭头是困扰了我很久的问题，我使用过非常多的办法，但通常往往差强人意或者新版本的编译错误，这里我提供一个很好用的函数<code>arrow.m</code>，我把它放在了我的github仓库<a href="https://github.com/Alpha-Yang/Matlab_arrowPlot" target="_blank" rel="noopener">Matlab_arrowPlot</a>中，大家可自行下载使用。下面我来说明该函数的使用方法，该函数不光可以画坐标轴，所有箭头都是同理。</p><p><code>arrow.m</code>函数绘制命令如下<code>arrow([x1 y1],[x2 y2])</code>，(三维也同理)表示绘制从(x1,y1)到(x2,y2)的箭头，非框图坐标是大家自己定义的坐标轴。还有两个我通常使用的命令，<code>BaseAngle</code>设置箭头的夹角，我通常设置30，以及<code>LineWidth</code>设置1即可。</p><p>下面我们来绘制上图的坐标轴，比如x轴绘制从(0,0,0)到(25,0,0)，y轴绘制从(0,-3,0)到(0,3,0)，z轴绘制从(0,0,-3)到(0,0,3)，好让我们直接来看代码。</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">clear,clc</span><br><span class="line">x = <span class="built_in">linspace</span>(<span class="number">0</span>,<span class="number">20</span>,<span class="number">1000</span>); </span><br><span class="line">y1 = <span class="number">2</span>*<span class="built_in">cos</span>(x);</span><br><span class="line">z1 = <span class="number">2</span>*<span class="built_in">sin</span>(x);</span><br><span class="line">y2 = <span class="built_in">sin</span>(x);</span><br><span class="line">z2 = <span class="built_in">cos</span>(x);</span><br><span class="line"><span class="built_in">figure</span>(<span class="number">3</span>);</span><br><span class="line"><span class="built_in">plot3</span>(x,y1,z1,<span class="string">'r'</span>,<span class="string">'LineWidth'</span>,<span class="number">1.5</span>);</span><br><span class="line"><span class="built_in">hold</span> on</span><br><span class="line"><span class="built_in">plot3</span>(x,y2,z2,<span class="string">'b:'</span>,<span class="string">'LineWidth'</span>,<span class="number">1.5</span>);</span><br><span class="line">grid on</span><br><span class="line">set(gca,<span class="string">'XLim'</span>,[<span class="number">0</span> <span class="number">25</span>]);</span><br><span class="line">set(gca,<span class="string">'YLim'</span>,[<span class="number">-3</span> <span class="number">3</span>]);</span><br><span class="line">set(gca,<span class="string">'ZLim'</span>,[<span class="number">-3</span> <span class="number">3</span>]);</span><br><span class="line">xlabel(<span class="string">'x'</span>); ylabel(<span class="string">'y'</span>);zlabel(<span class="string">'z'</span>);</span><br><span class="line">arrow([<span class="number">0</span> <span class="number">0</span> <span class="number">0</span>],[<span class="number">25</span> <span class="number">0</span> <span class="number">0</span>],<span class="string">'BaseAngle'</span>,<span class="number">30</span>,<span class="string">'LineWidth'</span>,<span class="number">1</span>); <span class="comment">% x轴绘制从(0,0,0)到(25,0,0)</span></span><br><span class="line">arrow([<span class="number">0</span> <span class="number">-3</span> <span class="number">0</span>],[<span class="number">0</span> <span class="number">3</span> <span class="number">0</span>],<span class="string">'BaseAngle'</span>,<span class="number">30</span>,<span class="string">'LineWidth'</span>,<span class="number">1</span>); <span class="comment">% y轴绘制从(0,-3,0)到(0,3,0)</span></span><br><span class="line">arrow([<span class="number">0</span> <span class="number">0</span> <span class="number">-3</span>],[<span class="number">0</span> <span class="number">0</span> <span class="number">3</span>],<span class="string">'BaseAngle'</span>,<span class="number">30</span>,<span class="string">'LineWidth'</span>,<span class="number">1</span>); <span class="comment">% z轴绘制从(0,0,-3)到(0,0,3)</span></span><br><span class="line">set(gca,<span class="string">'Fontname'</span>,<span class="string">'Monospaced'</span>,<span class="string">'Fontsize'</span>,<span class="number">10</span>,<span class="string">'FontWeight'</span>,<span class="string">'bold'</span>);</span><br><span class="line">title(<span class="string">'三维例子：x\sim y_1,y_2 \sim z_1,z_2'</span>);</span><br></pre></td></tr></table></figure><p>效果如下图所示，再次强调不光是坐标轴箭头，坐标空间任意两点的箭头都可以绘制：</p><p><img src="/../image/mat8.png" alt=""></p><h4 id="绘制非线型箭头"><a href="#绘制非线型箭头" class="headerlink" title="绘制非线型箭头"></a>绘制非线型箭头</h4><p>在我们绘图的过程中，我们还有另外一种情况，就是我们想表示某条曲线的变化趋势，比如$sin(x)$，我们希望在正弦函数上绘制一些箭头来表示，同样我找到了开源的绘制代码，放在了我的github仓库<a href="https://github.com/Alpha-Yang/Matlab_arrowPlot" target="_blank" rel="noopener">Matlab_arrowPlot</a>中。</p><p>使用<code>arrowPlot.m</code>函数绘制非线型箭头，<code>arrowPlot(x,y)</code>代表绘制x,y曲线上的箭头，常用的命令还有<code>number</code>代表曲线上的箭头个数，<code>LineWidth</code>代表线宽，<code>color</code>代表颜色。</p><p>例如以下的example：</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">clear,clc</span><br><span class="line">t = [<span class="number">0</span>:<span class="number">0.01</span>:<span class="number">20</span>];</span><br><span class="line">x = t.*<span class="built_in">cos</span>(t);</span><br><span class="line">y = t.*<span class="built_in">sin</span>(t);</span><br><span class="line">arrowPlot(x, y, <span class="string">'number'</span>, <span class="number">5</span>, <span class="string">'color'</span>, <span class="string">'r'</span>, <span class="string">'LineWidth'</span>, <span class="number">1</span>)</span><br></pre></td></tr></table></figure><p>效果图如下图所示，可惜的是此函数暂不支持三维图形的箭头绘制：</p><p><img src="/../image/mat9.png" alt=""></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本博客基于上一篇的基础上做了一些稍微进阶的命令汇总，由于本人很菜，所以这些命令可能对于大佬而言，依旧是基础，所以请大佬们略过轻喷。在这部分内容中，我添加了一些实用的以及我喜欢用的绘图方式，例如坐标轴绘制等等，本博客也会持续更新，包括三维颜色填充等等内容。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;绘制三维图形&lt;/li&gt;
&lt;li&gt;设置坐标轴范围&lt;/li&gt;
&lt;li&gt;绘制坐标轴箭头&lt;/li&gt;
&lt;li&gt;绘制非线型箭头&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    
      <category term="科研路漫漫" scheme="http://yoursite.com/categories/%E7%A7%91%E7%A0%94%E8%B7%AF%E6%BC%AB%E6%BC%AB/"/>
    
      <category term="科研制图" scheme="http://yoursite.com/categories/%E7%A7%91%E7%A0%94%E8%B7%AF%E6%BC%AB%E6%BC%AB/%E7%A7%91%E7%A0%94%E5%88%B6%E5%9B%BE/"/>
    
    
      <category term="MATLAB" scheme="http://yoursite.com/tags/MATLAB/"/>
    
  </entry>
  
  <entry>
    <title>【基础篇】MATLAB科研制图常用代码命令</title>
    <link href="http://yoursite.com/2020/07/13/%E3%80%90%E5%9F%BA%E7%A1%80%E7%AF%87%E3%80%91MATLAB%E7%A7%91%E7%A0%94%E5%88%B6%E5%9B%BE%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/"/>
    <id>http://yoursite.com/2020/07/13/%E3%80%90%E5%9F%BA%E7%A1%80%E7%AF%87%E3%80%91MATLAB%E7%A7%91%E7%A0%94%E5%88%B6%E5%9B%BE%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/</id>
    <published>2020-07-12T22:20:01.000Z</published>
    <updated>2020-07-12T16:09:04.035Z</updated>
    
    <content type="html"><![CDATA[<p>最近更新了不少关于数学建模算法与机器学习的博客，今天我来写写关于科研制图的MATLAB常用命令，众所周知，在未来的科研生涯中，只要是学工科的同学们，MATLAB都是大家必学的工具之一，而发paper中的制图更是重中之重，虽然科研制图讲究一个<strong>“丑”</strong>，但是不会画想必是不行的。本文应该是持续更新的，本博客我会总结一些较为细节处理的代码，如果你是个使用MATLAB科研制图的小白，我会强烈推荐<a href="https://www.bilibili.com/video/BV1GJ41137UH?p=5" target="_blank" rel="noopener">b站郭彦甫的MATLAB入门教程</a>，是我特别推荐的视屏系列。当然现在python科研制图也十分流行了，之后我也会整理。</p><a id="more"></a><h4 id="清屏、清除所有变量"><a href="#清屏、清除所有变量" class="headerlink" title="清屏、清除所有变量"></a>清屏、清除所有变量</h4><p>我有个习惯就是每个主程序的开头我都会清除所有变量以及进行清屏操作，这个习惯我个人认为还是防止我们代码重复运行的有效办法。</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">clear,clc <span class="comment">% clear清除所有变量，clc清屏</span></span><br></pre></td></tr></table></figure><h4 id="在同一坐标系下绘制多条曲线"><a href="#在同一坐标系下绘制多条曲线" class="headerlink" title="在同一坐标系下绘制多条曲线"></a>在同一坐标系下绘制多条曲线</h4><p>这依然是个十分基础的问题，我们可以使用<code>hold on</code>命令，这个命令在matlab中就是继续使用当前坐标轴的意思，与之对应的是<code>hold off</code>。当然大部分时候，后半部分命令可以不用写，下面我们以$y_1=2cos(x),y_2=sin(2x),y_3=3sin(x)$为例，进行图的绘制。</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">clear,clc</span><br><span class="line">x = <span class="built_in">linspace</span>(<span class="number">0</span>,<span class="number">20</span>,<span class="number">1000</span>); <span class="comment">% linspace(a,b,k)表示在区间[a,b]中任取k个点</span></span><br><span class="line">y1 = <span class="number">2</span>*<span class="built_in">cos</span>(x);</span><br><span class="line">y2 = <span class="built_in">sin</span>(<span class="number">2</span>*x);</span><br><span class="line">y3 = <span class="number">3</span>*<span class="built_in">sin</span>(x);</span><br><span class="line"><span class="built_in">figure</span>(<span class="number">1</span>); <span class="comment">% 其实可以不写，代表图画框1，但是通常为了标记图像，我一般都会这样写</span></span><br><span class="line"><span class="built_in">plot</span>(x,y1);</span><br><span class="line"><span class="built_in">hold</span> on <span class="comment">% 只需要一个hold on就可以了</span></span><br><span class="line"><span class="built_in">plot</span>(x,y2);</span><br><span class="line"><span class="built_in">plot</span>(x,y3);</span><br></pre></td></tr></table></figure><p>绘制效果如下图所示：</p><p><img src="/../image/mat1.png" alt=""></p><h4 id="在不同坐标系下绘制曲线，同框显示"><a href="#在不同坐标系下绘制曲线，同框显示" class="headerlink" title="在不同坐标系下绘制曲线，同框显示"></a>在不同坐标系下绘制曲线，同框显示</h4><p>相信学过的人都知道，这种情况我们一般使用<code>subplot</code>这样的命令，<code>subplot(a,b,k)</code>命令一般出现于每个<code>plot</code>命令前，代表的意思是绘制a*b的框图，目前绘制第k个图(顺序从上至下，从左至右)，比如我们实现以下代码会发生什么情况？</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">clear,clc</span><br><span class="line">x = <span class="built_in">linspace</span>(<span class="number">0</span>,<span class="number">20</span>,<span class="number">1000</span>);</span><br><span class="line">y1 = <span class="number">2</span>*<span class="built_in">cos</span>(x);</span><br><span class="line">y2 = <span class="built_in">sin</span>(<span class="number">2</span>*x);</span><br><span class="line">y3 = <span class="number">3</span>*<span class="built_in">sin</span>(x);</span><br><span class="line"><span class="comment">% figure 1: 2*3</span></span><br><span class="line"><span class="built_in">figure</span>(<span class="number">1</span>);</span><br><span class="line">subplot(<span class="number">2</span>,<span class="number">3</span>,<span class="number">1</span>); <span class="built_in">plot</span>(x,y1);</span><br><span class="line">subplot(<span class="number">2</span>,<span class="number">3</span>,<span class="number">2</span>); <span class="built_in">plot</span>(x,y2);</span><br><span class="line">subplot(<span class="number">2</span>,<span class="number">3</span>,<span class="number">3</span>); <span class="built_in">plot</span>(x,y3);</span><br><span class="line">subplot(<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>); <span class="built_in">plot</span>(x,y1);</span><br><span class="line">subplot(<span class="number">2</span>,<span class="number">3</span>,<span class="number">5</span>); <span class="built_in">plot</span>(x,y2);</span><br><span class="line">subplot(<span class="number">2</span>,<span class="number">3</span>,<span class="number">6</span>); <span class="built_in">plot</span>(x,y3);</span><br><span class="line"><span class="comment">% figure 2: 3*2</span></span><br><span class="line"><span class="built_in">figure</span>(<span class="number">2</span>);</span><br><span class="line">subplot(<span class="number">3</span>,<span class="number">2</span>,<span class="number">1</span>); <span class="built_in">plot</span>(x,y1);</span><br><span class="line">subplot(<span class="number">3</span>,<span class="number">2</span>,<span class="number">2</span>); <span class="built_in">plot</span>(x,y2);</span><br><span class="line">subplot(<span class="number">3</span>,<span class="number">2</span>,<span class="number">3</span>); <span class="built_in">plot</span>(x,y3);</span><br><span class="line">subplot(<span class="number">3</span>,<span class="number">2</span>,<span class="number">4</span>); <span class="built_in">plot</span>(x,y1);</span><br><span class="line">subplot(<span class="number">3</span>,<span class="number">2</span>,<span class="number">5</span>); <span class="built_in">plot</span>(x,y2);</span><br><span class="line">subplot(<span class="number">3</span>,<span class="number">2</span>,<span class="number">6</span>); <span class="built_in">plot</span>(x,y3);</span><br></pre></td></tr></table></figure><p>绘制效果如下图所示：</p><p><img src="/../image/mat2.png" alt=""></p><h4 id="开启坐标轴网格"><a href="#开启坐标轴网格" class="headerlink" title="开启坐标轴网格"></a>开启坐标轴网格</h4><p>在我们绘图的时候这样白色的界面实际上真的非常影响我们的对于数据分布情况的总结，于是我们想在坐标轴中添加相应的分割线，采用<code>grid on</code>命令即可。</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">clear,clc</span><br><span class="line">x = <span class="built_in">linspace</span>(<span class="number">0</span>,<span class="number">20</span>,<span class="number">1000</span>); </span><br><span class="line">y1 = <span class="number">2</span>*<span class="built_in">cos</span>(x);</span><br><span class="line">y2 = <span class="built_in">sin</span>(<span class="number">2</span>*x);</span><br><span class="line">y3 = <span class="number">3</span>*<span class="built_in">sin</span>(x);</span><br><span class="line"><span class="built_in">figure</span>(<span class="number">1</span>); </span><br><span class="line"><span class="built_in">plot</span>(x,y1);</span><br><span class="line"><span class="built_in">hold</span> on </span><br><span class="line"><span class="built_in">plot</span>(x,y2);</span><br><span class="line"><span class="built_in">plot</span>(x,y3);</span><br><span class="line">grid on</span><br></pre></td></tr></table></figure><p>效果如下图所示：</p><p><img src="/../image/mat3.png" alt=""></p><h4 id="改变曲线颜色，设置线宽"><a href="#改变曲线颜色，设置线宽" class="headerlink" title="改变曲线颜色，设置线宽"></a>改变曲线颜色，设置线宽</h4><p>在我们绘图的时候设置曲线的颜色同样重要，如果我们不设置的话，matlab会给所有曲线默认的颜色排列，以及宽度(默认1)。然而，事实上我们知道，通常我们并不适合他给的颜色以及默认线宽有些太细了。先来说说，matlab如何调整曲线颜色以及坐标点的问题，大家可参考博客：<a href="https://blog.csdn.net/sinat_21026543/article/details/80215281" target="_blank" rel="noopener">Matlab画图常用的符号和颜色</a></p><p>同样我们其实还有其他方法调整颜色，我们知道颜色的表示都是使用三维向量RGB表示，所以我们可以调整参数，来调整曲线的特殊颜色，如深红浅红等等。先上代码：</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">clear,clc</span><br><span class="line">x = <span class="built_in">linspace</span>(<span class="number">0</span>,<span class="number">20</span>,<span class="number">1000</span>); </span><br><span class="line">y1 = <span class="number">2</span>*<span class="built_in">cos</span>(x);</span><br><span class="line">y2 = <span class="built_in">sin</span>(<span class="number">2</span>*x);</span><br><span class="line">y3 = <span class="number">3</span>*<span class="built_in">sin</span>(x);</span><br><span class="line"><span class="built_in">figure</span>(<span class="number">1</span>); </span><br><span class="line"><span class="built_in">plot</span>(x,y1,<span class="string">'k'</span>,<span class="string">'LineWidth'</span>,<span class="number">1.5</span>); <span class="comment">% 黑色线性曲线，曲线宽度为1.5，我通常使用的线宽</span></span><br><span class="line"><span class="built_in">hold</span> on </span><br><span class="line"><span class="built_in">plot</span>(x,y2,<span class="string">'Color'</span>,[<span class="number">0.7</span> <span class="number">0</span> <span class="number">0</span>],<span class="string">'LineWidth'</span>,<span class="number">1.5</span>); <span class="comment">% RGB的R为0.7即深红</span></span><br><span class="line"><span class="built_in">plot</span>(x,y3,<span class="string">'b:'</span>,<span class="string">'LineWidth'</span>,<span class="number">1.5</span>); <span class="comment">% 蓝色虚线的曲线</span></span><br><span class="line">grid on</span><br></pre></td></tr></table></figure><p>效果图如下：</p><p><img src="/../image/mat4.png" alt=""></p><h4 id="设置坐标轴、标题与图例"><a href="#设置坐标轴、标题与图例" class="headerlink" title="设置坐标轴、标题与图例"></a>设置坐标轴、标题与图例</h4><p>最后一个基础的命令，就是设置坐标轴与图例。这两个命令都十分简单，分别使用<code>xlabel(&#39;x轴名称&#39;)</code>与<code>legend(&#39;第1条曲线名称&#39;,&#39;第2条曲线名称&#39;,&#39;第3条曲线名称&#39;)</code>。当然也可以这样设置y轴，z轴都没问题。关于标题的设置，<code>title</code>命令就能搞定，但是matlab往往不支持中文的格式，也就是说如果你在标题、坐标轴或图例中出现中文，往往会引发乱码。我在网上找到了一个比较不错的办法，就是添加一条命令<code>set(gca,&#39;Fontname&#39;,&#39;Monospaced&#39;,&#39;Fontsize&#39;,10,&#39;FontWeight&#39;,&#39;bold&#39;);</code>便可解决无法用中文命令标题的问题，当然你使用英文就不需要这行命令了。btw，所有matlab的文字部分都支持的是latex语法。</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">clear,clc</span><br><span class="line">x = <span class="built_in">linspace</span>(<span class="number">0</span>,<span class="number">20</span>,<span class="number">1000</span>); </span><br><span class="line">y1 = <span class="number">2</span>*<span class="built_in">cos</span>(x);</span><br><span class="line">y2 = <span class="built_in">sin</span>(<span class="number">2</span>*x);</span><br><span class="line">y3 = <span class="number">3</span>*<span class="built_in">sin</span>(x);</span><br><span class="line"><span class="built_in">figure</span>(<span class="number">1</span>); </span><br><span class="line"><span class="built_in">plot</span>(x,y1,<span class="string">'k'</span>,<span class="string">'LineWidth'</span>,<span class="number">1.5</span>); <span class="comment">% 黑色线性曲线，曲线宽度为1.5，我通常使用的线宽</span></span><br><span class="line"><span class="built_in">hold</span> on </span><br><span class="line"><span class="built_in">plot</span>(x,y2,<span class="string">'Color'</span>,[<span class="number">0.7</span> <span class="number">0</span> <span class="number">0</span>],<span class="string">'LineWidth'</span>,<span class="number">1.5</span>); <span class="comment">% RGB的R为0.7即深红</span></span><br><span class="line"><span class="built_in">plot</span>(x,y3,<span class="string">'b:'</span>,<span class="string">'LineWidth'</span>,<span class="number">1.5</span>); <span class="comment">% 蓝色虚线的曲线</span></span><br><span class="line">grid on</span><br><span class="line">xlabel(<span class="string">'x'</span>); ylabel(<span class="string">'y'</span>);</span><br><span class="line"><span class="built_in">legend</span>(<span class="string">'y_1'</span>,<span class="string">'y_2'</span>,<span class="string">'y_3'</span>); </span><br><span class="line">set(gca,<span class="string">'Fontname'</span>,<span class="string">'Monospaced'</span>,<span class="string">'Fontsize'</span>,<span class="number">10</span>,<span class="string">'FontWeight'</span>,<span class="string">'bold'</span>);</span><br><span class="line">title(<span class="string">'例子：x\sim y_1,y_2,y_3'</span>);</span><br></pre></td></tr></table></figure><p>效果图如下图所示：</p><p><img src="/../image/mat5.png" alt=""></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;最近更新了不少关于数学建模算法与机器学习的博客，今天我来写写关于科研制图的MATLAB常用命令，众所周知，在未来的科研生涯中，只要是学工科的同学们，MATLAB都是大家必学的工具之一，而发paper中的制图更是重中之重，虽然科研制图讲究一个&lt;strong&gt;“丑”&lt;/strong&gt;，但是不会画想必是不行的。本文应该是持续更新的，本博客我会总结一些较为细节处理的代码，如果你是个使用MATLAB科研制图的小白，我会强烈推荐&lt;a href=&quot;https://www.bilibili.com/video/BV1GJ41137UH?p=5&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;b站郭彦甫的MATLAB入门教程&lt;/a&gt;，是我特别推荐的视屏系列。当然现在python科研制图也十分流行了，之后我也会整理。&lt;/p&gt;
    
    </summary>
    
    
      <category term="科研路漫漫" scheme="http://yoursite.com/categories/%E7%A7%91%E7%A0%94%E8%B7%AF%E6%BC%AB%E6%BC%AB/"/>
    
      <category term="科研制图" scheme="http://yoursite.com/categories/%E7%A7%91%E7%A0%94%E8%B7%AF%E6%BC%AB%E6%BC%AB/%E7%A7%91%E7%A0%94%E5%88%B6%E5%9B%BE/"/>
    
    
      <category term="MATLAB" scheme="http://yoursite.com/tags/MATLAB/"/>
    
  </entry>
  
  <entry>
    <title>【降维模型】主成分分析PCA</title>
    <link href="http://yoursite.com/2020/07/10/%E3%80%90%E9%99%8D%E7%BB%B4%E6%A8%A1%E5%9E%8B%E3%80%91%E4%B8%BB%E6%88%90%E5%88%86%E5%88%86%E6%9E%90PCA/"/>
    <id>http://yoursite.com/2020/07/10/%E3%80%90%E9%99%8D%E7%BB%B4%E6%A8%A1%E5%9E%8B%E3%80%91%E4%B8%BB%E6%88%90%E5%88%86%E5%88%86%E6%9E%90PCA/</id>
    <published>2020-07-10T15:09:52.000Z</published>
    <updated>2020-08-27T14:24:31.686Z</updated>
    
    <content type="html"><![CDATA[<p><strong>主成分分析(Principal Component Analysis)</strong>的主要目的是希望用较少的变量去解释原来资料中的大部分变异，选出比原始特征值个数少的变量，构建能解释最终输出的新变量，即为主成分，简单而言，如果我们有题目给出了十几个变量制约的数学模型，我们便可通过PCA将其变化成为4个、5个变量制约的数学模型，这就是所谓的<strong>降维模型(Dimensionality Reduction Model)</strong>。</p><a id="more"></a><h3 id="数据压缩-Data-Compression"><a href="#数据压缩-Data-Compression" class="headerlink" title="数据压缩(Data Compression)"></a>数据压缩(Data Compression)</h3><p>数据压缩，其实我们可以把它理解为降维，这是一个狭义与广义的定义，我们首先来理解数据压缩的原理，比如我们有三个特征变量，现在我们希望仅用两个特征变量来反应数据特征。当然这是个非常简单的例子，在实际问题中，例如计算机视觉中，我们通常有上万个特征向量，我们也要有用PCA或白化等其他方法，对数据进行降维处理。而这就是PCA其中一个非常重要的作用。</p><p><img src="/../image/ml61.jpg" alt=""></p><h3 id="主成分维数设定-Number-of-principal-components"><a href="#主成分维数设定-Number-of-principal-components" class="headerlink" title="主成分维数设定(Number of principal components)"></a>主成分维数设定(Number of principal components)</h3><p>在我们的实际任务中，当我们需要对模型中的数据进行降维操作时，我们都要进行从$n$维到$k$维的转换，如何选取k维这个超参数，就是我们下面需要讨论的问题。事实上，我这里只写出如何实现选取k维数的方法，在这里我就不介绍内在原理了，如果感兴趣的可以自行去查阅相关资料。</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Sigma = (<span class="number">1</span>/m) * X' * X;</span><br><span class="line">[U, S, V] = svd(Sigma);</span><br><span class="line">Ureduce = U(:,<span class="number">1</span>:k);</span><br><span class="line">z = Ureduce' * x;</span><br></pre></td></tr></table></figure><p>核心的matlab代码仅有四行，其中</p><script type="math/tex; mode=display">Sigma = \frac{1}{m}\Sigma_{i=1}^{m}(x^{(i)})(x^{(i)})^T\\What\; we\; need \; to \; check\; : \frac{\Sigma_{i=1}^kS_{ii}}{\Sigma_{i=1}^mS_{ii}}\geq 0.99</script><p>这样我们通过选取k值去满足我们所需要的方程即可。当然降维的方法还有很多种，大家可以自行查阅。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;strong&gt;主成分分析(Principal Component Analysis)&lt;/strong&gt;的主要目的是希望用较少的变量去解释原来资料中的大部分变异，选出比原始特征值个数少的变量，构建能解释最终输出的新变量，即为主成分，简单而言，如果我们有题目给出了十几个变量制约的数学模型，我们便可通过PCA将其变化成为4个、5个变量制约的数学模型，这就是所谓的&lt;strong&gt;降维模型(Dimensionality Reduction Model)&lt;/strong&gt;。&lt;/p&gt;
    
    </summary>
    
    
      <category term="数学建模" scheme="http://yoursite.com/categories/%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1/"/>
    
      <category term="模型篇" scheme="http://yoursite.com/categories/%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1/%E6%A8%A1%E5%9E%8B%E7%AF%87/"/>
    
    
      <category term="PCA" scheme="http://yoursite.com/tags/PCA/"/>
    
  </entry>
  
  <entry>
    <title>【吴恩达笔记】PCA降维</title>
    <link href="http://yoursite.com/2020/07/10/%E3%80%90%E5%90%B4%E6%81%A9%E8%BE%BE%E7%AC%94%E8%AE%B0%E3%80%91PCA%E9%99%8D%E7%BB%B4/"/>
    <id>http://yoursite.com/2020/07/10/%E3%80%90%E5%90%B4%E6%81%A9%E8%BE%BE%E7%AC%94%E8%AE%B0%E3%80%91PCA%E9%99%8D%E7%BB%B4/</id>
    <published>2020-07-10T15:09:05.000Z</published>
    <updated>2020-08-27T14:26:57.417Z</updated>
    
    <content type="html"><![CDATA[<p><strong>主成分分析(Principal Component Analysis)</strong>的主要目的是希望用较少的变量去解释原来资料中的大部分变异，选出比原始特征值个数少的变量，构建能解释最终输出的新变量，即为主成分，简单而言，如果我们有题目给出了十几个变量制约的数学模型，我们便可通过PCA将其变化成为4个、5个变量制约的数学模型，这就是所谓的<strong>降维模型(Dimensionality Reduction Model)</strong>。</p><a id="more"></a><h3 id="数据压缩-Data-Compression"><a href="#数据压缩-Data-Compression" class="headerlink" title="数据压缩(Data Compression)"></a>数据压缩(Data Compression)</h3><p>数据压缩，其实我们可以把它理解为降维，这是一个狭义与广义的定义，我们首先来理解数据压缩的原理，比如我们有三个特征变量，现在我们希望仅用两个特征变量来反应数据特征。当然这是个非常简单的例子，在实际问题中，例如计算机视觉中，我们通常有上万个特征向量，我们也要有用PCA或白化等其他方法，对数据进行降维处理。而这就是PCA其中一个非常重要的作用。</p><p><img src="/../image/ml61.jpg" alt=""></p><h3 id="主成分维数设定-Number-of-principal-components"><a href="#主成分维数设定-Number-of-principal-components" class="headerlink" title="主成分维数设定(Number of principal components)"></a>主成分维数设定(Number of principal components)</h3><p>在我们的实际任务中，当我们需要对模型中的数据进行降维操作时，我们都要进行从$n$维到$k$维的转换，如何选取k维这个超参数，就是我们下面需要讨论的问题。事实上，我这里只写出如何实现选取k维数的方法，在这里我就不介绍内在原理了，如果感兴趣的可以自行去查阅相关资料。</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Sigma = (<span class="number">1</span>/m) * X' * X;</span><br><span class="line">[U, S, V] = svd(Sigma);</span><br><span class="line">Ureduce = U(:,<span class="number">1</span>:k);</span><br><span class="line">z = Ureduce' * x;</span><br></pre></td></tr></table></figure><p>核心的matlab代码仅有四行，其中</p><script type="math/tex; mode=display">Sigma = \frac{1}{m}\Sigma_{i=1}^{m}(x^{(i)})(x^{(i)})^T\\What\; we\; need \; to \; check\; : \frac{\Sigma_{i=1}^kS_{ii}}{\Sigma_{i=1}^mS_{ii}}\geq 0.99</script><p>这样我们通过选取k值去满足我们所需要的方程即可。当然降维的方法还有很多种，大家可以自行查阅。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;strong&gt;主成分分析(Principal Component Analysis)&lt;/strong&gt;的主要目的是希望用较少的变量去解释原来资料中的大部分变异，选出比原始特征值个数少的变量，构建能解释最终输出的新变量，即为主成分，简单而言，如果我们有题目给出了十几个变量制约的数学模型，我们便可通过PCA将其变化成为4个、5个变量制约的数学模型，这就是所谓的&lt;strong&gt;降维模型(Dimensionality Reduction Model)&lt;/strong&gt;。&lt;/p&gt;
    
    </summary>
    
    
      <category term="机器学习" scheme="http://yoursite.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="吴恩达课程笔记" scheme="http://yoursite.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%90%B4%E6%81%A9%E8%BE%BE%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="PCA" scheme="http://yoursite.com/tags/PCA/"/>
    
  </entry>
  
  <entry>
    <title>【聚类算法】K-means无监督学习</title>
    <link href="http://yoursite.com/2020/07/06/%E3%80%90%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95%E3%80%91K-means%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/"/>
    <id>http://yoursite.com/2020/07/06/%E3%80%90%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95%E3%80%91K-means%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/</id>
    <published>2020-07-05T19:48:34.000Z</published>
    <updated>2020-07-10T07:12:55.123Z</updated>
    
    <content type="html"><![CDATA[<p>之前我们讨论过关于线性回归、Logistic回归与SVM等模型与算法，然而之前讨论的事物在机器学习中，我们都统称为监督学习。在这之后，我将花两篇博客的内容来介绍一些无监督学习的算法，机器学习算法广义而言分为两类：监督学习与无监督学习，其判断标准其实就是我们所拥有的样本是否含有标签信息。当然，现在的学者们都专注在弱监督学习领域，一个更适用于工业的学习方法。下面我将会介绍无监督学习即不含标签的样本，并对其进行分类，我们称为<strong>聚类</strong>。</p><a id="more"></a><h3 id="聚类问题-Clustering"><a href="#聚类问题-Clustering" class="headerlink" title="聚类问题(Clustering)"></a>聚类问题(Clustering)</h3><p>我们经常在数学建模竞赛中，会遇到不少类似这样的问题，比如拍照定价给城市分类(参考国赛2017B)，球员之间联系的紧密性研究(参考今年2020美赛D题)等等，这些就是非常明显的聚类问题，我们再举几个平时生活的例子，比如市场消费调研，社交网络分析，衣服尺码分布等等，这些问题所给出的样本，不像之前监督学习问题中的垃圾邮件的判别或房价预测等问题，他们并没有带标签，而我们把这样没有带标签的样本进行算法学习，由参数体现出的分类情况成为<strong>聚类</strong>，也就是<strong>Clustering</strong>。</p><h3 id="K-means聚类算法"><a href="#K-means聚类算法" class="headerlink" title="K-means聚类算法"></a>K-means聚类算法</h3><p>这里我们介绍一种典型的聚类算法，就是所谓的<strong>K-means聚类算法</strong>，下面我给出这个算法流程，首先我们给出无标签的绿色样本，我们要求把样本分为两个聚类：</p><p><img src="/../image/ml51.jpg" alt=""></p><p><img src="/../image/ml52.jpg" alt=""></p><p>我们先随机生成两个<strong>聚类中心(cluster centroids)</strong>，然后将离它近的点标注成和它一样的颜色，根据红色/蓝色所有点再取它们的均值位置作为新的聚类中心，如此反复，直到收敛到最优解停止。</p><p>这个算法其实原理就我所说的那样，非常简单。下面是整个一般性算法的流程，也就是分成k类的情况下：</p><script type="math/tex; mode=display">\begin{align}Randomly&\ initialize\ K\ cluster\ centroids\ \mu_1,\mu_2,...,\mu_K\in \mathbb{R}^n\\for\ iter&=1\ to \ 100\\for&\ i=1\ to\ m\\c&^{(i)}:=index\ (from\ 1\ to\ K)\ of\ cluster\ centroid\ closest\ to\ x^{(1)}\\for&\ k=1\ to\ K\\\mu&_k:=average\ (mean)\ of\ points\ assigned\ to\ cluster\ k\\\end{align}</script><p>这里我们举的例子是迭代100次，其实K-means算法中主要就是迭代的思想，至于具体迭代到什么时候截止，这个问题我之后会说明清楚。</p><h3 id="优化目标-Optimization-Objective"><a href="#优化目标-Optimization-Objective" class="headerlink" title="优化目标(Optimization Objective)"></a>优化目标(Optimization Objective)</h3><p>在决定优化目标之前，我们先确定几个变量的名称：</p><ul><li>$c^{(i)}$=index of cluster (1,2,…,K) to which example $x^{(i)}$ is currently assigned</li><li>$\mu_k$=cluster centroid k ($\mu_k\in \mathbb{R}^n$)</li><li>$\mu_{c^{(i)}}$=cluster centroid of cluster to which example $x^{(i)}$ has been assigned</li></ul><p>我来简单解释下几个变量的含义，对于K-means聚类算法，最重要的是两个过程：</p><ul><li>S1：初始化K个聚类中心$\mu_k$</li><li>S2：计算与每个点即$x^{(i)}$距离最近的聚类中心，将每个点所属的聚类中心编号标记为$c^{(i)}$，这样每个点的聚类中心的位置就是$\mu_{c^{(i)}}$了。</li><li>S3：计算从属于同一个聚类中心$c^{(i)}$的均值位置，并将它作为新的聚类中心位置，即$\mu_{c^{(i)}}$。</li><li>S4：重复步骤S2和S3，进行迭代，收敛至最优解。</li></ul><p>这样我们便可以很轻易地写出我们的代价函数，而我们的优化目标则是最小化代价函数：</p><script type="math/tex; mode=display">min\ J(c^{(1)},...,c^{(m)},\mu_1,...,\mu_K)=\frac{1}{m}\sum^{m}_{i=1}\|x^{(i)}-\mu_{c^{(i)}}\|^2</script><p>代价函数表示的就是每个点距离聚类中心距离的平方和的均值。</p><h3 id="随机初始化-Random-Initialization"><a href="#随机初始化-Random-Initialization" class="headerlink" title="随机初始化(Random Initialization)"></a>随机初始化(Random Initialization)</h3><h4 id="如何随机选择初始点？"><a href="#如何随机选择初始点？" class="headerlink" title="如何随机选择初始点？"></a>如何随机选择初始点？</h4><p>在K-means算法中，我们还有一个悬而未决的问题，到现在也没有说明。那就是如何初始化K个聚类中心，实际上我能给出最好的答案就是，按照样本来选择，随机选择K个样本作为初始化的点，但是这样确实也会出现一些问题：</p><p><img src="/../image/ml53.jpg" alt=""></p><p>如上图所示，假设我们的K=2，那我们随机选取两个样本作为初始化的起点，我们可以看到上述两种情况，第二种随机的选择很明显效果很糟糕，甚至有可能因此得到不是我们所期望的聚类。</p><p>很遗憾，对于这种问题，我唯一的解决办法就是尝试多次初始化，并分别迭代到最优再进行比较，由于本人太菜，除此之外我可能不能分享更好理解的办法了。</p><h4 id="如何选择聚类的数量K？"><a href="#如何选择聚类的数量K？" class="headerlink" title="如何选择聚类的数量K？"></a>如何选择聚类的数量K？</h4><p>在聚类问题中，大部分情况我们都是能知道我们需要分成几类，或者说我们希望将整体样本分为几类的，这时候可以根据实际要求选择K，比如为不同的受众定制衣服，假设我们就三个尺码：S，M，L。那么很容易，我们得到我们希望的K是3，进行计算即可。</p><p>在很少的情况下，我们需要手动选择一个最优的聚类种数，这是个非常复杂的问题，很遗憾地说，到目前为止都没有什么好办法，我这里只介绍一种方法：<strong>Elbow method</strong></p><p><img src="/../image/ml54.jpg" alt=""></p><p>我们分别试验不同的K，并画出最小代价函数的折线图，如果是左边图的情况下，那么恭喜你们，随着收敛的渐渐平缓，毫无疑问K=3将会是聚类种数的最好选择。但是，往往我们的实际问题中，我们遇到的折线图都是右边这样的情况，其实你通过图像很难得出K的最优解，因为曲线一直是平缓下降的。这个时候，还是多问问自己，关于此题聚类算法应用的目的，从而自己规定聚类的数量吧。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;之前我们讨论过关于线性回归、Logistic回归与SVM等模型与算法，然而之前讨论的事物在机器学习中，我们都统称为监督学习。在这之后，我将花两篇博客的内容来介绍一些无监督学习的算法，机器学习算法广义而言分为两类：监督学习与无监督学习，其判断标准其实就是我们所拥有的样本是否含有标签信息。当然，现在的学者们都专注在弱监督学习领域，一个更适用于工业的学习方法。下面我将会介绍无监督学习即不含标签的样本，并对其进行分类，我们称为&lt;strong&gt;聚类&lt;/strong&gt;。&lt;/p&gt;
    
    </summary>
    
    
      <category term="数学建模" scheme="http://yoursite.com/categories/%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1/"/>
    
      <category term="算法篇" scheme="http://yoursite.com/categories/%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1/%E7%AE%97%E6%B3%95%E7%AF%87/"/>
    
    
      <category term="聚类" scheme="http://yoursite.com/tags/%E8%81%9A%E7%B1%BB/"/>
    
  </entry>
  
  <entry>
    <title>【吴恩达笔记】无监督学习K-means聚类算法</title>
    <link href="http://yoursite.com/2020/07/06/%E3%80%90%E5%90%B4%E6%81%A9%E8%BE%BE%E7%AC%94%E8%AE%B0%E3%80%91%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0K-means%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95/"/>
    <id>http://yoursite.com/2020/07/06/%E3%80%90%E5%90%B4%E6%81%A9%E8%BE%BE%E7%AC%94%E8%AE%B0%E3%80%91%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0K-means%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95/</id>
    <published>2020-07-05T19:48:02.000Z</published>
    <updated>2020-07-10T07:13:05.260Z</updated>
    
    <content type="html"><![CDATA[<p>之前我们讨论过关于线性回归、Logistic回归与SVM等模型与算法，然而之前讨论的事物在机器学习中，我们都统称为监督学习。在这之后，我将花两篇博客的内容来介绍一些无监督学习的算法，机器学习算法广义而言分为两类：监督学习与无监督学习，其判断标准其实就是我们所拥有的样本是否含有标签信息。当然，现在的学者们都专注在弱监督学习领域，一个更适用于工业的学习方法。下面我将会介绍无监督学习即不含标签的样本，并对其进行分类，我们称为<strong>聚类</strong>。</p><a id="more"></a><h3 id="聚类问题-Clustering"><a href="#聚类问题-Clustering" class="headerlink" title="聚类问题(Clustering)"></a>聚类问题(Clustering)</h3><p>我们经常在数学建模竞赛中，会遇到不少类似这样的问题，比如拍照定价给城市分类(参考国赛2017B)，球员之间联系的紧密性研究(参考今年2020美赛D题)等等，这些就是非常明显的聚类问题，我们再举几个平时生活的例子，比如市场消费调研，社交网络分析，衣服尺码分布等等，这些问题所给出的样本，不像之前监督学习问题中的垃圾邮件的判别或房价预测等问题，他们并没有带标签，而我们把这样没有带标签的样本进行算法学习，由参数体现出的分类情况成为<strong>聚类</strong>，也就是<strong>Clustering</strong>。</p><h3 id="K-means聚类算法"><a href="#K-means聚类算法" class="headerlink" title="K-means聚类算法"></a>K-means聚类算法</h3><p>这里我们介绍一种典型的聚类算法，就是所谓的<strong>K-means聚类算法</strong>，下面我给出这个算法流程，首先我们给出无标签的绿色样本，我们要求把样本分为两个聚类：</p><p><img src="/../image/ml51.jpg" alt=""></p><p><img src="/../image/ml52.jpg" alt=""></p><p>我们先随机生成两个<strong>聚类中心(cluster centroids)</strong>，然后将离它近的点标注成和它一样的颜色，根据红色/蓝色所有点再取它们的均值位置作为新的聚类中心，如此反复，直到收敛到最优解停止。</p><p>这个算法其实原理就我所说的那样，非常简单。下面是整个一般性算法的流程，也就是分成k类的情况下：</p><script type="math/tex; mode=display">\begin{align}Randomly&\ initialize\ K\ cluster\ centroids\ \mu_1,\mu_2,...,\mu_K\in \mathbb{R}^n\\for\ iter&=1\ to \ 100\\for&\ i=1\ to\ m\\c&^{(i)}:=index\ (from\ 1\ to\ K)\ of\ cluster\ centroid\ closest\ to\ x^{(1)}\\for&\ k=1\ to\ K\\\mu&_k:=average\ (mean)\ of\ points\ assigned\ to\ cluster\ k\\\end{align}</script><p>这里我们举的例子是迭代100次，其实K-means算法中主要就是迭代的思想，至于具体迭代到什么时候截止，这个问题我之后会说明清楚。</p><h3 id="优化目标-Optimization-Objective"><a href="#优化目标-Optimization-Objective" class="headerlink" title="优化目标(Optimization Objective)"></a>优化目标(Optimization Objective)</h3><p>在决定优化目标之前，我们先确定几个变量的名称：</p><ul><li>$c^{(i)}$=index of cluster (1,2,…,K) to which example $x^{(i)}$ is currently assigned</li><li>$\mu_k$=cluster centroid k ($\mu_k\in \mathbb{R}^n$)</li><li>$\mu_{c^{(i)}}$=cluster centroid of cluster to which example $x^{(i)}$ has been assigned</li></ul><p>我来简单解释下几个变量的含义，对于K-means聚类算法，最重要的是两个过程：</p><ul><li>S1：初始化K个聚类中心$\mu_k$</li><li>S2：计算与每个点即$x^{(i)}$距离最近的聚类中心，将每个点所属的聚类中心编号标记为$c^{(i)}$，这样每个点的聚类中心的位置就是$\mu_{c^{(i)}}$了。</li><li>S3：计算从属于同一个聚类中心$c^{(i)}$的均值位置，并将它作为新的聚类中心位置，即$\mu_{c^{(i)}}$。</li><li>S4：重复步骤S2和S3，进行迭代，收敛至最优解。</li></ul><p>这样我们便可以很轻易地写出我们的代价函数，而我们的优化目标则是最小化代价函数：</p><script type="math/tex; mode=display">min\ J(c^{(1)},...,c^{(m)},\mu_1,...,\mu_K)=\frac{1}{m}\sum^{m}_{i=1}\|x^{(i)}-\mu_{c^{(i)}}\|^2</script><p>代价函数表示的就是每个点距离聚类中心距离的平方和的均值。</p><h3 id="随机初始化-Random-Initialization"><a href="#随机初始化-Random-Initialization" class="headerlink" title="随机初始化(Random Initialization)"></a>随机初始化(Random Initialization)</h3><h4 id="如何随机选择初始点？"><a href="#如何随机选择初始点？" class="headerlink" title="如何随机选择初始点？"></a>如何随机选择初始点？</h4><p>在K-means算法中，我们还有一个悬而未决的问题，到现在也没有说明。那就是如何初始化K个聚类中心，实际上我能给出最好的答案就是，按照样本来选择，随机选择K个样本作为初始化的点，但是这样确实也会出现一些问题：</p><p><img src="/../image/ml53.jpg" alt=""></p><p>如上图所示，假设我们的K=2，那我们随机选取两个样本作为初始化的起点，我们可以看到上述两种情况，第二种随机的选择很明显效果很糟糕，甚至有可能因此得到不是我们所期望的聚类。</p><p>很遗憾，对于这种问题，我唯一的解决办法就是尝试多次初始化，并分别迭代到最优再进行比较，由于本人太菜，除此之外我可能不能分享更好理解的办法了。</p><h4 id="如何选择聚类的数量K？"><a href="#如何选择聚类的数量K？" class="headerlink" title="如何选择聚类的数量K？"></a>如何选择聚类的数量K？</h4><p>在聚类问题中，大部分情况我们都是能知道我们需要分成几类，或者说我们希望将整体样本分为几类的，这时候可以根据实际要求选择K，比如为不同的受众定制衣服，假设我们就三个尺码：S，M，L。那么很容易，我们得到我们希望的K是3，进行计算即可。</p><p>在很少的情况下，我们需要手动选择一个最优的聚类种数，这是个非常复杂的问题，很遗憾地说，到目前为止都没有什么好办法，我这里只介绍一种方法：<strong>Elbow method</strong></p><p><img src="/../image/ml54.jpg" alt=""></p><p>我们分别试验不同的K，并画出最小代价函数的折线图，如果是左边图的情况下，那么恭喜你们，随着收敛的渐渐平缓，毫无疑问K=3将会是聚类种数的最好选择。但是，往往我们的实际问题中，我们遇到的折线图都是右边这样的情况，其实你通过图像很难得出K的最优解，因为曲线一直是平缓下降的。这个时候，还是多问问自己，关于此题聚类算法应用的目的，从而自己规定聚类的数量吧。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;之前我们讨论过关于线性回归、Logistic回归与SVM等模型与算法，然而之前讨论的事物在机器学习中，我们都统称为监督学习。在这之后，我将花两篇博客的内容来介绍一些无监督学习的算法，机器学习算法广义而言分为两类：监督学习与无监督学习，其判断标准其实就是我们所拥有的样本是否含有标签信息。当然，现在的学者们都专注在弱监督学习领域，一个更适用于工业的学习方法。下面我将会介绍无监督学习即不含标签的样本，并对其进行分类，我们称为&lt;strong&gt;聚类&lt;/strong&gt;。&lt;/p&gt;
    
    </summary>
    
    
      <category term="机器学习" scheme="http://yoursite.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="吴恩达课程笔记" scheme="http://yoursite.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%90%B4%E6%81%A9%E8%BE%BE%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="Kmeans" scheme="http://yoursite.com/tags/Kmeans/"/>
    
  </entry>
  
  <entry>
    <title>【吴恩达笔记】支持向量机SVM</title>
    <link href="http://yoursite.com/2020/07/04/%E3%80%90%E5%90%B4%E6%81%A9%E8%BE%BE%E7%AC%94%E8%AE%B0%E3%80%91%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BASVM/"/>
    <id>http://yoursite.com/2020/07/04/%E3%80%90%E5%90%B4%E6%81%A9%E8%BE%BE%E7%AC%94%E8%AE%B0%E3%80%91%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BASVM/</id>
    <published>2020-07-04T11:01:10.000Z</published>
    <updated>2020-07-04T05:18:11.567Z</updated>
    
    <content type="html"><![CDATA[<p><strong>Support Vector Machines(简称SVM)支持向量机</strong>是机器学习中非常重要的一种算法，一般用于分类与判别，你可以能还会见到<strong>Support Vector Classification(简称SVC)、Support Vector Regression(简称SVR)</strong>，分别用于分类与回归，别担心他们的内理是一模一样的，只是功能不同而进行了划分罢了。</p><a id="more"></a><h3 id="优化目标-Optimization-Objective"><a href="#优化目标-Optimization-Objective" class="headerlink" title="优化目标(Optimization Objective)"></a>优化目标(Optimization Objective)</h3><p>我们先从Logistic回归说起，我们知道在Logistic回归中，Sigmoid函数的作用$z=\theta^Tx$，如果我们需要让$y=1$，那我们就想要$h(x)\approx1$，即$z\gg0$，反之则是，$z\ll0$。下面我们为远大于和远小于划定一定的界限，首先我们还是以代价函数的例子来说明，我们之前定义了：</p><script type="math/tex; mode=display">Cost(h(x),y)=-ylog\frac{1}{1+e^{-\theta^Tx}}-(1-y)log\left(1-\frac{1}{1+e^{-\theta^Tx}}\right)</script><p>我们分别画出当$y=0,1$时的函数图像：</p><p><img src="/../image/ml41.jpg" alt=""></p><p>我们可以很明显地看出当$y=1,z&gt;1$时，代价z就差不多变成0了，反之则是$z&lt;-1$。这里注意一下，关于1和-1，基本是我们约定俗成的，请大家不用过分在意。于是我们得到了新的代价，在机器学习，我们把它成为支持向量：</p><script type="math/tex; mode=display">\begin{align}cost_1(z)&=0 \text{ if } z>1\\cost_0(z)&=0 \text{ if } z<-1\end{align}</script><p>下面我们重写SVM的整体代价函数，我们加入了正则项，并与logistic作对比：</p><script type="math/tex; mode=display">\begin{align}Logistic: J(\theta)&=min\frac{1}{m}[\sum_{i=1}^my^{(i)}\left(-logh(x^{(i)})\right)+(1-y^{(i)})\left(-log(1-h(x^{(i)}))\right)]+\frac{\lambda}{2m}\sum_{j=1}^n\theta_j^2\\SVM: J(\theta)&=minC\sum_{i=1}^m[y^{(i)}cost_1(\theta^Tx^{(i)})+(1-y^{(i)})cost_0(\theta^Tx^{(i)})]+\frac{1}{2}\sum_{i=1}^n\theta_j^2\end{align}</script><p>我们可以看出SVM中有一个常数C，没有关系，你可以把他当做和正则化参数一样的东西，用于调整权重的比例，防止过拟合的问题。这就是SVM的优化目标，即代价函数。</p><h3 id="大间隔学习-Large-Margin-Learning"><a href="#大间隔学习-Large-Margin-Learning" class="headerlink" title="大间隔学习(Large Margin Learning)"></a>大间隔学习(Large Margin Learning)</h3><p>支持向量机还有一个名称，就是大间隔学习，下面我会用可视化的方式来告诉你为何它是大间隔学习，以及为何它的效果要优于我们的Logistic回归。假设我们有一个二分类的样本，如下图所示：</p><p><img src="/../image/ml42.jpg" alt=""></p><p>在这里分类问题中，L1和L2是我们Logsitic回归可能得到的决策界限，可以看出的是，虽然这两条直线，确实分开了两个样本，但是分类效果并不太好。而支持向量机划分的决策界限，则是S1，其中S2和S3为初始划定界限，最终选择S1作为决策界限，而S1与S2、S3的距离被称为Margin。这就是我们称SVM为大间隔学习的原因，其中关于SVM为何能做到这样的原因，就牵扯到了其背后的数学原理，在这里不做展开，比较复杂，建议基础扎实后看西瓜书或<a href="http://blog.pluskid.org/" target="_blank" rel="noopener">我老板朋友Free Mind的博客</a>。ps：之前听说有位学长面试时手推SVM，被lamda录取了。</p><h3 id="核函数-Kernel"><a href="#核函数-Kernel" class="headerlink" title="核函数(Kernel)"></a>核函数(Kernel)</h3><p>其实核函数核方法这些东西在所有的模型算法中都能应用到，但是其在SVM中的效果明显，所以核函数常常后来和SVM一起出现。我们在解决非线性问题的时候，常常会为假设函数的选择而困扰，选择单变量一次项$x_1$，还是单变量高次项$x_1^n$，还是选择多变量的积$x_1x_2x_3$，这常常会给我们的分类问题的解决造成障碍，于是我们可以得到一个较为统一的式子：</p><script type="math/tex; mode=display">h_{\theta}(x)=\theta_0+\theta_1f_1+\theta_2f_2+\theta_3f_3+...</script><p>下面我们就来谈谈如何选择这项通用式子中的$f_1,f_2,f_3$。对于给定的特征向量x，我们定义三个坐标点$l^{(1)},l^{(2)},l^{(3)}$。我们以此来决定通向式中的三个权重：</p><script type="math/tex; mode=display">\begin{align}f_1=similarity(x,l^{(1)})=exp(-\frac{\left\|x-l^{(1)}\right\|^2}{2\sigma^2})\\f_2=similarity(x,l^{(2)})=exp(-\frac{\left\|x-l^{(2)}\right\|^2}{2\sigma^2})\\f_3=similarity(x,l^{(3)})=exp(-\frac{\left\|x-l^{(3)}\right\|^2}{2\sigma^2})\end{align}</script><p>其中similarity函数就是我们所经常使用<strong>高斯核函数(Gaussion Kernels)</strong>，如果特征值离我们的定义坐标点越近，则$f\approx1$，反之则是$f\approx0 $。</p><p>简单说说，我们如何选择坐标点$l^{(1)},l^{(2)},l^{(3)},…$，我通常的选择方法笔记比较简单(当然还有很多复杂的选择方法)，比如我们有m个特征向量样本即$x^{(1)},x^{(2)},…,x^{(m)}$。</p><p>那我们便选择m个坐标点，$l^{(1)}=x^{(1)},l^{(2)}=x^{(2)},…,l^{(m)}=x^{(m)}$。一般而言，我会这么选择。然而核函数还有很多种，我这里列举一些：</p><ul><li>String kernel</li><li>chi-square kernel</li><li>histogram intersection kernel</li></ul><p>不过最常用且较为容易的还是高斯核函数。</p><h3 id="与Logistic如何选择"><a href="#与Logistic如何选择" class="headerlink" title="与Logistic如何选择"></a>与Logistic如何选择</h3><p>我们假设$n=number\text{ }of\text{ }features(x\in\mathbb{R}^{n+1}),m=number\;of\;trainingg\;examples$。</p><ul><li>如果n相对于m来说非常大：我们选用Logistic回归，或者不用核函数的SVM(不用核函数就相当于线性核函数Linear Kernel)。</li><li>如果n比较小，m中等：我们选用高斯核函数的SVM。</li><li>如果n小，m大：那我们需要增加特征向量的种类，然后同理第一种情况</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;strong&gt;Support Vector Machines(简称SVM)支持向量机&lt;/strong&gt;是机器学习中非常重要的一种算法，一般用于分类与判别，你可以能还会见到&lt;strong&gt;Support Vector Classification(简称SVC)、Support Vector Regression(简称SVR)&lt;/strong&gt;，分别用于分类与回归，别担心他们的内理是一模一样的，只是功能不同而进行了划分罢了。&lt;/p&gt;
    
    </summary>
    
    
      <category term="机器学习" scheme="http://yoursite.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="吴恩达课程笔记" scheme="http://yoursite.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%90%B4%E6%81%A9%E8%BE%BE%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="SVM" scheme="http://yoursite.com/tags/SVM/"/>
    
  </entry>
  
  <entry>
    <title>【分类与判别算法】支持向量机SVM</title>
    <link href="http://yoursite.com/2020/07/04/%E3%80%90%E5%88%86%E7%B1%BB%E4%B8%8E%E5%88%A4%E5%88%AB%E7%AE%97%E6%B3%95%E3%80%91%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BASVM/"/>
    <id>http://yoursite.com/2020/07/04/%E3%80%90%E5%88%86%E7%B1%BB%E4%B8%8E%E5%88%A4%E5%88%AB%E7%AE%97%E6%B3%95%E3%80%91%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BASVM/</id>
    <published>2020-07-04T11:00:36.000Z</published>
    <updated>2020-07-04T05:18:51.239Z</updated>
    
    <content type="html"><![CDATA[<p>终于讲到了算法的内容了，<strong>Support Vector Machines(简称SVM)支持向量机</strong>是机器学习与数学建模中非常重要的一种算法，一般用于分类与判别，你可以能还会见到<strong>Support Vector Classification(简称SVC)、Support Vector Regression(简称SVR)</strong>，分别用于分类与回归，别担心他们的内理是一模一样的，只是功能不同而进行了划分罢了。</p><a id="more"></a><h3 id="优化目标-Optimization-Objective"><a href="#优化目标-Optimization-Objective" class="headerlink" title="优化目标(Optimization Objective)"></a>优化目标(Optimization Objective)</h3><p>我们先从Logistic回归说起，我们知道在Logistic回归中，Sigmoid函数的作用$z=\theta^Tx$，如果我们需要让$y=1$，那我们就想要$h(x)\approx1$，即$z\gg0$，反之则是，$z\ll0$。下面我们为远大于和远小于划定一定的界限，首先我们还是以代价函数的例子来说明，我们之前定义了：</p><script type="math/tex; mode=display">Cost(h(x),y)=-ylog\frac{1}{1+e^{-\theta^Tx}}-(1-y)log\left(1-\frac{1}{1+e^{-\theta^Tx}}\right)</script><p>我们分别画出当$y=0,1$时的函数图像：</p><p><img src="/../image/ml41.jpg" alt=""></p><p>我们可以很明显地看出当$y=1,z&gt;1$时，代价z就差不多变成0了，反之则是$z&lt;-1$。这里注意一下，关于1和-1，基本是我们约定俗成的，请大家不用过分在意。于是我们得到了新的代价，在机器学习，我们把它成为支持向量：</p><script type="math/tex; mode=display">\begin{align}cost_1(z)&=0 \text{ if } z>1\\cost_0(z)&=0 \text{ if } z<-1\end{align}</script><p>下面我们重写SVM的整体代价函数，我们加入了正则项，并与logistic作对比：</p><script type="math/tex; mode=display">\begin{align}Logistic: J(\theta)&=min\frac{1}{m}[\sum_{i=1}^my^{(i)}\left(-logh(x^{(i)})\right)+(1-y^{(i)})\left(-log(1-h(x^{(i)}))\right)]+\frac{\lambda}{2m}\sum_{j=1}^n\theta_j^2\\SVM: J(\theta)&=minC\sum_{i=1}^m[y^{(i)}cost_1(\theta^Tx^{(i)})+(1-y^{(i)})cost_0(\theta^Tx^{(i)})]+\frac{1}{2}\sum_{i=1}^n\theta_j^2\end{align}</script><p>我们可以看出SVM中有一个常数C，没有关系，你可以把他当做和正则化参数一样的东西，用于调整权重的比例，防止过拟合的问题。这就是SVM的优化目标，即代价函数。</p><h3 id="大间隔学习-Large-Margin-Learning"><a href="#大间隔学习-Large-Margin-Learning" class="headerlink" title="大间隔学习(Large Margin Learning)"></a>大间隔学习(Large Margin Learning)</h3><p>支持向量机还有一个名称，就是大间隔学习，下面我会用可视化的方式来告诉你为何它是大间隔学习，以及为何它的效果要优于我们的Logistic回归。假设我们有一个二分类的样本，如下图所示：</p><p><img src="/../image/ml42.jpg" alt=""></p><p>在这里分类问题中，L1和L2是我们Logsitic回归可能得到的决策界限，可以看出的是，虽然这两条直线，确实分开了两个样本，但是分类效果并不太好。而支持向量机划分的决策界限，则是S1，其中S2和S3为初始划定界限，最终选择S1作为决策界限，而S1与S2、S3的距离被称为Margin。这就是我们称SVM为大间隔学习的原因，其中关于SVM为何能做到这样的原因，就牵扯到了其背后的数学原理，在这里不做展开，比较复杂，建议基础扎实后看西瓜书或<a href="http://blog.pluskid.org/" target="_blank" rel="noopener">我老板朋友Free Mind的博客</a>。ps：之前听说有位学长面试时手推SVM，被lamda录取了。</p><h3 id="核函数-Kernel"><a href="#核函数-Kernel" class="headerlink" title="核函数(Kernel)"></a>核函数(Kernel)</h3><p>其实核函数核方法这些东西在所有的模型算法中都能应用到，但是其在SVM中的效果明显，所以核函数常常后来和SVM一起出现。我们在解决非线性问题的时候，常常会为假设函数的选择而困扰，选择单变量一次项$x_1$，还是单变量高次项$x_1^n$，还是选择多变量的积$x_1x_2x_3$，这常常会给我们的分类问题的解决造成障碍，于是我们可以得到一个较为统一的式子：</p><script type="math/tex; mode=display">h_{\theta}(x)=\theta_0+\theta_1f_1+\theta_2f_2+\theta_3f_3+...</script><p>下面我们就来谈谈如何选择这项通用式子中的$f_1,f_2,f_3$。对于给定的特征向量x，我们定义三个坐标点$l^{(1)},l^{(2)},l^{(3)}$。我们以此来决定通向式中的三个权重：</p><script type="math/tex; mode=display">\begin{align}f_1=similarity(x,l^{(1)})=exp(-\frac{\left\|x-l^{(1)}\right\|^2}{2\sigma^2})\\f_2=similarity(x,l^{(2)})=exp(-\frac{\left\|x-l^{(2)}\right\|^2}{2\sigma^2})\\f_3=similarity(x,l^{(3)})=exp(-\frac{\left\|x-l^{(3)}\right\|^2}{2\sigma^2})\end{align}</script><p>其中similarity函数就是我们所经常使用<strong>高斯核函数(Gaussion Kernels)</strong>，如果特征值离我们的定义坐标点越近，则$f\approx1$，反之则是$f\approx0 $。</p><p>简单说说，我们如何选择坐标点$l^{(1)},l^{(2)},l^{(3)},…$，我通常的选择方法笔记比较简单(当然还有很多复杂的选择方法)，比如我们有m个特征向量样本即$x^{(1)},x^{(2)},…,x^{(m)}$。</p><p>那我们便选择m个坐标点，$l^{(1)}=x^{(1)},l^{(2)}=x^{(2)},…,l^{(m)}=x^{(m)}$。一般而言，我会这么选择。然而核函数还有很多种，我这里列举一些：</p><ul><li>String kernel</li><li>chi-square kernel</li><li>histogram intersection kernel</li></ul><p>不过最常用且较为容易的还是高斯核函数。</p><h3 id="与Logistic如何选择"><a href="#与Logistic如何选择" class="headerlink" title="与Logistic如何选择"></a>与Logistic如何选择</h3><p>我们假设$n=number\text{ }of\text{ }features(x\in\mathbb{R}^{n+1}),m=number\;of\;trainingg\;examples$。</p><ul><li>如果n相对于m来说非常大：我们选用Logistic回归，或者不用核函数的SVM(不用核函数就相当于线性核函数Linear Kernel)。</li><li>如果n比较小，m中等：我们选用高斯核函数的SVM。</li><li>如果n小，m大：那我们需要增加特征向量的种类，然后同理第一种情况</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;终于讲到了算法的内容了，&lt;strong&gt;Support Vector Machines(简称SVM)支持向量机&lt;/strong&gt;是机器学习与数学建模中非常重要的一种算法，一般用于分类与判别，你可以能还会见到&lt;strong&gt;Support Vector Classification(简称SVC)、Support Vector Regression(简称SVR)&lt;/strong&gt;，分别用于分类与回归，别担心他们的内理是一模一样的，只是功能不同而进行了划分罢了。&lt;/p&gt;
    
    </summary>
    
    
      <category term="数学建模" scheme="http://yoursite.com/categories/%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1/"/>
    
      <category term="算法篇" scheme="http://yoursite.com/categories/%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1/%E7%AE%97%E6%B3%95%E7%AF%87/"/>
    
    
      <category term="SVM" scheme="http://yoursite.com/tags/SVM/"/>
    
  </entry>
  
  <entry>
    <title>【吴恩达笔记】正则化</title>
    <link href="http://yoursite.com/2020/07/03/%E3%80%90%E5%90%B4%E6%81%A9%E8%BE%BE%E7%AC%94%E8%AE%B0%E3%80%91%E6%AD%A3%E5%88%99%E5%8C%96/"/>
    <id>http://yoursite.com/2020/07/03/%E3%80%90%E5%90%B4%E6%81%A9%E8%BE%BE%E7%AC%94%E8%AE%B0%E3%80%91%E6%AD%A3%E5%88%99%E5%8C%96/</id>
    <published>2020-07-03T11:44:01.000Z</published>
    <updated>2020-07-04T05:17:53.202Z</updated>
    
    <content type="html"><![CDATA[<p>关于<strong>Regularization(正则化)</strong>的问题，这实际上在数学模型优化以及机器学习系统设计中，都是特别难处理的问题，所以我这里也只能用我浅显的认知和大家讲述正则化中最基本的知识。</p><a id="more"></a><h3 id="关于拟合：Underfitting-VS-Overfitting"><a href="#关于拟合：Underfitting-VS-Overfitting" class="headerlink" title="关于拟合：Underfitting VS Overfitting"></a>关于拟合：Underfitting VS Overfitting</h3><p><img src="/../image/ml31.jpg" alt=""></p><p>还是之前关于房价的例子，如果我们尝试用不同的函数进行拟合，选用一次函数，我们会发现，我们并没有完成一个比较好的拟合效果，所以我们称这种拟合为<strong>欠拟合(Underfitting)</strong>。而选用四次函数，我们会发现这样的拟合可能会误差很小，即<script type="math/tex">J(\theta)=\frac{1}{2m}\sum\limits_{i=1}^n\left(h_\theta(x)-y^{(i)}\right)^2\approx0</script>，但是很显然这个，函数拟合的并不满足实际情况(实际曲线根本不可能这么陡峭)，也就是说这个拟合的泛化效果不好，这种情况我们称为过拟合。而正则化正是为我们解决过拟合问题的。</p><h3 id="正则化代价函数"><a href="#正则化代价函数" class="headerlink" title="正则化代价函数"></a>正则化代价函数</h3><p>我们考虑一个问题，会出现过拟合现象的原因可能是我们对于参数的权重选用不得当，所以我们得像个办法来进行约束，引入一个新的正则化参数$\lambda$，<strong>regularization parament</strong> 。从而我们可以得到新的代价函数：</p><script type="math/tex; mode=display">J(\theta)=\frac{1}{2m}[\sum_{i=1}^{m}\left(h_\theta(x^{(i)})-y^{(i)}\right)^2+\lambda\sum_{i=1}^n\theta_j^2]</script><p>这样我们通过控制正则化参数的值就能对模型或者系统进行一定程度的优化或者说可视化的控制。</p><p>不管是正则化任何模型，我们控制的都是我们待定的权重，通过这样的方式，我们可以固定函数的类别，得到更合理的模型，在处理非线性的问题中广泛应用。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;关于&lt;strong&gt;Regularization(正则化)&lt;/strong&gt;的问题，这实际上在数学模型优化以及机器学习系统设计中，都是特别难处理的问题，所以我这里也只能用我浅显的认知和大家讲述正则化中最基本的知识。&lt;/p&gt;
    
    </summary>
    
    
      <category term="机器学习" scheme="http://yoursite.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="吴恩达课程笔记" scheme="http://yoursite.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%90%B4%E6%81%A9%E8%BE%BE%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="正则化" scheme="http://yoursite.com/tags/%E6%AD%A3%E5%88%99%E5%8C%96/"/>
    
  </entry>
  
  <entry>
    <title>【模型优化】浅谈正则化</title>
    <link href="http://yoursite.com/2020/07/03/%E3%80%90%E6%A8%A1%E5%9E%8B%E4%BC%98%E5%8C%96%E3%80%91%E6%B5%85%E8%B0%88%E6%AD%A3%E5%88%99%E5%8C%96/"/>
    <id>http://yoursite.com/2020/07/03/%E3%80%90%E6%A8%A1%E5%9E%8B%E4%BC%98%E5%8C%96%E3%80%91%E6%B5%85%E8%B0%88%E6%AD%A3%E5%88%99%E5%8C%96/</id>
    <published>2020-07-03T11:43:35.000Z</published>
    <updated>2020-07-04T05:18:02.374Z</updated>
    
    <content type="html"><![CDATA[<p>关于<strong>Regularization(正则化)</strong>的问题，这实际上在数学模型优化以及机器学习系统设计中，都是特别难处理的问题，所以我这里也只能用我浅显的认知和大家讲述正则化中最基本的知识。</p><a id="more"></a><h3 id="关于拟合：Underfitting-VS-Overfitting"><a href="#关于拟合：Underfitting-VS-Overfitting" class="headerlink" title="关于拟合：Underfitting VS Overfitting"></a>关于拟合：Underfitting VS Overfitting</h3><p><img src="/../image/ml31.jpg" alt=""></p><p>还是之前关于房价的例子，如果我们尝试用不同的函数进行拟合，选用一次函数，我们会发现，我们并没有完成一个比较好的拟合效果，所以我们称这种拟合为<strong>欠拟合(Underfitting)</strong>。而选用四次函数，我们会发现这样的拟合可能会误差很小，即<script type="math/tex">J(\theta)=\frac{1}{2m}\sum\limits_{i=1}^n\left(h_\theta(x)-y^{(i)}\right)^2\approx0</script>，但是很显然这个，函数拟合的并不满足实际情况(实际曲线根本不可能这么陡峭)，也就是说这个拟合的泛化效果不好，这种情况我们称为过拟合。而正则化正是为我们解决过拟合问题的。</p><h3 id="正则化代价函数"><a href="#正则化代价函数" class="headerlink" title="正则化代价函数"></a>正则化代价函数</h3><p>我们考虑一个问题，会出现过拟合现象的原因可能是我们对于参数的权重选用不得当，所以我们得像个办法来进行约束，引入一个新的正则化参数$\lambda$，<strong>regularization parament</strong> 。从而我们可以得到新的代价函数：</p><script type="math/tex; mode=display">J(\theta)=\frac{1}{2m}[\sum_{i=1}^{m}\left(h_\theta(x^{(i)})-y^{(i)}\right)^2+\lambda\sum_{i=1}^n\theta_j^2]</script><p>这样我们通过控制正则化参数的值就能对模型或者系统进行一定程度的优化或者说可视化的控制。</p><p>不管是正则化任何模型，我们控制的都是我们待定的权重，通过这样的方式，我们可以固定函数的类别，得到更合理的模型，在处理非线性的问题中广泛应用。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;关于&lt;strong&gt;Regularization(正则化)&lt;/strong&gt;的问题，这实际上在数学模型优化以及机器学习系统设计中，都是特别难处理的问题，所以我这里也只能用我浅显的认知和大家讲述正则化中最基本的知识。&lt;/p&gt;
    
    </summary>
    
    
      <category term="数学建模" scheme="http://yoursite.com/categories/%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1/"/>
    
      <category term="模型篇" scheme="http://yoursite.com/categories/%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1/%E6%A8%A1%E5%9E%8B%E7%AF%87/"/>
    
    
      <category term="正则化" scheme="http://yoursite.com/tags/%E6%AD%A3%E5%88%99%E5%8C%96/"/>
    
  </entry>
  
  <entry>
    <title>【初等模型】Logistic回归模型</title>
    <link href="http://yoursite.com/2020/06/29/%E3%80%90%E5%88%9D%E7%AD%89%E6%A8%A1%E5%9E%8B%E3%80%91Logistic%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B/"/>
    <id>http://yoursite.com/2020/06/29/%E3%80%90%E5%88%9D%E7%AD%89%E6%A8%A1%E5%9E%8B%E3%80%91Logistic%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B/</id>
    <published>2020-06-28T21:14:03.000Z</published>
    <updated>2020-07-02T16:09:56.294Z</updated>
    
    <content type="html"><![CDATA[<p>上一篇博客中，我们讲到了线性回归模型，是监督学习中的一个做预测工作的例子。而这里的Logistic回归则是监督学习的一个做分类工作例子，在数学建模与机器学习中，Logistic回归通常用于分类的目的，例如邮件的垃圾邮件分类，肿瘤的恶性良性分类等等。By the way，Logistic回归和Logistic分类是一回事，大家完全可以将两者等价。</p><p>Logistic回归有两种任务情况，分别是二元分类和多元分类问题，从字面上理解来说，binary problem是二元问题：非此即彼，非0即1 。而多元分类则是有多个分类组别，下面我们先从易入难，从binary的Logistic回归说起。</p><a id="more"></a><h3 id="Logistic模型描述"><a href="#Logistic模型描述" class="headerlink" title="Logistic模型描述"></a>Logistic模型描述</h3><p>和线性回归模型思想一项，也会存在单特征或多个特征$x^{(1)}_j$的情况，但是我们的目标值或者是输出值只有两种，0或1，即$y\in \{0,1\}$。其中”0”代表”Negative Class”，”1”代表”Positive Class”。</p><p>但是我们通过假设函数计算的输出值即$h_{\theta}(x)$可不可能只有0或1两个情况，很显然，根本没有连续函数能达到这个功能，所以在输出值有一段连续值得情况下，我们设置一个<strong>阈值(threshold)</strong>。例如我们讨论关于肿瘤恶性与良性的分类，设置阈值为0.5，这是什么意思呢？</p><p>如果$h_{\theta}(x)\geq 0.5$，那我们预测$y=1$，即在这种情况下，我们更倾向于将这个肿瘤划分为恶性的。反之$h_{\theta}(x)&lt;0.5$，则$y=0$。在这方面，后来也有很多扩展，比如应用于年龄估计和情感计算的多标签分布学习与标记增强，拜读过东南大学耿新老师的论文，如果有兴趣可以去看看。</p><p>为了使得分类任务靠设定阈值顺利进行，我们其实还得保证输出$h(x)$的范围的确定性，如果范围过于不确定，那阈值的选择会比较困难，所以之后我们会讲到这种方法，使得$0\leq h_{\theta}(x)\leq 1$。</p><h3 id="假设函数的新表示方法-区别于线性回归"><a href="#假设函数的新表示方法-区别于线性回归" class="headerlink" title="假设函数的新表示方法(区别于线性回归)"></a>假设函数的新表示方法(区别于线性回归)</h3><p>在上文中提到，我们为了想让$0\leq h_{\theta}(x)\leq 1$满足在这个范围内，我们引入一个神奇的函数，在机器学习中这个函数当真反复出现，<strong>Sigmoid function/Logistic function</strong>(这两个函数就是等价的，一个意思)：</p><p><img src="/../image/ml21.jpg" alt=""></p><p>这是个生物学函数，为了显示它的重要性，我单独列一行出来：</p><script type="math/tex; mode=display">g(z)=\frac{1}{1+e^{-z}}</script><p>现在我们写出Logistic回归模型的假设函数，并与之前的线性回归模型的进行对比：</p><script type="math/tex; mode=display">\begin{align}Linear&:h_{\theta}(x)=\theta^Tx\\Logistic&:h_{\theta}(x)=g(\theta^Tx)=\frac{1}{1+e^{-\theta^Tx}}\end{align}</script><p>事实上，就是区别于Sigmoid函数，还是之前恶性与良性肿瘤的例子。根据我输入的特征向量，求出的假设函数$h(x)$实际上代表着预测$y=1$的概率，即：</p><script type="math/tex; mode=display">h(x)=P(y=1|x;\theta),y=0,1</script><p>比如输出一组特征值，我们输出$h(x)=0.7$代表肿瘤为恶性的可能性为$70\%$，考虑到我们之前所定阈值为0.5，所以这个肿瘤我们划分在恶性中去。</p><h3 id="决策界限-Decision-Boundary"><a href="#决策界限-Decision-Boundary" class="headerlink" title="决策界限(Decision Boundary)"></a>决策界限(Decision Boundary)</h3><h4 id="线性"><a href="#线性" class="headerlink" title="线性"></a>线性</h4><p><img src="/../image/ml22.jpg" alt=""></p><p>通常选择线性or非线性，主要还是观察数据集的分布情况。比如上图，我们采用线性Boundary，$z=\theta^Tx$我们通过现有的数据集计算出了，$\theta^T=\begin{bmatrix}-3 &amp; 1&amp; 1\end{bmatrix}$，由于我们知道Sigmoid函数的性质我们知道，当$z\geq0$时，$g(z)\geq0.5$，我们认为它属于恶性肿瘤，反之相对即可。即我们最终计算出的线性决策界限，就是$z\geq0$时为恶性肿瘤，即$-3+x_1+x_2\geq0$。我们通过$\theta$反推得出了决策界限。</p><h4 id="非线性"><a href="#非线性" class="headerlink" title="非线性"></a>非线性</h4><p><img src="/../image/ml23.jpg" alt=""></p><p>在这个非线性的例子中，我们处理非线性的决策边界问题，令假设函数的表达式为：</p><script type="math/tex; mode=display">h(x)=g(\theta_0+\theta_1x_1+\theta_2x_2+\theta_3x_1^2+\theta_4x_2^2)</script><p>当然你可能会觉得这个假设函数的设置过于主观，that’s ok. 这可能是我通常不会选择Logistic来处理非线性分类问题的原因。在这种分类问题，我更喜欢构建SVM的模型，这个我们之后会提到。好了，话说回来，这个我们通过计算得到，$\theta^T=\begin{bmatrix}-1 &amp; 0 &amp; 0 &amp; 1 &amp; 1\end{bmatrix}$，由Sigmoid的性质可得，当$z\geq 0$时，即$x_1^2+x^2_2\geq 1$，在这个情况下，我们更希望相信这个分类成为恶性肿瘤，反之也相对。下面我们来说说，Logistic回归的代价函数。</p><h3 id="代价函数-Cost-Function"><a href="#代价函数-Cost-Function" class="headerlink" title="代价函数(Cost Function)"></a>代价函数(Cost Function)</h3><h4 id="引入"><a href="#引入" class="headerlink" title="引入"></a>引入</h4><p>我们上述讨论了决策边界的问题，那么我们现在需要解决的问题就是如何选取最优的$\theta$值，即代价函数最小。首先，我先说Logistic的代价函数，和我们之前的线性回归的表达形式一模一样：</p><script type="math/tex; mode=display">J(\theta)=\frac{1}{2m}\sum_{i=1}^m\left(h_\theta(x^{(i)})-y^{(i)}\right)^2</script><p>你可能觉得这个代价函数和线性回归的一模一样，但是有一些细微的差别，在这里$h(x)=g(z)$，而线性回归则没有加入sigmoid函数。但是，我们其实通常并不选择这个函数为我们所要的代价函数，我这里简单说下原因，由于我们的假设函数是关于sigmoid的函数，是一个非线性的函数。代入计算，我们的代价函数会是一个非凸函数。</p><p><img src="/../image/ml24.jpg" alt=""></p><p>在这个情况下，非凸函数如左图所示，他有很多的局部最优点，所以我们使用梯度下降法是找不到全局最优点的。而我们需要找一个<strong>凸函数(convex function)</strong>，也就是弓形函数，仅有一个全局最优解，所以我们通过梯度下降法就能很好做到找到代价函数的最优点。</p><h4 id="改进Cost，重新化简代价函数"><a href="#改进Cost，重新化简代价函数" class="headerlink" title="改进Cost，重新化简代价函数"></a>改进Cost，重新化简代价函数</h4><p>在上个引入部分中，我们令代价函数的部分为：</p><script type="math/tex; mode=display">\begin{align}J(\theta)&=\frac{1}{m}\sum_{i=1}^m\frac{1}{2}\left(h_\theta(x^{(i)})-y^{(i)}\right)^2\\Cost(h_\theta(x^{(i)}),y^{(i)})&=\frac{1}{2}\left(h_\theta(x^{(i)})-y^{(i)}\right)^2\\\end{align}</script><p>下面我们来改进一个新的Cost从而得到新的代价函数，而这个代价函数我们希望他是convex的，还是以二分类问题来举例：</p><script type="math/tex; mode=display">Cost(h_\theta(x),y)=\begin{cases}-log(h_\theta(x)) & \text{if } y=1\\-log(1-h_\theta(x)) & \text{if } y=0\\\end{cases}</script><p>在binary的问题中，我们注意到y的值总是0或1，所以我们重新化简代价函数：</p><script type="math/tex; mode=display">J(\theta)=-\frac{1}{m}[\sum_{i=1}^my^{(i)}logh_{\theta}(x^{(i)})+(1-y^{(i)})log(1-h_{\theta}(x^{(i)}))]</script><p>然后我们又可以愉快地用梯度下降算法啦！！</p><h3 id="多元分类问题-Multi-class-classification"><a href="#多元分类问题-Multi-class-classification" class="headerlink" title="多元分类问题(Multi-class classification)"></a>多元分类问题(Multi-class classification)</h3><p>其实，多元分类与二元分类基本类似，我们现在假设我们有三个类别(更多的也一样)，Class 1~3，我们简单用下图来说明下问题。</p><p><img src="/../image/ml25.jpg" alt=""></p><p>吴恩达老师上课的课件，看到$h_{\theta}^{(i)}=P(y=i|x;\theta)$这个公式(julao不愧是julao)，让我茅塞顿开。其实多元分类问题就可以写成二元分类，如果你还没看懂，我来做下简单的解释。</p><script type="math/tex; mode=display">J^{(i)}(\theta)=-\frac{1}{m}[\sum_{i=1}^mylogh^{(i)}_{\theta}(x)+(i-y)log(1-h^{(i)}_{\theta}(x))]</script><p>这样，我们便依然可以采用梯度下降法去求解。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;上一篇博客中，我们讲到了线性回归模型，是监督学习中的一个做预测工作的例子。而这里的Logistic回归则是监督学习的一个做分类工作例子，在数学建模与机器学习中，Logistic回归通常用于分类的目的，例如邮件的垃圾邮件分类，肿瘤的恶性良性分类等等。By the way，Logistic回归和Logistic分类是一回事，大家完全可以将两者等价。&lt;/p&gt;
&lt;p&gt;Logistic回归有两种任务情况，分别是二元分类和多元分类问题，从字面上理解来说，binary problem是二元问题：非此即彼，非0即1 。而多元分类则是有多个分类组别，下面我们先从易入难，从binary的Logistic回归说起。&lt;/p&gt;
    
    </summary>
    
    
      <category term="数学建模" scheme="http://yoursite.com/categories/%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1/"/>
    
      <category term="模型篇" scheme="http://yoursite.com/categories/%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1/%E6%A8%A1%E5%9E%8B%E7%AF%87/"/>
    
    
      <category term="Logistic" scheme="http://yoursite.com/tags/Logistic/"/>
    
  </entry>
  
  <entry>
    <title>【吴恩达笔记】Logistic回归</title>
    <link href="http://yoursite.com/2020/06/29/%E3%80%90%E5%90%B4%E6%81%A9%E8%BE%BE%E7%AC%94%E8%AE%B0%E3%80%91Logistic%E5%9B%9E%E5%BD%92/"/>
    <id>http://yoursite.com/2020/06/29/%E3%80%90%E5%90%B4%E6%81%A9%E8%BE%BE%E7%AC%94%E8%AE%B0%E3%80%91Logistic%E5%9B%9E%E5%BD%92/</id>
    <published>2020-06-28T21:13:21.000Z</published>
    <updated>2020-07-03T02:31:53.704Z</updated>
    
    <content type="html"><![CDATA[<p>上一篇博客中，我们讲到了线性回归模型，是监督学习中的一个做预测工作的例子。而这里的Logistic回归则是监督学习的一个做分类工作例子，在数学建模与机器学习中，Logistic回归通常用于分类的目的，例如邮件的垃圾邮件分类，肿瘤的恶性良性分类等等。By the way，Logistic回归和Logistic分类是一回事，大家完全可以将两者等价。</p><p>Logistic回归有两种任务情况，分别是二元分类和多元分类问题，从字面上理解来说，binary problem是二元问题：非此即彼，非0即1 。而多元分类则是有多个分类组别，下面我们先从易入难，从binary的Logistic回归说起。</p><a id="more"></a><h3 id="Logistic模型描述"><a href="#Logistic模型描述" class="headerlink" title="Logistic模型描述"></a>Logistic模型描述</h3><p>和线性回归模型思想一项，也会存在单特征或多个特征$x^{(1)}_j$的情况，但是我们的目标值或者是输出值只有两种，0或1，即$y\in \{0,1\}$。其中”0”代表”Negative Class”，”1”代表”Positive Class”。</p><p>但是我们通过假设函数计算的输出值即$h_{\theta}(x)$可不可能只有0或1两个情况，很显然，根本没有连续函数能达到这个功能，所以在输出值有一段连续值得情况下，我们设置一个<strong>阈值(threshold)</strong>。例如我们讨论关于肿瘤恶性与良性的分类，设置阈值为0.5，这是什么意思呢？</p><p>如果$h_{\theta}(x)\geq 0.5$，那我们预测$y=1$，即在这种情况下，我们更倾向于将这个肿瘤划分为恶性的。反之$h_{\theta}(x)&lt;0.5$，则$y=0$。在这方面，后来也有很多扩展，比如应用于年龄估计和情感计算的多标签分布学习与标记增强，拜读过东南大学耿新老师的论文，如果有兴趣可以去看看。</p><p>为了使得分类任务靠设定阈值顺利进行，我们其实还得保证输出$h(x)$的范围的确定性，如果范围过于不确定，那阈值的选择会比较困难，所以之后我们会讲到这种方法，使得$0\leq h_{\theta}(x)\leq 1$。</p><h3 id="假设函数的新表示方法-区别于线性回归"><a href="#假设函数的新表示方法-区别于线性回归" class="headerlink" title="假设函数的新表示方法(区别于线性回归)"></a>假设函数的新表示方法(区别于线性回归)</h3><p>在上文中提到，我们为了想让$0\leq h_{\theta}(x)\leq 1$满足在这个范围内，我们引入一个神奇的函数，在机器学习中这个函数当真反复出现，<strong>Sigmoid function/Logistic function</strong>(这两个函数就是等价的，一个意思)：</p><p><img src="/../image/ml21.jpg" alt=""></p><p>这是个生物学函数，为了显示它的重要性，我单独列一行出来：</p><script type="math/tex; mode=display">g(z)=\frac{1}{1+e^{-z}}</script><p>现在我们写出Logistic回归模型的假设函数，并与之前的线性回归模型的进行对比：</p><script type="math/tex; mode=display">\begin{align}Linear&:h_{\theta}(x)=\theta^Tx\\Logistic&:h_{\theta}(x)=g(\theta^Tx)=\frac{1}{1+e^{-\theta^Tx}}\end{align}</script><p>事实上，就是区别于Sigmoid函数，还是之前恶性与良性肿瘤的例子。根据我输入的特征向量，求出的假设函数$h(x)$实际上代表着预测$y=1$的概率，即：</p><script type="math/tex; mode=display">h(x)=P(y=1|x;\theta),y=0,1</script><p>比如输出一组特征值，我们输出$h(x)=0.7$代表肿瘤为恶性的可能性为$70\%$，考虑到我们之前所定阈值为0.5，所以这个肿瘤我们划分在恶性中去。</p><h3 id="决策界限-Decision-Boundary"><a href="#决策界限-Decision-Boundary" class="headerlink" title="决策界限(Decision Boundary)"></a>决策界限(Decision Boundary)</h3><h4 id="线性"><a href="#线性" class="headerlink" title="线性"></a>线性</h4><p><img src="/../image/ml22.jpg" alt=""></p><p>通常选择线性or非线性，主要还是观察数据集的分布情况。比如上图，我们采用线性Boundary，$z=\theta^Tx$我们通过现有的数据集计算出了，$\theta^T=\begin{bmatrix}-3 &amp; 1&amp; 1\end{bmatrix}$，由于我们知道Sigmoid函数的性质我们知道，当$z\geq0$时，$g(z)\geq0.5$，我们认为它属于恶性肿瘤，反之相对即可。即我们最终计算出的线性决策界限，就是$z\geq0$时为恶性肿瘤，即$-3+x_1+x_2\geq0$。我们通过$\theta$反推得出了决策界限。</p><h4 id="非线性"><a href="#非线性" class="headerlink" title="非线性"></a>非线性</h4><p><img src="/../image/ml23.jpg" alt=""></p><p>在这个非线性的例子中，我们处理非线性的决策边界问题，令假设函数的表达式为：</p><script type="math/tex; mode=display">h(x)=g(\theta_0+\theta_1x_1+\theta_2x_2+\theta_3x_1^2+\theta_4x_2^2)</script><p>当然你可能会觉得这个假设函数的设置过于主观，that’s ok. 这可能是我通常不会选择Logistic来处理非线性分类问题的原因。在这种分类问题，我更喜欢构建SVM的模型，这个我们之后会提到。好了，话说回来，这个我们通过计算得到，$\theta^T=\begin{bmatrix}-1 &amp; 0 &amp; 0 &amp; 1 &amp; 1\end{bmatrix}$，由Sigmoid的性质可得，当$z\geq 0$时，即$x_1^2+x^2_2\geq 1$，在这个情况下，我们更希望相信这个分类成为恶性肿瘤，反之也相对。下面我们来说说，Logistic回归的代价函数。</p><h3 id="代价函数-Cost-Function"><a href="#代价函数-Cost-Function" class="headerlink" title="代价函数(Cost Function)"></a>代价函数(Cost Function)</h3><h4 id="引入"><a href="#引入" class="headerlink" title="引入"></a>引入</h4><p>我们上述讨论了决策边界的问题，那么我们现在需要解决的问题就是如何选取最优的$\theta$值，即代价函数最小。首先，我先说Logistic的代价函数，和我们之前的线性回归的表达形式一模一样：</p><script type="math/tex; mode=display">J(\theta)=\frac{1}{2m}\sum_{i=1}^m\left(h_\theta(x^{(i)})-y^{(i)}\right)^2</script><p>你可能觉得这个代价函数和线性回归的一模一样，但是有一些细微的差别，在这里$h(x)=g(z)$，而线性回归则没有加入sigmoid函数。但是，我们其实通常并不选择这个函数为我们所要的代价函数，我这里简单说下原因，由于我们的假设函数是关于sigmoid的函数，是一个非线性的函数。代入计算，我们的代价函数会是一个非凸函数。</p><p><img src="/../image/ml24.jpg" alt=""></p><p>在这个情况下，非凸函数如左图所示，他有很多的局部最优点，所以我们使用梯度下降法是找不到全局最优点的。而我们需要找一个<strong>凸函数(convex function)</strong>，也就是弓形函数，仅有一个全局最优解，所以我们通过梯度下降法就能很好做到找到代价函数的最优点。</p><h4 id="改进Cost，重新化简代价函数"><a href="#改进Cost，重新化简代价函数" class="headerlink" title="改进Cost，重新化简代价函数"></a>改进Cost，重新化简代价函数</h4><p>在上个引入部分中，我们令代价函数的部分为：</p><script type="math/tex; mode=display">\begin{align}J(\theta)&=\frac{1}{m}\sum_{i=1}^m\frac{1}{2}\left(h_\theta(x^{(i)})-y^{(i)}\right)^2\\Cost(h_\theta(x^{(i)}),y^{(i)})&=\frac{1}{2}\left(h_\theta(x^{(i)})-y^{(i)}\right)^2\\\end{align}</script><p>下面我们来改进一个新的Cost从而得到新的代价函数，而这个代价函数我们希望他是convex的，还是以二分类问题来举例：</p><script type="math/tex; mode=display">Cost(h_\theta(x),y)=\begin{cases}-log(h_\theta(x)) & \text{if } y=1\\-log(1-h_\theta(x)) & \text{if } y=0\\\end{cases}</script><p>在binary的问题中，我们注意到y的值总是0或1，所以我们重新化简代价函数：</p><script type="math/tex; mode=display">J(\theta)=-\frac{1}{m}[\sum_{i=1}^my^{(i)}logh_{\theta}(x^{(i)})+(1-y^{(i)})log(1-h_{\theta}(x^{(i)}))]</script><p>然后我们又可以愉快地用梯度下降算法啦！！</p><h3 id="多元分类问题-Multi-class-classification"><a href="#多元分类问题-Multi-class-classification" class="headerlink" title="多元分类问题(Multi-class classification)"></a>多元分类问题(Multi-class classification)</h3><p>其实，多元分类与二元分类基本类似，我们现在假设我们有三个类别(更多的也一样)，Class 1~3，我们简单用下图来说明下问题。</p><p><img src="/../image/ml25.jpg" alt=""></p><p>吴恩达老师上课的课件，看到$h_{\theta}^{(i)}=P(y=i|x;\theta)$这个公式(julao不愧是julao)，让我茅塞顿开。其实多元分类问题就可以写成二元分类，如果你还没看懂，我来做下简单的解释。</p><script type="math/tex; mode=display">J^{(i)}(\theta)=-\frac{1}{m}[\sum_{i=1}^mylogh^{(i)}_{\theta}(x)+(i-y)log(1-h^{(i)}_{\theta}(x))]</script><p>这样，我们便依然可以采用梯度下降法去求解。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;上一篇博客中，我们讲到了线性回归模型，是监督学习中的一个做预测工作的例子。而这里的Logistic回归则是监督学习的一个做分类工作例子，在数学建模与机器学习中，Logistic回归通常用于分类的目的，例如邮件的垃圾邮件分类，肿瘤的恶性良性分类等等。By the way，Logistic回归和Logistic分类是一回事，大家完全可以将两者等价。&lt;/p&gt;
&lt;p&gt;Logistic回归有两种任务情况，分别是二元分类和多元分类问题，从字面上理解来说，binary problem是二元问题：非此即彼，非0即1 。而多元分类则是有多个分类组别，下面我们先从易入难，从binary的Logistic回归说起。&lt;/p&gt;
    
    </summary>
    
    
      <category term="机器学习" scheme="http://yoursite.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="吴恩达课程笔记" scheme="http://yoursite.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%90%B4%E6%81%A9%E8%BE%BE%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="Logistic" scheme="http://yoursite.com/tags/Logistic/"/>
    
  </entry>
  
  <entry>
    <title>【初等模型】线性回归</title>
    <link href="http://yoursite.com/2020/06/29/%E3%80%90%E5%88%9D%E7%AD%89%E6%A8%A1%E5%9E%8B%E3%80%91%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/"/>
    <id>http://yoursite.com/2020/06/29/%E3%80%90%E5%88%9D%E7%AD%89%E6%A8%A1%E5%9E%8B%E3%80%91%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/</id>
    <published>2020-06-28T20:19:57.000Z</published>
    <updated>2020-06-28T13:29:45.296Z</updated>
    
    <content type="html"><![CDATA[<p>你可能会发现这篇博客与我之前的机器学习的线性回归完全一样，没错，就是一样的。知识点都是线性回归，所以能有什么区别呢，线性回归模型都是数学模型与机器学习中最基础的模型，需要注意的是，学校老师培训的数学建模竞赛培训可能更重视原理，导致大部分同学听了个寂寞。但是往往比赛我们会使用就行，不用太过于纠结，另外题目与源代码之后补上2333。</p><h3 id="一元线性回归-单变量线性回归-Linear-Regression-with-one-variable"><a href="#一元线性回归-单变量线性回归-Linear-Regression-with-one-variable" class="headerlink" title="一元线性回归(单变量线性回归)  Linear Regression with one variable"></a>一元线性回归(单变量线性回归)  Linear Regression with one variable</h3><a id="more"></a><h4 id="1-模型描述"><a href="#1-模型描述" class="headerlink" title="1. 模型描述"></a>1. 模型描述</h4><p>首先明确线性回归的作用，在机器学习中，我们可以广义的把机器学习划分为两类学习，监督学习与无监督学习。简单而言，监督学习就是给出了准确答案，期望计算机能学习其中的原理，并对我们未知的事情做出一定的预测。无监督学习就是指，我们并不知道准确结果的事情，希望机器通过学习，能从中抽取有效信息，举个简单的例子，例如邮箱垃圾邮件分类，新闻栏目划分等等，这些我们都能通过无监督学习去解决。</p><p>好了下面再举一个关于监督学习的例子，吴老师上课的例子是房价预估，如下图所示。</p><p><img src="/../image/ml1.jpg" alt=""></p><p>给你一定数量的数据集，代表房屋尺寸与价格的散点图，现在你希望知道除这些数据集以外的Size所对应的Price，相当于我之前说的预测。比如Size为1250时，那Price可能为2200左右这样子。那这个过程，我们实际就是想从现已知的数据集中学习某些知识内容，从而达到预测的效果。而这个过程就是我们所说的，<strong>回归</strong>。</p><p>其实就是拟合函数曲线，从而达到其与数据集的最优拟合，然后预测所有的Size。由于这个房子的单价这个假设中只与Size有关，所以我们称它为单变量或是一元。</p><p>下图是关于机器学习的基本流程图，你可以认为几乎所有机器学习问题都是这个框架的东西。</p><p><img src="/../image/ml2.jpg" alt=""></p><p>而这其中的$h$，代表$hypothesis$，由流程图可以看出，它是由数据集与学习算法得来的，在数学模型中，它代表回归模型，在机器学习中，我们通常把它称作假设函数。</p><script type="math/tex; mode=display">\begin{align}how\quad &to \quad represent \quad h \quad ?\\h_{\theta}(x)&=\theta_0+\theta_1x\end{align}</script><p>以上便是我们在一元线性回归模型中的假设函数了，可以看出，实际上我们是对数据集拟合了一个一次函数，所以我们才说是线性回归，那么实际的问题中，当然不是所有问题都是线性的关系，这个我们之后再去说。好了，目前为止，我已经解释了所有关于一元线性回归模型的意义了，下面我们来看点重要的。</p><h4 id="2-代价函数-cost-function"><a href="#2-代价函数-cost-function" class="headerlink" title="2. 代价函数 cost function"></a>2. 代价函数 cost function</h4><p><img src="/../image/ml3.jpg" alt=""></p><p>下面我们来看个更具体的例子，我们已经给出了数据集，要求求出Size和Price的内在关系，可以很明显的知道这是个一元回归问题，至于线性，这个我们不是我们现在需要考虑的，我们就当它拟合为线性一次函数。首先先解释数据集中几个变量符号的意义：</p><ul><li><strong>m：数据集的数量</strong></li><li><strong>x：特征/输入变量</strong>      $x^{(i)}$代表第i个特征$(i=1,2,…,m)$</li><li><strong>y：目标/输出变量</strong>      $y^{(i)}$代表第i个目标$(i=1,2,…,m)$</li></ul><p>当然不同的人有不同的表示方法，我相信这不是比较关键的东西，whatever。我们还是需要得到我们的假设函数$h_{\theta}(x)=\theta_0+\theta_1x$，如何选择$\theta_i$，即参数，才是我们需要关注的问题。ps：之后的$h_{\theta}(x)$全部简写为$h(x)$</p><p>我们的目的当然是，一次线性函数与原数据集有高度的拟合，即我们假设函数$h(x)$得到的结果与原目标$y$差距越小越好，于是我们得到了我们所谓的回归目标：</p><script type="math/tex; mode=display">min_{\theta_i}:\frac{1}{2m}\sum_{i=1}^m \left(h(x^{(i)})-y^{(i)}\right)^2</script><p>这其实是个方差公式的形式，我们添上了系数1/2。然后很明显地，我们完全可以用这个函数来判断我们的拟合程度，这个值越小就说明我们的拟合效果越好。于是，我们就规定了一个函数：</p><script type="math/tex; mode=display">J(\theta_i)=\frac{1}{2m}\sum_{i=1}^m \left(h(x^{(i)})-y^{(i)}\right)^2</script><p>然而这个函数就是<strong>代价函数(cost function)</strong>，表面意思就是为了拟合某个数据集，我们所需要付出的代价。在所有机器学习的问题中，我们都在研究如何使得代价函数最小，也就是我们上面所说的回归目标。</p><p><img src="/../image/ml4.jpg" alt=""></p><p>解决问题时，我们通常会有两张常见的可视化图片，第一张是$h(x)$的图，也就是Size和Price的数据集的图，第二张图是关于代价函数的，也有画三维图的，当然也有这种画等高线的。在接下来的问题中，我们会研究通过何种算法，让机器帮助我们找到最优目标的参数值。</p><h4 id="3-梯度下降算法-Gradient-Descent-Algorithm"><a href="#3-梯度下降算法-Gradient-Descent-Algorithm" class="headerlink" title="3. 梯度下降算法  Gradient Descent Algorithm"></a>3. 梯度下降算法  Gradient Descent Algorithm</h4><p>再次明确我们的模型函数，我们现在有$J(\theta_i)$,目标是让这个函数得到最小值。朴素的思想就是我们可以定起始的$\theta_i$，然后不断地改变他们，直到他们最后到达了最小值。很明显，这样的想法我们还需要更可靠的算法，毕竟全部遍历是不可能的。</p><p>所以这也就引入了梯度下降算法来解决这个问题，先给大家看某个代价函数，以及算法实现的某个过程。</p><p><img src="/../image/ml5.jpg" alt=""></p><p>想法不变，我们从某个$(\theta_0,\theta_1)$开始，不断改变他们的值，直到收敛到局部最优。而这个改变的过程我们称为梯度下降，为了方便理解，我直接给出参数改变的公式，也就是$\theta_i$不断更新的依据，假设仅有两个参数的时候。</p><script type="math/tex; mode=display">\theta_j:=\theta_j-\alpha \frac{\partial}{\partial \theta_j}J(\theta_0,\theta_1) \quad (j=0,1)</script><p>这便是梯度下降最关键的地方，其中有了偏导数符号，这个如果看不懂的话，还是要先学微积分的。仔细想想的话，这样确实能通过下降的方式，使得代价函数收敛到局部最优解。其中$\alpha$代表学习率，你可以理解为每次更新的步长，这个也很关键，但是之后我们也会提到。</p><p>还有需要强调的是，我们的$\theta_i$是同步更新(Simultaneous update)的，这个如果你学过计算方法这门课中求解微分方程的两种方法或许你应该深有体会。</p><p>下面这个例子是同步更新</p><script type="math/tex; mode=display">\begin{align}\\Correct&:Simultaneous \quad update\\temp0&:=\theta_0-\alpha \frac{\partial}{\partial \theta_0}J(\theta_0,\theta_1)\\temp1&:=\theta_1-\alpha \frac{\partial}{\partial \theta_1}J(\theta_0,\theta_1)\\\theta_0&:=temp0\\\theta_1&:=temp1\end{align}</script><p>然后这是不同步更新的例子</p><script type="math/tex; mode=display">\begin{align}Inco&rrect:\\temp0&:=\theta_0-\alpha \frac{\partial}{\partial \theta_0}J(\theta_0,\theta_1)\\\theta_0&:=temp0\\temp1&:=\theta_1-\alpha \frac{\partial}{\partial \theta_1}J(\theta_0,\theta_1)\\\theta_1&:=temp1\end{align}</script><p>在不同步更新的例子中我们发现，$\theta_0$更新后带入了$\theta_1$的更新公式中，这不是我们想要的。</p><p>理解清楚了这个后，我们就明白了梯度下降法的公式了，你可能会说选择不同的开始的起始值会导致不同的收敛点，确实是这样，比如下面这个图。</p><p><img src="/../image/ml6.jpg" alt=""></p><p>很显然因为选择了不同的$\theta_i$会导致两种不同的路线，通过梯度下降算法我们只能找到局部收敛点，而不是全局最优点。不过这也没关系，我们处理问题的时候都尽量会选择弓形函数，也就是<strong>凸函数(convex function)</strong>.这种函数我们保证它仅有一个收敛点，即全局最优解。</p><h3 id="多元线性回归-Linear-Regression-with-Multiple-Variables"><a href="#多元线性回归-Linear-Regression-with-Multiple-Variables" class="headerlink" title="多元线性回归  Linear Regression with Multiple Variables"></a>多元线性回归  Linear Regression with Multiple Variables</h3><h4 id="1-模型描述-多特征"><a href="#1-模型描述-多特征" class="headerlink" title="1. 模型描述 多特征"></a>1. 模型描述 多特征</h4><p>我们根据上面那个房价的例子，很显然在实际的生活中，房价Price绝不可能只与其Size有关系的，你的北京六环和二环的房子能比得起来吗？哦，我知道你没有。这里还是根据那个房价的例子，不过我们提出了更多的影响因素。</p><p><img src="/../image/ml7.jpg" alt=""></p><p>我们还是首先来规定下符号：</p><ul><li><strong>m：数据集的数量</strong></li><li><strong>n：特征的个数</strong>  例如此例n=4</li><li><strong>$x^{(i)}$：序号为i的数据集的特征向量</strong></li><li><strong>$x_j^{(i)}$：序号为i的数据集的第j个特征</strong>  比如40年我们如何表示？ $x_4^{(2)}$=40</li></ul><p>假设函数那当然也是多变量的了，我默认大家都学完了矩阵的东西，所以我就直接用矩阵的表示形式来列了。</p><script type="math/tex; mode=display">\begin{align}h(x)&=\theta_0+\theta_1x_1+\theta_2x_2+...+\theta_nx_n\\define \quad x_0&=1\\x=\begin{bmatrix} x_0\\x_1\\x_2\\\vdots\\x_n \end{bmatrix} \quad& \theta=\begin{bmatrix} \theta_0\\\theta_1\\\theta_2\\\vdots\\\theta_n \end{bmatrix}\\h(x)&=\theta^Tx\end{align}</script><p>我们采用矩阵的表达方式，已经写出了假设函数的矩阵形式，很简单，那下面就来说说如何在这个假设函数中进行梯度下降。</p><h4 id="2-多变量梯度下降"><a href="#2-多变量梯度下降" class="headerlink" title="2. 多变量梯度下降"></a>2. 多变量梯度下降</h4><p>其实梯度下降的公式都是一样的，只不过原来一元的时候只需要更新两个$\theta$值，现在需要更新n个，仅此而已。</p><script type="math/tex; mode=display">\theta_j:=\theta_j-\alpha \frac{\partial}{\partial \theta_j}J(\theta) \quad (j=0,1,...,n)</script><p>但是我们需要注意的，可不是这些。</p><h5 id="1-特征缩放"><a href="#1-特征缩放" class="headerlink" title="(1) 特征缩放"></a>(1) 特征缩放</h5><p>线性回归的目的就是在于求出我们所需要的权重，即$\theta$值，而权重和每个特征量的大小相关。试想一下，如果一个房间的Size的范围是1000左右，而房子的楼层是3以内的数，那我们直接拟合出来的权重，肯定更偏向于Size啊，而这显然不符合实际情况。这就是多元回归区别于一元回归的事情，一元回归就一个变量，咱们不需要考虑其大小范围。但是多元我们必须考虑，我们最好能够将所有变量统一缩放到某个区间，比如$-1\leq x_i\leq 1$。当然这个区间不是必须的，这里只给个参考范围。而对于所有的变量，我们都需要先进行<strong>均值标准化(Mean Normalization)</strong> 的处理。</p><script type="math/tex; mode=display">\begin{align}Mean &\quad Normalization:\\x_j&:=\frac{x_j-\mu_j}{\sigma_j}\end{align}</script><p>我相信如果你学过概率论的话，这个式子应该经常出现，不管是在八大公式还是假设检验里面。还是需要解释一下，这其中$\mu_j$表示第j组特征向量的均值，而$\sigma_j$表示第j组数据的标准差。</p><h5 id="2-特征合并"><a href="#2-特征合并" class="headerlink" title="(2) 特征合并"></a>(2) 特征合并</h5><p>这个是很好理解，也算是多元线性回归里面的一点技巧。比如题目给出的因素中，Price与房子的frontage和depth有关，那我们就要想到$Size=Frontage\times Depth$。于是我们就能把这个两个特征当成一个来处理，其实实际问题中这样的例子还是挺常见的。</p><h5 id="3-学习率与假设函数选择"><a href="#3-学习率与假设函数选择" class="headerlink" title="(3) 学习率与假设函数选择"></a>(3) 学习率与假设函数选择</h5><p>关于学习率$\alpha$与假设函数次项的选择，我在这里就不明说了，因为我自己也不是很能给出一个具体的方案。以及这样的情况遇到的较少。</p><h3 id="正规方程求解参数-Normal-Equation"><a href="#正规方程求解参数-Normal-Equation" class="headerlink" title="正规方程求解参数  Normal Equation"></a>正规方程求解参数  Normal Equation</h3><p>事实上，我们除了梯度下降法，还有另一种方法求解我们所需要的参数以及权重$\theta$的方法，就是用普通的方程求解，剩下的交给MATLAB就好，以上面那个例子来说明。</p><p><img src="/../image/ml7.jpg" alt=""></p><p>我们希望求得一组$\theta$值，能够假设函数能够很好地拟合最终的Price，其实我们不难列出我们的假设函数：</p><script type="math/tex; mode=display">h(x)=\begin{bmatrix}1 & 2104 & 5 &1 &45\\1 & 1416 & 3 &2 &40\\\vdots & \vdots & \vdots & \vdots & \vdots\end{bmatrix}\times\begin{bmatrix}\theta_0 \\\theta_1 \\\vdots \\\theta_n\end{bmatrix}=X\theta</script><p>实际上我们添加了$x_0=1$这一项，如果能够理解的话，那说明你基本明白了线性回归的知识点。然后我们要用Normal的方法解得我们需要的$\theta$：</p><script type="math/tex; mode=display">\theta = (X^TX)^{-1}X^Ty \quad ,\quad y=\begin{bmatrix} 460\\232\\315\\178\\ \vdots\end{bmatrix}</script><p>很遗憾地告诉你，我并不能告诉你这个方程是怎么推出来的，其实你也不需要理解。在数学建模竞赛或是机器学习研究中，我们大部分情况下只需要会用即可。</p><p>ok，到这里关于线性回归模型的求解，你已经学会了两种方法，梯度下降算法与正规方程解法，你可能会觉得正规方程解法会比较方便，下面我就来说说正规方程解法的局限性。</p><ul><li>正规方程解法需要计算矩阵的逆，当特征数大于样本数时，矩阵为奇异矩阵，无逆矩阵，虽然MATLAB命令<code>pinv</code>也能得到近似解，但是这往往不符合我们的预测要求。</li><li>当样本数量也特别大的时候，矩阵计算会非常缓慢，通常几千以内的矩阵，MATLAB计算还是比梯度下降快的，数量再往上我们可能就要选择梯度下降法了。</li></ul><p>当然梯度下降法也要选择学习率与迭代次数，这就需要我们理解代价函数，并根据此来判断。Emmm，说到这里，线性回归的内容基本就结束了，我可能会遗憾的告诉你，大部分数学建模竞赛或是机器学习问题，光靠线性回归模型基本不可能解决问题，因为真正的实际问题是线性关系的真的很少，但是这并不影响线性回归依旧是你最需要掌握的算法，这是所有其他问题的基础。</p><p>Good Luck！</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;你可能会发现这篇博客与我之前的机器学习的线性回归完全一样，没错，就是一样的。知识点都是线性回归，所以能有什么区别呢，线性回归模型都是数学模型与机器学习中最基础的模型，需要注意的是，学校老师培训的数学建模竞赛培训可能更重视原理，导致大部分同学听了个寂寞。但是往往比赛我们会使用就行，不用太过于纠结，另外题目与源代码之后补上2333。&lt;/p&gt;
&lt;h3 id=&quot;一元线性回归-单变量线性回归-Linear-Regression-with-one-variable&quot;&gt;&lt;a href=&quot;#一元线性回归-单变量线性回归-Linear-Regression-with-one-variable&quot; class=&quot;headerlink&quot; title=&quot;一元线性回归(单变量线性回归)  Linear Regression with one variable&quot;&gt;&lt;/a&gt;一元线性回归(单变量线性回归)  Linear Regression with one variable&lt;/h3&gt;
    
    </summary>
    
    
      <category term="数学建模" scheme="http://yoursite.com/categories/%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1/"/>
    
      <category term="模型篇" scheme="http://yoursite.com/categories/%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1/%E6%A8%A1%E5%9E%8B%E7%AF%87/"/>
    
    
      <category term="线性回归" scheme="http://yoursite.com/tags/%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/"/>
    
  </entry>
  
  <entry>
    <title>【吴恩达笔记】线性回归</title>
    <link href="http://yoursite.com/2020/06/27/%E3%80%90%E5%90%B4%E6%81%A9%E8%BE%BE%E7%AC%94%E8%AE%B0%E3%80%91%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/"/>
    <id>http://yoursite.com/2020/06/27/%E3%80%90%E5%90%B4%E6%81%A9%E8%BE%BE%E7%AC%94%E8%AE%B0%E3%80%91%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/</id>
    <published>2020-06-27T14:58:06.000Z</published>
    <updated>2020-06-28T12:16:35.667Z</updated>
    
    <content type="html"><![CDATA[<p>吴恩达老师的机器学习公开课应该算是目前我见过，最适合小白入门的公开课程了。即使内容对新人比较友好，但我想还是需要整理些许笔记的，因为涉及到机器学习的基础阶段，各个概念的掌握情况，我跳过了一些对我个人而言不重要的栏目，比如线性代数和matlab教程这些。之后也会补上上课的作业，Coursera申请助学金需要时间比较久。</p><h3 id="一元线性回归-单变量线性回归-Linear-Regression-with-one-variable"><a href="#一元线性回归-单变量线性回归-Linear-Regression-with-one-variable" class="headerlink" title="一元线性回归(单变量线性回归)  Linear Regression with one variable"></a>一元线性回归(单变量线性回归)  Linear Regression with one variable</h3><a id="more"></a><h4 id="1-模型描述"><a href="#1-模型描述" class="headerlink" title="1. 模型描述"></a>1. 模型描述</h4><p>首先明确线性回归的作用，在机器学习中，我们可以广义的把机器学习划分为两类学习，监督学习与无监督学习。简单而言，监督学习就是给出了准确答案，期望计算机能学习其中的原理，并对我们未知的事情做出一定的预测。无监督学习就是指，我们并不知道准确结果的事情，希望机器通过学习，能从中抽取有效信息，举个简单的例子，例如邮箱垃圾邮件分类，新闻栏目划分等等，这些我们都能通过无监督学习去解决。</p><p>好了下面再举一个关于监督学习的例子，吴老师上课的例子是房价预估，如下图所示。</p><p><img src="/../image/ml1.jpg" alt=""></p><p>给你一定数量的数据集，代表房屋尺寸与价格的散点图，现在你希望知道除这些数据集以外的Size所对应的Price，相当于我之前说的预测。比如Size为1250时，那Price可能为2200左右这样子。那这个过程，我们实际就是想从现已知的数据集中学习某些知识内容，从而达到预测的效果。而这个过程就是我们所说的，<strong>回归</strong>。</p><p>其实就是拟合函数曲线，从而达到其与数据集的最优拟合，然后预测所有的Size。由于这个房子的单价这个假设中只与Size有关，所以我们称它为单变量或是一元。</p><p>下图是关于机器学习的基本流程图，你可以认为几乎所有机器学习问题都是这个框架的东西。</p><p><img src="/../image/ml2.jpg" alt=""></p><p>而这其中的$h$，代表$hypothesis$，由流程图可以看出，它是由数据集与学习算法得来的，在数学模型中，它代表回归模型，在机器学习中，我们通常把它称作假设函数。</p><script type="math/tex; mode=display">\begin{align}how\quad &to \quad represent \quad h \quad ?\\h_{\theta}(x)&=\theta_0+\theta_1x\end{align}</script><p>以上便是我们在一元线性回归模型中的假设函数了，可以看出，实际上我们是对数据集拟合了一个一次函数，所以我们才说是线性回归，那么实际的问题中，当然不是所有问题都是线性的关系，这个我们之后再去说。好了，目前为止，我已经解释了所有关于一元线性回归模型的意义了，下面我们来看点重要的。</p><h4 id="2-代价函数-cost-function"><a href="#2-代价函数-cost-function" class="headerlink" title="2. 代价函数 cost function"></a>2. 代价函数 cost function</h4><p><img src="/../image/ml3.jpg" alt=""></p><p>下面我们来看个更具体的例子，我们已经给出了数据集，要求求出Size和Price的内在关系，可以很明显的知道这是个一元回归问题，至于线性，这个我们不是我们现在需要考虑的，我们就当它拟合为线性一次函数。首先先解释数据集中几个变量符号的意义：</p><ul><li><strong>m：数据集的数量</strong></li><li><strong>x：特征/输入变量</strong>      $x^{(i)}$代表第i个特征$(i=1,2,…,m)$</li><li><strong>y：目标/输出变量</strong>      $y^{(i)}$代表第i个目标$(i=1,2,…,m)$</li></ul><p>当然不同的人有不同的表示方法，我相信这不是比较关键的东西，whatever。我们还是需要得到我们的假设函数$h_{\theta}(x)=\theta_0+\theta_1x$，如何选择$\theta_i$，即参数，才是我们需要关注的问题。ps：之后的$h_{\theta}(x)$全部简写为$h(x)$</p><p>我们的目的当然是，一次线性函数与原数据集有高度的拟合，即我们假设函数$h(x)$得到的结果与原目标$y$差距越小越好，于是我们得到了我们所谓的回归目标：</p><script type="math/tex; mode=display">min_{\theta_i}:\frac{1}{2m}\sum_{i=1}^m \left(h(x^{(i)})-y^{(i)}\right)^2</script><p>这其实是个方差公式的形式，我们添上了系数1/2。然后很明显地，我们完全可以用这个函数来判断我们的拟合程度，这个值越小就说明我们的拟合效果越好。于是，我们就规定了一个函数：</p><script type="math/tex; mode=display">J(\theta_i)=\frac{1}{2m}\sum_{i=1}^m \left(h(x^{(i)})-y^{(i)}\right)^2</script><p>然而这个函数就是<strong>代价函数(cost function)</strong>，表面意思就是为了拟合某个数据集，我们所需要付出的代价。在所有机器学习的问题中，我们都在研究如何使得代价函数最小，也就是我们上面所说的回归目标。</p><p><img src="/../image/ml4.jpg" alt=""></p><p>解决问题时，我们通常会有两张常见的可视化图片，第一张是$h(x)$的图，也就是Size和Price的数据集的图，第二张图是关于代价函数的，也有画三维图的，当然也有这种画等高线的。在接下来的问题中，我们会研究通过何种算法，让机器帮助我们找到最优目标的参数值。</p><h4 id="3-梯度下降算法-Gradient-Descent-Algorithm"><a href="#3-梯度下降算法-Gradient-Descent-Algorithm" class="headerlink" title="3. 梯度下降算法  Gradient Descent Algorithm"></a>3. 梯度下降算法  Gradient Descent Algorithm</h4><p>再次明确我们的模型函数，我们现在有$J(\theta_i)$,目标是让这个函数得到最小值。朴素的思想就是我们可以定起始的$\theta_i$，然后不断地改变他们，直到他们最后到达了最小值。很明显，这样的想法我们还需要更可靠的算法，毕竟全部遍历是不可能的。</p><p>所以这也就引入了梯度下降算法来解决这个问题，先给大家看某个代价函数，以及算法实现的某个过程。</p><p><img src="/../image/ml5.jpg" alt=""></p><p>想法不变，我们从某个$(\theta_0,\theta_1)$开始，不断改变他们的值，直到收敛到局部最优。而这个改变的过程我们称为梯度下降，为了方便理解，我直接给出参数改变的公式，也就是$\theta_i$不断更新的依据，假设仅有两个参数的时候。</p><script type="math/tex; mode=display">\theta_j:=\theta_j-\alpha \frac{\partial}{\partial \theta_j}J(\theta_0,\theta_1) \quad (j=0,1)</script><p>这便是梯度下降最关键的地方，其中有了偏导数符号，这个如果看不懂的话，还是要先学微积分的。仔细想想的话，这样确实能通过下降的方式，使得代价函数收敛到局部最优解。其中$\alpha$代表学习率，你可以理解为每次更新的步长，这个也很关键，但是之后我们也会提到。</p><p>还有需要强调的是，我们的$\theta_i$是同步更新(Simultaneous update)的，这个如果你学过计算方法这门课中求解微分方程的两种方法或许你应该深有体会。</p><p>下面这个例子是同步更新</p><script type="math/tex; mode=display">\begin{align}\\Correct&:Simultaneous \quad update\\temp0&:=\theta_0-\alpha \frac{\partial}{\partial \theta_0}J(\theta_0,\theta_1)\\temp1&:=\theta_1-\alpha \frac{\partial}{\partial \theta_1}J(\theta_0,\theta_1)\\\theta_0&:=temp0\\\theta_1&:=temp1\end{align}</script><p>然后这是不同步更新的例子</p><script type="math/tex; mode=display">\begin{align}Inco&rrect:\\temp0&:=\theta_0-\alpha \frac{\partial}{\partial \theta_0}J(\theta_0,\theta_1)\\\theta_0&:=temp0\\temp1&:=\theta_1-\alpha \frac{\partial}{\partial \theta_1}J(\theta_0,\theta_1)\\\theta_1&:=temp1\end{align}</script><p>在不同步更新的例子中我们发现，$\theta_0$更新后带入了$\theta_1$的更新公式中，这不是我们想要的。</p><p>理解清楚了这个后，我们就明白了梯度下降法的公式了，你可能会说选择不同的开始的起始值会导致不同的收敛点，确实是这样，比如下面这个图。</p><p><img src="/../image/ml6.jpg" alt=""></p><p>很显然因为选择了不同的$\theta_i$会导致两种不同的路线，通过梯度下降算法我们只能找到局部收敛点，而不是全局最优点。不过这也没关系，我们处理问题的时候都尽量会选择弓形函数，也就是<strong>凸函数(convex function)</strong>.这种函数我们保证它仅有一个收敛点，即全局最优解。</p><h3 id="多元线性回归-Linear-Regression-with-Multiple-Variables"><a href="#多元线性回归-Linear-Regression-with-Multiple-Variables" class="headerlink" title="多元线性回归  Linear Regression with Multiple Variables"></a>多元线性回归  Linear Regression with Multiple Variables</h3><h4 id="1-模型描述-多特征"><a href="#1-模型描述-多特征" class="headerlink" title="1. 模型描述 多特征"></a>1. 模型描述 多特征</h4><p>我们根据上面那个房价的例子，很显然在实际的生活中，房价Price绝不可能只与其Size有关系的，你的北京六环和二环的房子能比得起来吗？哦，我知道你没有。这里还是根据那个房价的例子，不过我们提出了更多的影响因素。</p><p><img src="/../image/ml7.jpg" alt=""></p><p>我们还是首先来规定下符号：</p><ul><li><strong>m：数据集的数量</strong></li><li><strong>n：特征的个数</strong>  例如此例n=4</li><li><strong>$x^{(i)}$：序号为i的数据集的特征向量</strong></li><li><strong>$x_j^{(i)}$：序号为i的数据集的第j个特征</strong>  比如40年我们如何表示？ $x_4^{(2)}$=40</li></ul><p>假设函数那当然也是多变量的了，我默认大家都学完了矩阵的东西，所以我就直接用矩阵的表示形式来列了。</p><script type="math/tex; mode=display">\begin{align}h(x)&=\theta_0+\theta_1x_1+\theta_2x_2+...+\theta_nx_n\\define \quad x_0&=1\\x=\begin{bmatrix} x_0\\x_1\\x_2\\\vdots\\x_n \end{bmatrix} \quad& \theta=\begin{bmatrix} \theta_0\\\theta_1\\\theta_2\\\vdots\\\theta_n \end{bmatrix}\\h(x)&=\theta^Tx\end{align}</script><p>我们采用矩阵的表达方式，已经写出了假设函数的矩阵形式，很简单，那下面就来说说如何在这个假设函数中进行梯度下降。</p><h4 id="2-多变量梯度下降"><a href="#2-多变量梯度下降" class="headerlink" title="2. 多变量梯度下降"></a>2. 多变量梯度下降</h4><p>其实梯度下降的公式都是一样的，只不过原来一元的时候只需要更新两个$\theta$值，现在需要更新n个，仅此而已。</p><script type="math/tex; mode=display">\theta_j:=\theta_j-\alpha \frac{\partial}{\partial \theta_j}J(\theta) \quad (j=0,1,...,n)</script><p>但是我们需要注意的，可不是这些。</p><h5 id="1-特征缩放"><a href="#1-特征缩放" class="headerlink" title="(1) 特征缩放"></a>(1) 特征缩放</h5><p>线性回归的目的就是在于求出我们所需要的权重，即$\theta$值，而权重和每个特征量的大小相关。试想一下，如果一个房间的Size的范围是1000左右，而房子的楼层是3以内的数，那我们直接拟合出来的权重，肯定更偏向于Size啊，而这显然不符合实际情况。这就是多元回归区别于一元回归的事情，一元回归就一个变量，咱们不需要考虑其大小范围。但是多元我们必须考虑，我们最好能够将所有变量统一缩放到某个区间，比如$-1\leq x_i\leq 1$。当然这个区间不是必须的，这里只给个参考范围。而对于所有的变量，我们都需要先进行<strong>均值标准化(Mean Normalization)</strong> 的处理。</p><script type="math/tex; mode=display">\begin{align}Mean &\quad Normalization:\\x_j&:=\frac{x_j-\mu_j}{\sigma_j}\end{align}</script><p>我相信如果你学过概率论的话，这个式子应该经常出现，不管是在八大公式还是假设检验里面。还是需要解释一下，这其中$\mu_j$表示第j组特征向量的均值，而$\sigma_j$表示第j组数据的标准差。</p><h5 id="2-特征合并"><a href="#2-特征合并" class="headerlink" title="(2) 特征合并"></a>(2) 特征合并</h5><p>这个是很好理解，也算是多元线性回归里面的一点技巧。比如题目给出的因素中，Price与房子的frontage和depth有关，那我们就要想到$Size=Frontage\times Depth$。于是我们就能把这个两个特征当成一个来处理，其实实际问题中这样的例子还是挺常见的。</p><h5 id="3-学习率与假设函数选择"><a href="#3-学习率与假设函数选择" class="headerlink" title="(3) 学习率与假设函数选择"></a>(3) 学习率与假设函数选择</h5><p>关于学习率$\alpha$与假设函数次项的选择，我在这里就不明说了，因为我自己也不是很能给出一个具体的方案。以及这样的情况遇到的较少。</p><h3 id="正规方程求解参数-Normal-Equation"><a href="#正规方程求解参数-Normal-Equation" class="headerlink" title="正规方程求解参数  Normal Equation"></a>正规方程求解参数  Normal Equation</h3><p>事实上，我们除了梯度下降法，还有另一种方法求解我们所需要的参数以及权重$\theta$的方法，就是用普通的方程求解，剩下的交给MATLAB就好，以上面那个例子来说明。</p><p><img src="/../image/ml7.jpg" alt=""></p><p>我们希望求得一组$\theta$值，能够假设函数能够很好地拟合最终的Price，其实我们不难列出我们的假设函数：</p><script type="math/tex; mode=display">h(x)=\begin{bmatrix}1 & 2104 & 5 &1 &45\\1 & 1416 & 3 &2 &40\\\vdots & \vdots & \vdots & \vdots & \vdots\end{bmatrix}\times\begin{bmatrix}\theta_0 \\\theta_1 \\\vdots \\\theta_n\end{bmatrix}=X\theta</script><p>实际上我们添加了$x_0=1$这一项，如果能够理解的话，那说明你基本明白了线性回归的知识点。然后我们要用Normal的方法解得我们需要的$\theta$：</p><script type="math/tex; mode=display">\theta = (X^TX)^{-1}X^Ty \quad ,\quad y=\begin{bmatrix} 460\\232\\315\\178\\ \vdots\end{bmatrix}</script><p>很遗憾地告诉你，我并不能告诉你这个方程是怎么推出来的，其实你也不需要理解。在数学建模竞赛或是机器学习研究中，我们大部分情况下只需要会用即可。</p><p>ok，到这里关于线性回归模型的求解，你已经学会了两种方法，梯度下降算法与正规方程解法，你可能会觉得正规方程解法会比较方便，下面我就来说说正规方程解法的局限性。</p><ul><li>正规方程解法需要计算矩阵的逆，当特征数大于样本数时，矩阵为奇异矩阵，无逆矩阵，虽然MATLAB命令<code>pinv</code>也能得到近似解，但是这往往不符合我们的预测要求。</li><li>当样本数量也特别大的时候，矩阵计算会非常缓慢，通常几千以内的矩阵，MATLAB计算还是比梯度下降快的，数量再往上我们可能就要选择梯度下降法了。</li></ul><p>当然梯度下降法也要选择学习率与迭代次数，这就需要我们理解代价函数，并根据此来判断。Emmm，说到这里，线性回归的内容基本就结束了，我可能会遗憾的告诉你，大部分数学建模竞赛或是机器学习问题，光靠线性回归模型基本不可能解决问题，因为真正的实际问题是线性关系的真的很少，但是这并不影响线性回归依旧是你最需要掌握的算法，这是所有其他问题的基础。</p><p>Good Luck！</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;吴恩达老师的机器学习公开课应该算是目前我见过，最适合小白入门的公开课程了。即使内容对新人比较友好，但我想还是需要整理些许笔记的，因为涉及到机器学习的基础阶段，各个概念的掌握情况，我跳过了一些对我个人而言不重要的栏目，比如线性代数和matlab教程这些。之后也会补上上课的作业，Coursera申请助学金需要时间比较久。&lt;/p&gt;
&lt;h3 id=&quot;一元线性回归-单变量线性回归-Linear-Regression-with-one-variable&quot;&gt;&lt;a href=&quot;#一元线性回归-单变量线性回归-Linear-Regression-with-one-variable&quot; class=&quot;headerlink&quot; title=&quot;一元线性回归(单变量线性回归)  Linear Regression with one variable&quot;&gt;&lt;/a&gt;一元线性回归(单变量线性回归)  Linear Regression with one variable&lt;/h3&gt;
    
    </summary>
    
    
      <category term="机器学习" scheme="http://yoursite.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="吴恩达课程笔记" scheme="http://yoursite.com/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E5%90%B4%E6%81%A9%E8%BE%BE%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="机器学习" scheme="http://yoursite.com/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>【XDUACM暑培】二分法洛谷作业题解</title>
    <link href="http://yoursite.com/2020/06/25/%E3%80%90XDUACM%E6%9A%91%E5%9F%B9%E3%80%91%E4%BA%8C%E5%88%86%E6%B3%95%E6%B4%9B%E8%B0%B7%E4%BD%9C%E4%B8%9A%E9%A2%98%E8%A7%A3/"/>
    <id>http://yoursite.com/2020/06/25/%E3%80%90XDUACM%E6%9A%91%E5%9F%B9%E3%80%91%E4%BA%8C%E5%88%86%E6%B3%95%E6%B4%9B%E8%B0%B7%E4%BD%9C%E4%B8%9A%E9%A2%98%E8%A7%A3/</id>
    <published>2020-06-24T18:13:49.000Z</published>
    <updated>2020-06-24T11:32:27.506Z</updated>
    
    <content type="html"><![CDATA[<p>二分法模板与思路可见我之前的<a href="[https://www.alpha-yang.cn/2020/06/25/%E3%80%90%E4%BA%8C%E5%88%86%E3%80%91%E6%80%9D%E8%B7%AF%E4%B8%8E%E6%A8%A1%E6%9D%BF/](https://www.alpha-yang.cn/2020/06/25/[二分]思路与模板/">二分博客</a>)或<a href="https://zhuanlan.zhihu.com/p/150570206" target="_blank" rel="noopener">知乎专栏</a>，这次作业的题目比较容易，相对于【图论与树】，所以我就先写题解了。</p><h4 id="P1024-一元三次方程求解"><a href="#P1024-一元三次方程求解" class="headerlink" title="P1024 一元三次方程求解"></a>P1024 一元三次方程求解</h4><p>题目地址：<a href="https://www.luogu.com.cn/problem/P1024" target="_blank" rel="noopener">P1024 一元三次方程求解</a></p><a id="more"></a><p>二分法，题目告诉你保证有三个根，且差的绝对值都大于1，那就是说明-100~100的区间，以1为间隔，每个小区间最多有一个根，那就好说了。先把这三个小区间给一个个揪出来，满足<code>f(i)*f(i+1)&lt;0</code>一定有一个实根在这个小区间里面，因为是精确到小数点后两位。为了继续能用整数二分法的模板，我们把所有数放大100倍，比如[15,16]的区间有根，那我们以1为步长遍历[1500,1600]出来除以100就行了(特别当心浮点数陷阱)。</p><p>再讲讲二分的部分，还是略微改动了下模板的。对于判断条件，我们分别左临界为<code>y</code>，右临界为<code>z</code>，中间点为<code>x</code>，如果<code>f(x)*f(y)&lt;=0</code>，那就说明我们需要让x作为新的右临界。</p><p>以此二分下去，直到剩下最小的区间，如[1559,1560]，只存在两个值了，分别是15.59和15.60。对于这两个数我们再选取计算离0近的返回作为我们的答案即可。</p><p>最后附上ac代码，对细节有注释。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;bits/stdc++.h&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">double</span> a,b,c,d;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">double</span> <span class="title">f</span><span class="params">(<span class="keyword">double</span> x)</span> <span class="comment">// 函数</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">return</span> a*x*x*x+b*x*x+c*x+d;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">check</span><span class="params">(<span class="keyword">int</span> x,<span class="keyword">int</span> y,<span class="keyword">int</span> z)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">double</span> p=x*<span class="number">1.00</span>/<span class="number">100</span>,q=y*<span class="number">1.00</span>/<span class="number">100</span>,r=z*<span class="number">1.00</span>/<span class="number">100</span>;</span><br><span class="line">    <span class="keyword">if</span> (f(p)*f(q)&lt;=<span class="number">0</span>) <span class="keyword">return</span> <span class="literal">false</span>; <span class="keyword">else</span> <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">binary_search</span><span class="params">(<span class="keyword">int</span> left,<span class="keyword">int</span> right)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> mid;</span><br><span class="line">    <span class="keyword">while</span> (left+<span class="number">1</span>&lt;right)</span><br><span class="line">    &#123;</span><br><span class="line">        mid=(left+right)&gt;&gt;<span class="number">1</span>;</span><br><span class="line">        (check(mid,left,right) ? left : right) =mid;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (<span class="built_in">abs</span>(f(left*<span class="number">1.00</span>/<span class="number">100</span>))&lt;=<span class="built_in">abs</span>(f(right*<span class="number">1.00</span>/<span class="number">100</span>))) <span class="keyword">return</span> left;</span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">return</span> right;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="built_in">cin</span>&gt;&gt;a&gt;&gt;b&gt;&gt;c&gt;&gt;d;</span><br><span class="line">    <span class="keyword">int</span> i,ans=<span class="number">0</span>;</span><br><span class="line">    <span class="keyword">double</span> x;</span><br><span class="line">    <span class="keyword">for</span> (i=<span class="number">-100</span>;i&lt;<span class="number">100</span>;i++)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">if</span> (f(i*<span class="number">1.00</span>)*f((i+<span class="number">1</span>)*<span class="number">1.00</span>)&lt;<span class="number">0</span>)</span><br><span class="line">        &#123;</span><br><span class="line">            ans++;</span><br><span class="line">            x=binary_search(i*<span class="number">100</span>,(i+<span class="number">1</span>)*<span class="number">100</span>)*<span class="number">1.00</span>/<span class="number">100</span>;</span><br><span class="line">            <span class="built_in">printf</span>(<span class="string">"%.2lf "</span>,x);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span> (f(i*<span class="number">1.00</span>)==<span class="number">0</span>) <span class="comment">// 如果区间上i正好等于0，单独判断，防止重判</span></span><br><span class="line">        &#123;</span><br><span class="line">            ans++;</span><br><span class="line">            <span class="built_in">printf</span>(<span class="string">"%.2lf "</span>,i*<span class="number">1.00</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (ans==<span class="number">3</span>) <span class="keyword">break</span>; <span class="comment">// 题目保证有且仅有三个解，所以三个解的时候退出，可以节省一点时间</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="P2678-跳石头"><a href="#P2678-跳石头" class="headerlink" title="P2678 跳石头"></a>P2678 跳石头</h4><p>题目地址：<a href="https://www.luogu.com.cn/problem/P2678" target="_blank" rel="noopener">P2678 跳石头</a></p><p>很经典的OI题目，也是道很经典的二分题，看到最值这些问题，先考虑二分的flag。用二分法做题首先我们得明确二分的对象，很显然不可能是石头序号，所以应该是二分距离。简单点，题目问你啥你二分啥，下面来说说具体的思路。</p><p>不能被移走的石头束缚住，这是个前提。移走的石头数不是重点，<strong>需不需要移走才是重点</strong>。好吧，这么讲还是有点不形象，这题要我们求最短跳跃距离的最大值。思考一下，我们的二分是往上分的，如果<code>mid</code>满足条件，那就让<code>left=mid</code>，继续向上二分查找，看看有没有更大的可能结果。</p><p>下面就是判断条件，即什么样的<code>mid</code>满足条件，也是本题的核心思路所在。之前说了不能被移走的石头数量给束缚住，让我们反过来思考，为了达到这个最短跳跃距离，需要移走多少块石头。我们将距离设为<code>d[i]</code>，即第i个石头到起点的距离，以下为核心代码，<code>check</code>函数部分。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">check</span><span class="params">(<span class="keyword">int</span> x)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> s=<span class="number">0</span>,i=<span class="number">0</span>,flag=<span class="number">0</span>; <span class="comment">// s代表当前移走的石头数，i代表当前走到的石头序号，flag代表离i最近没被移走的石头序号</span></span><br><span class="line">    <span class="keyword">while</span> (i&lt;n+<span class="number">1</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        i++;</span><br><span class="line">        <span class="keyword">if</span> (d[i]-d[flag]&lt;x) s++;</span><br><span class="line">        <span class="keyword">else</span> flag=i;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> s&lt;=m;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>设置三个变量s，i，flag。如果我们发现<code>d[i]-d[flag]&lt;x</code>，那就说明这两块石头中间的石头必须挪走(中间肯定有石头，因为二分的初始值就是距离的一半)，反之则flag也前移。如果需要移走的石头数大于我们题目组委会移走的石头数，对不起，不符合条件。这时我们再向下二分查找，以此类推。</p><p>最后附上ac代码。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;bits/stdc++.h&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"><span class="keyword">const</span> <span class="keyword">int</span> maxn=<span class="number">5e4</span>+<span class="number">5</span>;</span><br><span class="line"><span class="keyword">int</span> d[maxn];</span><br><span class="line"><span class="keyword">int</span> l,m,n;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">check</span><span class="params">(<span class="keyword">int</span> x)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> s=<span class="number">0</span>,i=<span class="number">0</span>,flag=<span class="number">0</span>;</span><br><span class="line">    <span class="keyword">while</span> (i&lt;n+<span class="number">1</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        i++;</span><br><span class="line">        <span class="keyword">if</span> (d[i]-d[flag]&lt;x) s++;</span><br><span class="line">        <span class="keyword">else</span> flag=i;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> s&lt;=m;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">binary_search</span><span class="params">(<span class="keyword">int</span> left,<span class="keyword">int</span> right)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> mid;</span><br><span class="line">    <span class="keyword">while</span> (left+<span class="number">1</span>&lt;right)</span><br><span class="line">    &#123;</span><br><span class="line">        mid=(left+right)&gt;&gt;<span class="number">1</span>;</span><br><span class="line">        (check(mid) ? left : right) =mid;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> check(right) ? right : left;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="built_in">cin</span>&gt;&gt;l&gt;&gt;n&gt;&gt;m;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">1</span>;i&lt;=n;i++) <span class="built_in">cin</span>&gt;&gt;d[i];</span><br><span class="line">    d[n+<span class="number">1</span>]=l;</span><br><span class="line">    <span class="built_in">cout</span>&lt;&lt;binary_search(<span class="number">1</span>,l)&lt;&lt;<span class="built_in">endl</span>;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="P3853-TJOI2007-路标设置"><a href="#P3853-TJOI2007-路标设置" class="headerlink" title="P3853 [TJOI2007]路标设置"></a>P3853 [TJOI2007]路标设置</h4><p>题目地址：<a href="https://www.luogu.com.cn/problem/P3853" target="_blank" rel="noopener">P3853 [TJOI2007]路标设置</a></p><p>这个题目啊，几乎和P2678跳石头一模一样，甚至还要更简单一点。“空旷指数”就是距离，那此题我们就对距离进行二分。跳石头是移走石头，本题是加路标，思路几乎一模一样。</p><p>要我们求最小空旷指数，这就不一样了，这是向下二分，如果<code>mid</code>满足条件，那我们就得让<code>mid=right</code>，进行更小的可能值的查找了。</p><p>上面那点明确后，我们再来确定判断条件，也就是核心思想的部分。一样的本题加路牌，为了验证<code>mid</code>是否符合条件，我们算出两两路牌之间的距离，<code>a[i]</code>表示第i个路牌的距离，如果<code>a[i+1]-a[i]&gt;mid</code>，那就i和i+1中间得加路牌，那加几个呢？用距离除以mid即可，但一定小心一个整除的问题，例如<code>mid=5,a[i+1]-a[i]=10</code>时，虽然除的结果是2，但实际上距离为10的中间只需要差一块路牌即可。这是我们就需要对于整除的情况减一了，整数情况可以这样判断<code>(a[i+1]-a[i])/x*x==a[i+1]-a[i] ? 1 : 0</code>。附上核心代码。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">check</span><span class="params">(<span class="keyword">int</span> x)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> ans=<span class="number">0</span>,i=<span class="number">0</span>;</span><br><span class="line">    <span class="keyword">while</span> (i&lt;n+<span class="number">1</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        i++;</span><br><span class="line">        <span class="keyword">if</span> (a[i+<span class="number">1</span>]-a[i]&gt;x) </span><br><span class="line">            ans+=(a[i+<span class="number">1</span>]-a[i])/x-((a[i+<span class="number">1</span>]-a[i])/x*x==a[i+<span class="number">1</span>]-a[i] ? <span class="number">1</span> : <span class="number">0</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> ans&lt;=k; <span class="comment">// 如果需要加的路牌小于等于规定加的路牌，则判断为真</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>需要注意的是<code>check</code>函数表示的永远是符合条件的判断，也就是说符合就是true，反之则是false。至于最大值最小值，那就是二分法里关于左右区间的判断了。</p><p>最后是完整ac代码。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;bits/stdc++.h&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"><span class="keyword">const</span> <span class="keyword">int</span> maxn=<span class="number">1e5</span>+<span class="number">5</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span> l,n,k;</span><br><span class="line"><span class="keyword">int</span> a[maxn];</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">check</span><span class="params">(<span class="keyword">int</span> x)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> ans=<span class="number">0</span>,i=<span class="number">0</span>;</span><br><span class="line">    <span class="keyword">while</span> (i&lt;n+<span class="number">1</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        i++;</span><br><span class="line">        <span class="keyword">if</span> (a[i+<span class="number">1</span>]-a[i]&gt;x) </span><br><span class="line">            ans+=(a[i+<span class="number">1</span>]-a[i])/x-((a[i+<span class="number">1</span>]-a[i])/x*x==a[i+<span class="number">1</span>]-a[i] ? <span class="number">1</span> : <span class="number">0</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> ans&lt;=k;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">binary_search</span><span class="params">(<span class="keyword">int</span> left,<span class="keyword">int</span> right)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> mid;</span><br><span class="line">    <span class="keyword">while</span> (left+<span class="number">1</span>&lt;right)</span><br><span class="line">    &#123;</span><br><span class="line">        mid=(left+right)&gt;&gt;<span class="number">1</span>;</span><br><span class="line">        (check(mid) ? right : left)=mid;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> check(left) ? left : right;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="built_in">cin</span>&gt;&gt;l&gt;&gt;n&gt;&gt;k;</span><br><span class="line">    <span class="keyword">int</span> i;</span><br><span class="line">    <span class="keyword">for</span> (i=<span class="number">1</span>;i&lt;=n;i++) <span class="built_in">cin</span>&gt;&gt;a[i];</span><br><span class="line">    a[n+<span class="number">1</span>]=l;</span><br><span class="line">    <span class="built_in">cout</span>&lt;&lt;binary_search(<span class="number">0</span>,l)&lt;&lt;<span class="built_in">endl</span>;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;二分法模板与思路可见我之前的&lt;a href=&quot;[https://www.alpha-yang.cn/2020/06/25/%E3%80%90%E4%BA%8C%E5%88%86%E3%80%91%E6%80%9D%E8%B7%AF%E4%B8%8E%E6%A8%A1%E6%9D%BF/](https://www.alpha-yang.cn/2020/06/25/[二分]思路与模板/&quot;&gt;二分博客&lt;/a&gt;)或&lt;a href=&quot;https://zhuanlan.zhihu.com/p/150570206&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;知乎专栏&lt;/a&gt;，这次作业的题目比较容易，相对于【图论与树】，所以我就先写题解了。&lt;/p&gt;
&lt;h4 id=&quot;P1024-一元三次方程求解&quot;&gt;&lt;a href=&quot;#P1024-一元三次方程求解&quot; class=&quot;headerlink&quot; title=&quot;P1024 一元三次方程求解&quot;&gt;&lt;/a&gt;P1024 一元三次方程求解&lt;/h4&gt;&lt;p&gt;题目地址：&lt;a href=&quot;https://www.luogu.com.cn/problem/P1024&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;P1024 一元三次方程求解&lt;/a&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="ACM算法" scheme="http://yoursite.com/categories/ACM%E7%AE%97%E6%B3%95/"/>
    
      <category term="洛谷试炼场" scheme="http://yoursite.com/categories/ACM%E7%AE%97%E6%B3%95/%E6%B4%9B%E8%B0%B7%E8%AF%95%E7%82%BC%E5%9C%BA/"/>
    
    
      <category term="二分" scheme="http://yoursite.com/tags/%E4%BA%8C%E5%88%86/"/>
    
  </entry>
  
  <entry>
    <title>【二分】思路与模板</title>
    <link href="http://yoursite.com/2020/06/25/%E3%80%90%E4%BA%8C%E5%88%86%E3%80%91%E6%80%9D%E8%B7%AF%E4%B8%8E%E6%A8%A1%E6%9D%BF/"/>
    <id>http://yoursite.com/2020/06/25/%E3%80%90%E4%BA%8C%E5%88%86%E3%80%91%E6%80%9D%E8%B7%AF%E4%B8%8E%E6%A8%A1%E6%9D%BF/</id>
    <published>2020-06-24T16:10:30.000Z</published>
    <updated>2020-06-24T11:33:57.164Z</updated>
    
    <content type="html"><![CDATA[<p>西电ACM暑假培训二分法课程，感谢柴东辰大佬的讲课！</p><p>二分算法，就是为了在<strong>单调</strong>的序列中寻找某个值，而每次选取中间位置，合理减少问题的规模，从而快速得到答案。</p><p>二分法，我想大家肯定都知道，这里我也不再赘述了，不过二分法的模板网上到处都是，但是有问题的也很多，比如这题是mid+1，那题是mid-1，也就是边界条件难以处理，很讨厌对吧？所以我这里介绍一种通用模板并分析思路。</p><a id="more"></a><p>哦对了，想给个标准的情景，1~n，查找x。就这么简单，暴力的话复杂度会达到O(n)，如果用二分法就是O(logn)了。废话不多说，直接上万用板(感谢柴大佬的模板)。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">check</span><span class="params">(<span class="keyword">int</span> k)</span> <span class="comment">// 判断真假情况的，根据题目意思自己写不同的check函数</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">return</span> k&lt;=x;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">binary_search</span><span class="params">(<span class="keyword">int</span> left,<span class="keyword">int</span> right)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> mid;</span><br><span class="line">    <span class="keyword">while</span> (left+<span class="number">1</span>&lt;right)</span><br><span class="line">    &#123;</span><br><span class="line">        mid=(left+right)&gt;&gt;<span class="number">1</span>; <span class="comment">// 位运算加快速度</span></span><br><span class="line">        (check(mid) ? left : right) =mid;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> check(right) ? right : left;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这是个二分法模板，查找1~n的区间，可以查找的是任何东西。如果满足<code>left+1&lt;right</code>的条件，那就继续二分，反言之，如果<code>left+1&gt;=right</code>就不继续二分了。</p><p>二分求出左右区间的mid值，判断mid的条件，会根据题目改变而改变。此题的条件是，如果价格偏高返回false，此时让<code>right=mid</code>，如果价格偏低或者相等，返回true，此时让<code>left=mid</code>。知道区间仅剩下<code>left,right</code>两个数时，即条件<code>left+1&gt;=right</code>，此时我们需要查找的数一定在<code>left</code>和<code>right</code>之间了，这样很好理解了吧。</p><p>以上模板是稳定不易出错的写法，下面我们来尝试二分法的题目。</p><p>请移步我洛谷<a href="[https://www.alpha-yang.cn/2020/06/25/%E3%80%90XDUACM%E6%9A%91%E5%9F%B9%E3%80%91%E4%BA%8C%E5%88%86%E6%B3%95%E6%B4%9B%E8%B0%B7%E4%BD%9C%E4%B8%9A%E9%A2%98%E8%A7%A3/](https://www.alpha-yang.cn/2020/06/25/[XDUACM暑培]二分法洛谷作业题解/">二分博客</a>)或<a href="https://zhuanlan.zhihu.com/p/150570433" target="_blank" rel="noopener">知乎专栏</a>的题解。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;西电ACM暑假培训二分法课程，感谢柴东辰大佬的讲课！&lt;/p&gt;
&lt;p&gt;二分算法，就是为了在&lt;strong&gt;单调&lt;/strong&gt;的序列中寻找某个值，而每次选取中间位置，合理减少问题的规模，从而快速得到答案。&lt;/p&gt;
&lt;p&gt;二分法，我想大家肯定都知道，这里我也不再赘述了，不过二分法的模板网上到处都是，但是有问题的也很多，比如这题是mid+1，那题是mid-1，也就是边界条件难以处理，很讨厌对吧？所以我这里介绍一种通用模板并分析思路。&lt;/p&gt;
    
    </summary>
    
    
      <category term="ACM算法" scheme="http://yoursite.com/categories/ACM%E7%AE%97%E6%B3%95/"/>
    
      <category term="西电培训笔记" scheme="http://yoursite.com/categories/ACM%E7%AE%97%E6%B3%95/%E8%A5%BF%E7%94%B5%E5%9F%B9%E8%AE%AD%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="二分" scheme="http://yoursite.com/tags/%E4%BA%8C%E5%88%86/"/>
    
  </entry>
  
  <entry>
    <title>【图论与树】最短路径Dijkstra与Floyd算法</title>
    <link href="http://yoursite.com/2020/06/23/%E3%80%90%E5%9B%BE%E8%AE%BA%E4%B8%8E%E6%A0%91%E3%80%91%E6%9C%80%E7%9F%AD%E8%B7%AF%E5%BE%84Dijkstra%E4%B8%8EFloyd%E7%AE%97%E6%B3%95/"/>
    <id>http://yoursite.com/2020/06/23/%E3%80%90%E5%9B%BE%E8%AE%BA%E4%B8%8E%E6%A0%91%E3%80%91%E6%9C%80%E7%9F%AD%E8%B7%AF%E5%BE%84Dijkstra%E4%B8%8EFloyd%E7%AE%97%E6%B3%95/</id>
    <published>2020-06-23T10:05:20.000Z</published>
    <updated>2020-06-24T11:08:43.850Z</updated>
    
    <content type="html"><![CDATA[<p>在图论中有一个非常常见的问题，就是最短路径的问题。常见的最短路径算法有三种：dijkstra，floyd和SPFA。本文将带你了解前两种最短路算法，他们分别适用于不同场景下的问题。</p><p>以下笔记乃是参考西电ACM暑假培训张帆大佬的讲课以及<a href="https://www.cnblogs.com/xzxl/p/7266404.html" target="_blank" rel="noopener">优先队列博客</a></p><a id="more"></a><h3 id="Dijkstra"><a href="#Dijkstra" class="headerlink" title="Dijkstra"></a>Dijkstra</h3><p>首先我们必须了解这个算法的两个局限之处，才能做题</p><ul><li>不能适用于负权图</li><li>只适用于单源最短路问题</li></ul><p>如果权重是负数，那就直接pass这个算法，在这里原因不表。</p><p><strong>单源最短路径</strong>就是指只有一个出发点，到其他点的最短路径问题，以下问题也在这个前提下展开。</p><p>下面我们就来说说算法流程：</p><ul><li>S1. 设置dis数组，<code>dis[i]</code>表示起点start到i的距离。</li><li>S2. 从点集V中弹出一个dis值最小且未以该点为起点进行松弛操作的点。</li><li>S3. 从该点松弛与其领接的各个点更新dis数组，返回S2，循环进行。</li><li>通过优先队列的操作可以优化S2，之后详细说明。</li></ul><p><img src="https://i.loli.net/2020/06/23/T7m3JYt2evIwKLP.png" alt=""></p><p>如果这样说，有点抽象。那就举个例子。这个例子也是洛谷的单源最短路径的模板题，请求出1到各点的最短路？</p><p>很显然你用肉眼看，1到本身是0,1到2、3、4的最短路分别为2,4,3。那dijkstra的操作流程是什么呢？</p><p>首先我们先开一个dis数组，让数组的值足够大，<code>dis[i]=0x7fffffff</code>,从1开始出发，令<code>dis[1]=0</code>，发现与1相连的有三个点234，那我们一个个进行松弛操作，比较<code>if (dis[1]+w[i]&lt;dis[i])</code>,w表示各边的权重，如果小于，那就让其覆盖本身的dis值，即<code>dis[i]=dis[1]+w[i]</code>，这一波更新完后，234的值分别为2,5,4。</p><p>然后，我们需要让234全部入队，并选取dis值最小的数即2继续进行松弛操作，发现连接的是3和4，继续更新，这波结束，234的值分别为2,4,3。</p><p>接着，是上一轮dis值次小的点4，进行操作，但是4没有出的边，所以不进行操作。</p><p>最后就是剩下的一个3了，3和4还有一条权边，但是4最小的dis值依旧是3。</p><p>下面我们发现算法到这就截止了，为什么呢，因为S2的一句话，未进行松弛的点，早在第一轮234就已经全部进入过队列并且已经弹出过了，所以之后他们也不会再进入队列，我们可以设置一个bool类型的<code>vis[i]</code>数组代表第i个点是否被访问过了，如果访问过了就结束此循环，或者直接不push进入队列。</p><p>这就是整个dijkstra的算法，其实很好理解，证明我们就先略过了。</p><h4 id="优先队列priority-queue"><a href="#优先队列priority-queue" class="headerlink" title="优先队列priority_queue"></a>优先队列priority_queue</h4><p>上面那个算法有个问题，就是怎样才能保证每次弹出的都是dis最小的数呢？如果用普通队列，不能解决这个问题，如果每次都遍历一遍来找，那复杂度直接O(VE)，百分百会被T掉。</p><p>所以我们这里采用优先队列priority_queue对S2进行堆优化，就变成O((V+E)logV)了，所以做题的时候堆优化+dijkstra都是一起出现的，模板也是一起写的。</p><p><strong>优先队列</strong>：按照一定次序的队列结构，升序或降序，从小到大排列，push和pop都遵循其规律。</p><p>优先队列的详细用法请参照这篇<a href="https://www.cnblogs.com/xzxl/p/7266404.html" target="_blank" rel="noopener">博客</a>，本文仅描述dijkstra模板下的用法。</p><p>首先对于图论中的<strong>每条点</strong>，我们都需建立一个<code>node</code>结构体，包含两个内容<code>num</code>和<code>dis</code>。分别表示该点的序号以及dis值。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">node</span>&#123;</span></span><br><span class="line">    <span class="keyword">int</span> num,dis;</span><br><span class="line">&#125;;</span><br><span class="line">priority_queue &lt;node&gt; q;</span><br></pre></td></tr></table></figure><p>然而这样建立优先队列是会报错的，因为优先队列无法对结构体进行优先级比较。所以我们就想办法告诉程序，我们的队列是对结构体的哪儿个值进行排序，其实做法有很多，我习惯的方式是采取重载的形式。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">node</span>&#123;</span></span><br><span class="line">    <span class="keyword">int</span> num,dis;</span><br><span class="line">    <span class="keyword">bool</span> <span class="keyword">operator</span> &lt; (<span class="keyword">const</span> node &amp;x)<span class="keyword">const</span>&#123;</span><br><span class="line">        <span class="keyword">return</span> x.dis &lt; dis; <span class="comment">// dis小的结构体在队列中的优先级高</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line">priority_queue &lt;node&gt; q;</span><br></pre></td></tr></table></figure><p>请重载&lt;号，别重载&gt;会报错的。这里如果不理解的就死记硬背把，讲重载的话又要涉及很多知识。</p><h4 id="【模板】Dijkstra算法实现"><a href="#【模板】Dijkstra算法实现" class="headerlink" title="【模板】Dijkstra算法实现"></a>【模板】Dijkstra算法实现</h4><p>以洛谷模板题为例，<a href="https://www.luogu.com.cn/problem/P4779" target="_blank" rel="noopener">P4779 【模板】单源最短路径（标准版）</a></p><p>这道题目的样例就是我上面所举的例子。上面我们解决了算法思路，以及用优先队列的方式对步骤2弹出dis最小的点进行了堆优化，下面我们还需要解决程序细节的问题。</p><p>先是存边的问题，这道题不存在重边等为难我们的限制，所以直接构造结构体<code>edge</code>。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">edge</span>&#123;</span></span><br><span class="line">    <span class="keyword">int</span> to,cost; <span class="comment">// to代表下一个点，cost代表该边的权重</span></span><br><span class="line">&#125;;</span><br><span class="line"><span class="built_in">vector</span> &lt;edge&gt; e[maxn];</span><br></pre></td></tr></table></figure><p>之后就是存边，然后进行Dijkstra算法，我直接上代码了，我的代码还是新手向的，不会设计复杂的操作。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;bits/stdc++.h&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"><span class="keyword">const</span> <span class="keyword">int</span> maxn=<span class="number">1e5</span>+<span class="number">5</span>;</span><br><span class="line"><span class="keyword">const</span> <span class="keyword">int</span> maxm=<span class="number">2e5</span>+<span class="number">5</span>;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">edge</span>&#123;</span></span><br><span class="line">    <span class="keyword">int</span> to,cost;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">node</span>&#123;</span></span><br><span class="line">    <span class="keyword">int</span> num,dis;</span><br><span class="line">    <span class="keyword">bool</span> <span class="keyword">operator</span> &lt; (<span class="keyword">const</span> node &amp;x)<span class="keyword">const</span>&#123;</span><br><span class="line">        <span class="keyword">return</span> x.dis &lt; dis;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="built_in">vector</span>&lt;edge&gt; e[maxm];</span><br><span class="line"><span class="keyword">int</span> dis[maxn];</span><br><span class="line"><span class="keyword">bool</span> vis[maxn]; <span class="comment">// 布尔型vis数组</span></span><br><span class="line"><span class="keyword">int</span> n,m,s,cnt=<span class="number">0</span>;</span><br><span class="line">priority_queue &lt;node&gt; q;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">add_edge</span><span class="params">(<span class="keyword">int</span> u,<span class="keyword">int</span> v,<span class="keyword">int</span> w)</span> <span class="comment">// 存边</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    e[u].push_back((edge)&#123;v,w&#125;);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">dijkstra</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    dis[s]=<span class="number">0</span>;</span><br><span class="line">    q.push((node)&#123;s,<span class="number">0</span>&#125;);</span><br><span class="line">    <span class="keyword">while</span> (!q.empty())</span><br><span class="line">    &#123;</span><br><span class="line">        node tmp=q.top();</span><br><span class="line">        q.pop();</span><br><span class="line">        <span class="keyword">int</span> x=tmp.num;</span><br><span class="line">        <span class="keyword">if</span> (vis[x]) <span class="keyword">continue</span>;</span><br><span class="line">        vis[x]=<span class="number">1</span>;</span><br><span class="line">        <span class="keyword">for</span> (edge k:e[x]) <span class="comment">// 遍历边信息，请注意洛谷请选用c++11，否则编译错误</span></span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">if</span> (dis[x] + k.cost &lt; dis[k.to])</span><br><span class="line">            &#123;</span><br><span class="line">                dis[k.to]=dis[x]+k.cost;</span><br><span class="line">                <span class="keyword">if</span> (!vis[k.to]) q.push((node)&#123;k.to,dis[k.to]&#125;);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="built_in">cin</span>&gt;&gt;n&gt;&gt;m&gt;&gt;s;</span><br><span class="line">    <span class="keyword">int</span> i;</span><br><span class="line">    <span class="keyword">for</span> (i=<span class="number">1</span>;i&lt;=n;i++) dis[i]=<span class="number">0x7fffffff</span>;</span><br><span class="line">    <span class="keyword">for</span> (i=<span class="number">0</span>;i&lt;m;i++)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">int</span> u,v,w;</span><br><span class="line">        <span class="built_in">cin</span>&gt;&gt;u&gt;&gt;v&gt;&gt;w;</span><br><span class="line">        add_edge(u,v,w);</span><br><span class="line">    &#125;</span><br><span class="line">    dijkstra();</span><br><span class="line">    <span class="keyword">for</span> (i=<span class="number">1</span>;i&lt;=n;i++) <span class="built_in">cout</span>&lt;&lt;dis[i]&lt;&lt;<span class="string">" "</span>;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="P1608-路径统计"><a href="#P1608-路径统计" class="headerlink" title="P1608 路径统计"></a>P1608 路径统计</h4><p>题目地址：<a href="https://www.luogu.com.cn/problem/P1608" target="_blank" rel="noopener">P1608 路径统计</a></p><p>这题基本也是个Dijkstra的模板题，大方向都没有任何变化。我们首先先考虑一个比较简单的问题，就是题目中的重边该怎么去除，重边我们当然选择最短的那条边，其实也不复杂。我采取的方法是邻接矩阵的办法，再把邻接矩阵转为边信息，考虑到N最大值为2000，二维矩阵肯定不会炸。（忽略奇怪的缩进</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (i=<span class="number">1</span>;i&lt;=m;i++)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">int</span> p,q,c,tmp;</span><br><span class="line">        <span class="built_in">cin</span>&gt;&gt;p&gt;&gt;q&gt;&gt;c;</span><br><span class="line">        <span class="keyword">if</span> (cmp[i][j]==<span class="number">0</span> || c&lt;cmp[i][j]) cmp[i][j]=c;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">for</span> (i=<span class="number">1</span>;i&lt;=n;i++)</span><br><span class="line">        <span class="keyword">for</span> (j=<span class="number">1</span>;j&lt;=n;j++)</span><br><span class="line">            <span class="keyword">if</span> (cmp[i][j]) e[i].push_back((edge)&#123;j,cmp[i][j]&#125;);</span><br></pre></td></tr></table></figure><p>这样就把重边给处理了，菜鸡的我也没想到其他方法了。。。</p><p>然后就是来处理本题的问题，最短路径非常简单，但是统计个数，还是需要思索一下的。我的办法是准备一个<code>ans</code>数组，<code>ans[i]</code>表示第i个点的最短路径的条数，好家伙！这样层层递推，就能推到第N个点了。</p><p>这样其实没啥问题，但是有可能统计第k个点，我统计了两条最短路径，突然来了一条更短的，这是我们的<code>ans[k]</code>从2又变回了1，好说！让k点的值等于最短路径上一个点的ans值就可以了。</p><p>所以核心代码如下。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (dis[k.to]==dis[x]+k.w) ans[k.to]+=ans[x];</span><br><span class="line"><span class="keyword">if</span> (dis[k.to]&gt;dis[x]+k.w)</span><br><span class="line">&#123;</span><br><span class="line">    dis[k.to]=dis[x]+k.w;</span><br><span class="line">    ans[k.to]=ans[x];</span><br><span class="line">    q.push((node)&#123;dis[k.to],k.to&#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>就是这样如果有相等的路径就相加，有小于的路径就让其ans值回去。如果最后的<code>dis[n]=0x7fffffff</code>，那说明根本没路径能到达它，无解。</p><p>最后附上ac代码。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;bits/stdc++.h&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"><span class="keyword">const</span> <span class="keyword">int</span> maxn=<span class="number">2005</span>;</span><br><span class="line"><span class="keyword">const</span> <span class="keyword">int</span> maxm=maxn*(maxn<span class="number">-1</span>)/<span class="number">2</span>;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">edge</span>&#123;</span></span><br><span class="line">    <span class="keyword">int</span> to,w;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">node</span>&#123;</span></span><br><span class="line">    <span class="keyword">int</span> dis,num;</span><br><span class="line">    <span class="keyword">bool</span> <span class="keyword">operator</span> &lt; (<span class="keyword">const</span> node &amp;x)<span class="keyword">const</span>&#123;</span><br><span class="line">        <span class="keyword">return</span> x.dis&lt;dis;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="built_in">vector</span> &lt;edge&gt; e[maxm];</span><br><span class="line"><span class="keyword">int</span> n,m;</span><br><span class="line"><span class="keyword">int</span> dis[maxn];</span><br><span class="line"><span class="keyword">int</span> ans[maxn];</span><br><span class="line"><span class="keyword">int</span> cmp[maxn][maxn];</span><br><span class="line"><span class="keyword">bool</span> vis[maxn];</span><br><span class="line"></span><br><span class="line">priority_queue &lt;node&gt; q;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">dijkstra</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    dis[<span class="number">1</span>]=<span class="number">0</span>;</span><br><span class="line">    ans[<span class="number">1</span>]=<span class="number">1</span>;</span><br><span class="line">    q.push((node)&#123;<span class="number">0</span>,<span class="number">1</span>&#125;);</span><br><span class="line">    <span class="keyword">while</span> (!q.empty())</span><br><span class="line">    &#123;</span><br><span class="line">        node tmp=q.top();</span><br><span class="line">        q.pop();</span><br><span class="line">        <span class="keyword">int</span> x=tmp.num;</span><br><span class="line">        <span class="keyword">if</span> (vis[x]) <span class="keyword">continue</span>;</span><br><span class="line">        vis[x]=<span class="number">1</span>;</span><br><span class="line">        <span class="keyword">for</span> (edge k : e[x])</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="keyword">if</span> (dis[k.to]==dis[x]+k.w) ans[k.to]+=ans[x];</span><br><span class="line">            <span class="keyword">if</span> (dis[k.to]&gt;dis[x]+k.w)</span><br><span class="line">            &#123;</span><br><span class="line">                dis[k.to]=dis[x]+k.w;</span><br><span class="line">                ans[k.to]=ans[x];</span><br><span class="line">                q.push((node)&#123;dis[k.to],k.to&#125;);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="built_in">cin</span>&gt;&gt;n&gt;&gt;m;</span><br><span class="line">    <span class="keyword">int</span> i,j;</span><br><span class="line">    <span class="keyword">for</span> (i=<span class="number">1</span>;i&lt;=n;i++) dis[i]=<span class="number">0x7fffffff</span>;</span><br><span class="line">    <span class="keyword">for</span> (i=<span class="number">1</span>;i&lt;=m;i++)</span><br><span class="line">    &#123;</span><br><span class="line">        <span class="keyword">int</span> p,q,c,tmp;</span><br><span class="line">        <span class="built_in">cin</span>&gt;&gt;p&gt;&gt;q&gt;&gt;c;</span><br><span class="line">        <span class="keyword">if</span> (cmp[i][j]==<span class="number">0</span> || c&lt;cmp[i][j]) cmp[i][j]=c;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">for</span> (i=<span class="number">1</span>;i&lt;=n;i++)</span><br><span class="line">        <span class="keyword">for</span> (j=<span class="number">1</span>;j&lt;=n;j++)</span><br><span class="line">            <span class="keyword">if</span> (cmp[i][j]) e[i].push_back((edge)&#123;j,cmp[i][j]&#125;);</span><br><span class="line">    dijkstra();</span><br><span class="line">    <span class="keyword">if</span> (dis[n]!=<span class="number">0x7fffffff</span>) <span class="built_in">cout</span>&lt;&lt;dis[n]&lt;&lt;<span class="string">" "</span>&lt;&lt;ans[n]&lt;&lt;<span class="built_in">endl</span>;</span><br><span class="line">    <span class="keyword">else</span> <span class="built_in">cout</span>&lt;&lt;<span class="string">"No answer"</span>&lt;&lt;<span class="built_in">endl</span>;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="Floyd"><a href="#Floyd" class="headerlink" title="Floyd"></a>Floyd</h3><p>著名的Floyd算法，算法的核心代码非常短，时间复杂度$O(V^3)$。采用邻接矩阵<code>arr[i][j]</code>的方式存图，三层循环不可调换。具体原理可以用dp来解释，在此不表。直接上核心代码。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> k=<span class="number">1</span>;k&lt;=N;k++)</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i=<span class="number">1</span>;i&lt;=N;i++)</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> j=<span class="number">1</span>;j&lt;=N;j++)</span><br><span class="line">            arr[i][j]=<span class="built_in">min</span>(arr[i][j],arr[i][k]+arr[k][j]);</span><br></pre></td></tr></table></figure><p>Floyd算法还需要看看练习题：<a href="https://www.luogu.com.cn/problem/P1119" target="_blank" rel="noopener">P1119 灾后重建</a></p><p>也可以看看我关与此题的题解，见<a href="[https://www.alpha-yang.cn/2020/06/23/%E3%80%90%E5%9B%BE%E8%AE%BA%E4%B8%8E%E6%A0%91%E3%80%91XDUACM%E6%9A%91%E5%9F%B9%E6%B4%9B%E8%B0%B7%E7%AE%97%E6%B3%95%E9%A2%98%E8%A7%A3/](https://www.alpha-yang.cn/2020/06/23/[图论与树]XDUACM暑培洛谷算法题解/">个人博客</a>)或<a href="https://zhuanlan.zhihu.com/p/150134695" target="_blank" rel="noopener">知乎专栏</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在图论中有一个非常常见的问题，就是最短路径的问题。常见的最短路径算法有三种：dijkstra，floyd和SPFA。本文将带你了解前两种最短路算法，他们分别适用于不同场景下的问题。&lt;/p&gt;
&lt;p&gt;以下笔记乃是参考西电ACM暑假培训张帆大佬的讲课以及&lt;a href=&quot;https://www.cnblogs.com/xzxl/p/7266404.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;优先队列博客&lt;/a&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="ACM算法" scheme="http://yoursite.com/categories/ACM%E7%AE%97%E6%B3%95/"/>
    
      <category term="西电培训笔记" scheme="http://yoursite.com/categories/ACM%E7%AE%97%E6%B3%95/%E8%A5%BF%E7%94%B5%E5%9F%B9%E8%AE%AD%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="图论" scheme="http://yoursite.com/tags/%E5%9B%BE%E8%AE%BA/"/>
    
  </entry>
  
</feed>
